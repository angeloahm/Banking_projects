{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call Reports Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Housekeeping and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from linearmodels import PanelOLS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/angel/Documents/Economics/Research/Banking Project/data/clean'\n",
    "path_output = 'C:/Users/angel/Documents/Economics/Research/Banking Project/data/output'\n",
    "\n",
    "# set colorblind theme for plots:\n",
    "sns.set_theme(context='notebook', style=\"ticks\", palette='colorblind')\n",
    "sns.set_color_codes(palette='colorblind')\n",
    "\n",
    "# Set path to be the directory:\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RCFD1754_x',\n",
       " 'RCFD1773_x',\n",
       " 'RCON1754_x',\n",
       " 'Unnamed: 79_x',\n",
       " 'Unnamed: 241_x',\n",
       " 'Unnamed: 88_x',\n",
       " 'RCFD1754_y',\n",
       " 'RCFD1773_y',\n",
       " 'RCON1754_y',\n",
       " 'Unnamed: 79_y',\n",
       " 'Unnamed: 241_y',\n",
       " 'Unnamed: 88_y']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read just the first row in the 'call_reports.csv' file:\n",
    "sample = pd.read_csv('call_reports.csv', nrows=1)\n",
    "\n",
    "# list the columns that have '_x' and '_y' in them:\n",
    "cols_x = [col for col in sample.columns if '_x' in col]\n",
    "cols_y = [col for col in sample.columns if '_y' in col]\n",
    "\n",
    "problem_cols = cols_x + cols_y\n",
    "problem_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the list of variables that will be used\n",
    "variables = ['RCON2170', 'RCFD2170', 'RCON2122', 'RCFD2122', 'RCON2122', 'RCON2200', 'RCON1754', 'RCFD1754',\n",
    "             'RCON1772', 'RCON0010', 'RCON0071', 'RCON0081', 'RCFD1754_x', 'RCFD1754_y', 'RCON1754_x', 'RCON1754_y',\n",
    "             'RIAD4073', 'RIAD4200', 'RIAD4185', 'RIAD4180', 'RIAD4172', \n",
    "             'Date', 'IDRSSD', 'Financial Institution Name'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file that contains only the variables of interest, specify that the column 'Date' is a date:\n",
    "main = pd.read_csv('call_reports.csv', parse_dates = ['Date'], usecols=variables)\n",
    "main['Year'] = main['Date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001-03-31 00:00:00\n",
      "2018-12-31 00:00:00\n",
      "2019-03-31 00:00:00\n",
      "2024-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# print the latest 'Date' for which either 'RCON1754_x' or 'RCON1754_y' is reported:\n",
    "print(main[main['RCFD1754_x'].notnull() | main['RCFD1754_y'].notnull()]['Date'].min())\n",
    "print(main[main['RCFD1754_x'].notnull() | main['RCFD1754_y'].notnull()]['Date'].max())\n",
    "\n",
    "print(main[main['RCFD1754'].notnull()]['Date'].min())\n",
    "print(main[main['RCFD1754'].notnull()]['Date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001-03-31 00:00:00\n",
      "2018-12-31 00:00:00\n",
      "2019-03-31 00:00:00\n",
      "2024-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# print the latest 'Date' for which either 'RCON1754_x' or 'RCON1754_y' is reported:\n",
    "print(main[main['RCON1754_x'].notnull() | main['RCON1754_y'].notnull()]['Date'].min())\n",
    "print(main[main['RCON1754_x'].notnull() | main['RCON1754_y'].notnull()]['Date'].max())\n",
    "\n",
    "print(main[main['RCON1754'].notnull()]['Date'].min())\n",
    "print(main[main['RCON1754'].notnull()]['Date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows in which RCON1754_x and RCON1754_y are both reported and different is: 0\n",
      "The number of rows in which RCFD1754_x and RCFD1754_y are both reported and different is: 0\n"
     ]
    }
   ],
   "source": [
    "print('The number of rows in which RCON1754_x and RCON1754_y are both reported and different is:',\n",
    "    len(main[main['RCON1754_x'].notnull() & main['RCON1754_y'].notnull() & (main['RCON1754_x']-main['RCON1754_y'] != 0)]))\n",
    "\n",
    "print('The number of rows in which RCFD1754_x and RCFD1754_y are both reported and different is:',\n",
    "    len(main[main['RCFD1754_x'].notnull() & main['RCFD1754_y'].notnull() & (main['RCFD1754_x']-main['RCFD1754_y'] != 0)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Balance sheet definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6.351330e+05\n",
      "mean     9.755156e+05\n",
      "std      1.244043e+07\n",
      "min      0.000000e+00\n",
      "25%      6.975000e+04\n",
      "50%      1.522690e+05\n",
      "75%      3.686870e+05\n",
      "max      1.445545e+09\n",
      "Name: RCON2170, dtype: float64\n",
      "count    9.589000e+03\n",
      "mean     1.036920e+08\n",
      "std      3.150145e+08\n",
      "min      4.264000e+03\n",
      "25%      1.455077e+06\n",
      "50%      1.235404e+07\n",
      "75%      6.758438e+07\n",
      "max      3.584105e+09\n",
      "Name: RCFD2170, dtype: float64\n",
      "count    6.399020e+05\n",
      "mean     2.114301e+06\n",
      "std      3.944563e+07\n",
      "min      0.000000e+00\n",
      "25%      7.020225e+04\n",
      "50%      1.539290e+05\n",
      "75%      3.772038e+05\n",
      "max      3.584105e+09\n",
      "Name: Total Assets, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create 'Total Assets' variable. If the bank fills the FFIEC41 (only RCON series available). Large banks may also have the \n",
    "# RCFD series available. If both are NaN, fill with NaN. If both are available, use the RCON series. If only RCFD is available,\n",
    "# use RCFD. \n",
    "main['Total Assets'] = main['RCON2170'].combine_first(main['RCFD2170'])\n",
    "\n",
    "print(main['RCON2170'].describe())\n",
    "print(main['RCFD2170'].describe())\n",
    "print(main['Total Assets'].describe())\n",
    "\n",
    "main['Total Assets'] = main['Total Assets'].mask(main['Total Assets'] == 0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6.399020e+05\n",
      "mean     1.115855e+06\n",
      "std      1.638202e+07\n",
      "min      0.000000e+00\n",
      "25%      3.991900e+04\n",
      "50%      9.623600e+04\n",
      "75%      2.468268e+05\n",
      "max      1.219816e+09\n",
      "Name: RCON2122, dtype: float64\n",
      "count    9.589000e+03\n",
      "mean     5.150065e+07\n",
      "std      1.402738e+08\n",
      "min      0.000000e+00\n",
      "25%      7.367520e+05\n",
      "50%      7.377421e+06\n",
      "75%      3.715684e+07\n",
      "max      1.353071e+09\n",
      "Name: RCFD2122, dtype: float64\n",
      "count    6.399020e+05\n",
      "mean     1.115855e+06\n",
      "std      1.638202e+07\n",
      "min      0.000000e+00\n",
      "25%      3.991900e+04\n",
      "50%      9.623600e+04\n",
      "75%      2.468268e+05\n",
      "max      1.219816e+09\n",
      "Name: Total Loans, dtype: float64\n",
      "count    6.294910e+05\n",
      "mean     1.134310e+06\n",
      "std      1.651630e+07\n",
      "min      1.000000e+00\n",
      "25%      4.195200e+04\n",
      "50%      9.887900e+04\n",
      "75%      2.515910e+05\n",
      "max      1.219816e+09\n",
      "Name: Total Loans, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angel\\AppData\\Local\\Temp\\ipykernel_10404\\2193418771.py:1: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  main['Total Loans'] = main['RCON2122'].combine_first(main['RCFD2122'])\n"
     ]
    }
   ],
   "source": [
    "main['Total Loans'] = main['RCON2122'].combine_first(main['RCFD2122'])\n",
    "\n",
    "print(main['RCON2122'].describe())\n",
    "print(main['RCFD2122'].describe())\n",
    "print(main['Total Loans'].describe())\n",
    "\n",
    "main['Total Loans'] = main['Total Loans'].mask(main['Total Loans'] == 0, np.nan)\n",
    "print(main['Total Loans'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6.333120e+05\n",
      "mean     1.459541e+06\n",
      "std      2.552438e+07\n",
      "min      1.000000e+00\n",
      "25%      5.953400e+04\n",
      "50%      1.298275e+05\n",
      "75%      3.129310e+05\n",
      "max      2.201118e+09\n",
      "Name: Total Deposits, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create 'Total Deposits'\n",
    "main.rename(columns = {'RCON2200':'Total Deposits'}, inplace = True)\n",
    "main['Total Deposits'] = main['Total Deposits'].mask(main['Total Deposits'] == 0, np.nan)\n",
    "print(main['Total Deposits'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6.390710e+05\n",
      "mean     1.715995e+05\n",
      "std      4.239690e+06\n",
      "min      1.000000e+00\n",
      "25%      3.374000e+03\n",
      "50%      8.435000e+03\n",
      "75%      2.253550e+04\n",
      "max      5.436850e+08\n",
      "Name: Cash, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create 'Cash' summing RCON0020 and RCON0080:\n",
    "main['Cash'] = main['RCON0010'].combine_first(main['RCON0071']+main['RCON0081'])\n",
    "main['Cash'] = main['Cash'].mask(main['Cash'] <= 0, np.nan)\n",
    "print(main['Cash'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "main['RCON1754_right'] = main['RCON1754_x'].combine_first(main['RCON1754'])\n",
    "main['RCFD1754_right'] = main['RCFD1754_x'].combine_first(main['RCFD1754'])\n",
    "\n",
    "# Create the new column '1754_right' and initialize with NaN\n",
    "main['1754_right'] = np.nan\n",
    "\n",
    "# Case 1: Both columns are not null\n",
    "mask_both_notnull = main['RCFD1754_right'].notna() & main['RCON1754_right'].notna()\n",
    "main.loc[mask_both_notnull, '1754_right'] = main.loc[mask_both_notnull, ['RCFD1754_right', 'RCON1754_right']].max(axis=1)\n",
    "\n",
    "# Case 2: Only one column is not null\n",
    "mask_col1_notnull = main['RCFD1754_right'].notna() & main['RCON1754_right'].isna()\n",
    "main.loc[mask_col1_notnull, '1754_right'] = main.loc[mask_col1_notnull, 'RCFD1754_right']\n",
    "\n",
    "mask_col2_notnull = main['RCON1754_right'].notna() & main['RCFD1754_right'].isna()\n",
    "main.loc[mask_col2_notnull, '1754_right'] = main.loc[mask_col2_notnull, 'RCON1754_right']\n",
    "\n",
    "# Case 3: Both columns are null (already handled by initialization to NaN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>RCON1754_right</th>\n",
       "      <th>RCFD1754_right</th>\n",
       "      <th>1754_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-03-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-03-31</td>\n",
       "      <td>38742.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38742.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-03-31</td>\n",
       "      <td>116.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-03-31</td>\n",
       "      <td>3191.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-03-31</td>\n",
       "      <td>5298.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639897</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639898</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639899</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639900</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639901</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630313 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date  RCON1754_right  RCFD1754_right  1754_right\n",
       "0      2001-03-31             0.0             NaN         0.0\n",
       "1      2001-03-31         38742.0             NaN     38742.0\n",
       "2      2001-03-31           116.0             NaN       116.0\n",
       "3      2001-03-31          3191.0             NaN      3191.0\n",
       "4      2001-03-31          5298.0             NaN      5298.0\n",
       "...           ...             ...             ...         ...\n",
       "639897 2023-12-31             0.0             NaN         0.0\n",
       "639898 2023-12-31             0.0             NaN         0.0\n",
       "639899 2023-12-31             0.0             NaN         0.0\n",
       "639900 2023-12-31             0.0             NaN         0.0\n",
       "639901 2023-12-31             0.0             NaN         0.0\n",
       "\n",
       "[630313 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main[main['RCON1754_right'].notnull() & \n",
    "     main['RCFD1754_right'].isnull() & \n",
    "     (main['RCON1754_right']-main['RCFD1754_right'] != 0)][['Date', 'RCON1754_right', 'RCFD1754_right', '1754_right']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6.165940e+05\n",
      "mean     2.119523e+05\n",
      "std      4.478091e+06\n",
      "min      1.000000e+00\n",
      "25%      1.113100e+04\n",
      "50%      2.871750e+04\n",
      "75%      7.480675e+04\n",
      "max      6.830540e+08\n",
      "Name: Securities AC, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create 'Securities AC' summing RCON1754 and RCON1772. If both are NaN, fill with NaN. If only one is available, use that one. If both \n",
    "# are available sum them:\n",
    "main['Securities AC'] = main[['1754_right', 'RCON1772']].apply(\n",
    "    lambda row: np.nan if pd.isna(row['1754_right']) and pd.isna(row['RCON1772']) else (row.fillna(0).sum()),\n",
    "    axis=1\n",
    ")\n",
    "main['Securities AC'] = main['Securities AC'].mask(main['Securities AC'] <= 0, np.nan)\n",
    "print(main['Securities AC'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the 'Deposit Share' of each bank, per 'Date':\n",
    "main.loc[:,'Deposit Share'] = main['Total Deposits']/main.groupby('Date')['Total Deposits'].transform('sum')\n",
    "print(main['Deposit Share'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Income Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the variable above avoiding the SettingWithCopyWarning:\n",
    "main.loc[:, 'Deposit Expenditure'] = (main['RIAD4073'].fillna(0) - main['RIAD4200'].fillna(0) - main['RIAD4185'].fillna(0) - \n",
    "                                      main['RIAD4180'].fillna(0) - main['RIAD4172'].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.loc[:, 'Actual Deposit Exp'] = main.groupby(['IDRSSD', 'Year'])['Deposit Expenditure'].diff().fillna(main['Deposit Expenditure'])\n",
    "main.loc[:, 'Actual Deposit Exp'] = main['Actual Deposit Exp'].mask(main['Actual Deposit Exp'] <= 0, np.nan)\n",
    "main['Actual Deposit Exp'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute deposit rates:\n",
    "main.loc[:,'Deposit Rate'] = main['Actual Deposit Exp'] / main['Total Deposits']\n",
    "print(main['Deposit Rate'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an extra column in df3 with the avg. deposit rate per Date:\n",
    "main.loc[:,'Avg. Deposit Rate'] = main.groupby('Date')['Deposit Rate'].transform('mean')\n",
    "main.loc[:,'Std. Deposit Rate'] = main.groupby('Date')['Deposit Rate'].transform('std')\n",
    "main.loc[:,'R_hat'] = (main['Deposit Rate'] - main['Avg. Deposit Rate']) / main['Std. Deposit Rate']\n",
    "main['R_hat'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_panel = 0\n",
    "\n",
    "if balanced_panel == 1:\n",
    "\n",
    "    # Step 1: Count the total number of unique dates in the dataset\n",
    "    total_dates = main['Date'].nunique()\n",
    "    print('Number of dates:', total_dates)\n",
    "\n",
    "    # Step 2: Count the number of unique dates each bank shows up\n",
    "    bank_date_counts = main.groupby('IDRSSD')['Date'].nunique()\n",
    "    print('Banks that show up in all dates:', sum(bank_date_counts==total_dates))\n",
    "\n",
    "    # Step 3: Identify banks that are present in all dates with positive 'Total Deposit':\n",
    "    banks = bank_date_counts[bank_date_counts == total_dates].index\n",
    "    main = main[main['IDRSSD'].isin(banks)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load monetary policy shock data:\n",
    "mp_shocks = pd.read_csv('brw-shock-series.csv')\n",
    "\n",
    "# Drop column that has 'Unnamed' in it:\n",
    "mp_shocks = mp_shocks.loc[:, ~mp_shocks.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# keep only the first 4 columns:\n",
    "mp_shocks = mp_shocks.iloc[:, 0:4]\n",
    "\n",
    "# rename columns:\n",
    "mp_shocks.columns = mp_shocks.columns.str.replace(' (updated)', '')\n",
    "mp_shocks.loc[:, 'month'] = mp_shocks['month'].str.replace('m', '-')\n",
    "mp_shocks = mp_shocks[['month', 'BRW_monthly']]\n",
    "\n",
    "# drop the 'NaT' row:\n",
    "mp_shocks = mp_shocks.dropna()\n",
    "mp_shocks['month'] = pd.to_datetime(mp_shocks['month'], format='%Y-%m')\n",
    "# compute the quarterly average of the monthly shocks:\n",
    "mp_shocks['quarter'] = mp_shocks['month'].dt.to_period('Q')\n",
    "mp_shocks['BRW_quarterly'] = mp_shocks.groupby('quarter')['BRW_monthly'].transform('sum')\n",
    "\n",
    "# keep only one observation for 'month' and 'BRW_quarterly' for each quarter:\n",
    "mp_shocks = mp_shocks.drop_duplicates(subset='quarter', keep='first')\n",
    "mp_shocks['Date'] = mp_shocks['month'] - pd.DateOffset(days = 1)\n",
    "\n",
    "mp_shocks = mp_shocks[['Date', 'BRW_quarterly']]\n",
    "mp_shocks.rename(columns={'BRW_quarterly': 'MP Shocks'}, inplace=True)\n",
    "\n",
    "mp_shocks.loc[:,'Positive FF Shock'] = 0\n",
    "mp_shocks.loc[mp_shocks['MP Shocks'] > 0, 'Positive FF Shock'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excess Bond Premium data:\n",
    "ebp = pd.read_csv('ebp_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fredgraph data:\n",
    "aggregates = pd.read_csv('fredgraph.csv')\n",
    "\n",
    "# rename some variables\n",
    "aggregates.rename(columns = {'DATE':'Date', \n",
    "                             'NGDPSAXDCUSQ': 'Nominal GDP', \n",
    "                             'CPIAUCSL_NBD19840101': 'CPI',\n",
    "                             'GDPDEF': 'Deflator'}, inplace = True)\n",
    "\n",
    "# drop the first row:\n",
    "aggregates = aggregates.iloc[1:,:]\n",
    "\n",
    "# for all entries with '.' substitute with NaN:\n",
    "aggregates = aggregates.replace('.', np.nan)\n",
    "\n",
    "# make 'Deflator' and 'Nominal GDP' floats:\n",
    "aggregates['Deflator'] = aggregates['Deflator'].astype(float)\n",
    "aggregates['Nominal GDP'] = aggregates['Nominal GDP'].astype(float)\n",
    "aggregates['FEDFUNDS'] = aggregates['FEDFUNDS'].astype(float)\n",
    "aggregates['CPI'] = aggregates['CPI'].astype(float)\n",
    "\n",
    "# make 'Date' a datetime object:\n",
    "aggregates['Date'] = pd.to_datetime(aggregates['Date'])\n",
    "\n",
    "# create 'Real GDP' variable:\n",
    "aggregates['Real GDP'] = aggregates['Nominal GDP'] / aggregates['CPI'] * 100\n",
    "aggregates = aggregates.dropna()\n",
    "\n",
    "# adjust the FF rate: \n",
    "aggregates['FEDFUNDS'] = aggregates['FEDFUNDS'] / 100\n",
    "aggregates['Date'] = aggregates['Date'] - pd.DateOffset(days = 1)\n",
    "\n",
    "# create 'Inflation' as the growth rate of the CPI:\n",
    "aggregates['Inflation'] = aggregates['CPI'].pct_change(fill_method=None)\n",
    "\n",
    "# create a variable named 'High Inflation' as 1 if the inflation is above the average, and 0 otherwise:\n",
    "aggregates['High Inflation'] = 0\n",
    "aggregates.loc[aggregates['Inflation'] > aggregates['Inflation'].mean(), 'High Inflation'] = 1\n",
    "\n",
    "# create a variable named 'FF Hike' as 1 if the FF rate increased, and 0 otherwise:\n",
    "aggregates['FF Hike'] = 0\n",
    "aggregates.loc[aggregates['FEDFUNDS'] > aggregates['FEDFUNDS'].shift(1), 'FF Hike'] = 1\n",
    "\n",
    "param = 1600\n",
    "\n",
    "# De-trend the variables using an HP filter:\n",
    "aggregates['De-trended Real GDP'] = sm.tsa.filters.hpfilter(np.log(aggregates['Real GDP']), lamb=param)[0]\n",
    "\n",
    "# create a variable named 'Boom' that is 1, if the De-trended Real GDP is above 0, and 0 otherwise:\n",
    "aggregates['Recession'] = 0\n",
    "aggregates.loc[aggregates['De-trended Real GDP'] < 0, 'Recession'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data on mergers and acquisitions:\n",
    "transformations = pd.read_csv('CSV_TRANSFORMATIONS.csv')\n",
    "\n",
    "# rename the columns:\n",
    "transformations = transformations.rename(columns={'#ID_RSSD_PREDECESSOR': 'Predecessor ID', \n",
    "                                                  'ID_RSSD_SUCCESSOR': 'Successor ID',\n",
    "                                                 'DT_TRANS': 'Transaction Date',\n",
    "                                                 'TRNSFM_CD': 'Transaction Code',})\n",
    "\n",
    "# convert the 'transaction_date' to datetime format:\n",
    "transformations['Transaction Date'] = pd.to_datetime(transformations['Transaction Date'], format='%Y%m%d')\n",
    "transformations = transformations[['Predecessor ID', 'Successor ID', 'Transaction Date', 'Transaction Code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main = pd.merge(main, aggregates, how = 'left', on = 'Date').sort_values(by = ['IDRSSD', 'Date'])\n",
    "#main = pd.merge(main, mp_shocks, how = 'left', on = 'Date').sort_values(by = ['IDRSSD', 'Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_growth(df, transformations, window=1):\n",
    "    \"\"\"\n",
    "    Compute the log difference of deposits while accounting for mergers, acquisitions, and failures.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): Dataframe containing bank-level balance sheet data.\n",
    "    - transformations (pd.DataFrame): Dataframe containing information about transformations.\n",
    "    - window (int): Number of quarters before and after a transaction to set as NaN for growth rate.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The updated 'df' with a 'deposit_growth' column.\n",
    "    \"\"\"\n",
    "    # Sort the dataframe by bank ID and date to ensure proper lag calculation\n",
    "    df = df.sort_values(by=['IDRSSD', 'Date'])\n",
    "    df['Real Deposits'] = df['Total Deposits'] / df['CPI'] * 100\n",
    "    df['Real Loans'] = df['Total Loans'] / df['CPI'] * 100\n",
    "\n",
    "\n",
    "    # Calculate log difference (log growth rate) of deposits\n",
    "    df['Deposit_Growth'] = df.groupby('IDRSSD')['Real Deposits'].transform(lambda x: np.log(x).diff())\n",
    "    df['Loan_Growth'] = df.groupby('IDRSSD')['Real Loans'].transform(lambda x: np.log(x).diff())\n",
    "    \n",
    "    # Create a mask to identify rows to be set to NaN\n",
    "    for _, row in transformations.iterrows():\n",
    "        predecessor_id = row['Predecessor ID']\n",
    "        successor_id = row['Successor ID']\n",
    "        transaction_date = row['Transaction Date']\n",
    "        \n",
    "        # Identify date range around the transaction\n",
    "        start_date = transaction_date - pd.DateOffset(months=3 * window)\n",
    "        end_date = transaction_date + pd.DateOffset(months=3 * window)\n",
    "        \n",
    "        # Apply NaN to the specified window for predecessor and successor banks\n",
    "        df.loc[\n",
    "            ((df['IDRSSD'] == predecessor_id) | (df['IDRSSD'] == successor_id)) & \n",
    "            (df['Date'].between(start_date, end_date)),\n",
    "            'Deposit_Growth'\n",
    "        ] = np.nan\n",
    "\n",
    "        df.loc[\n",
    "            ((df['IDRSSD'] == predecessor_id) | (df['IDRSSD'] == successor_id)) & \n",
    "            (df['Date'].between(start_date, end_date)),\n",
    "            'Loan_Growth'\n",
    "        ] = np.nan\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Define function to compute binned averages using qcut\n",
    "def binned_scatter(x, y, q, label):\n",
    "    # Create quantile bins using qcut\n",
    "    x_binned, bin_edges = pd.qcut(x, q=q, retbins=True, duplicates='drop')\n",
    "    bin_centers = [x[(x_binned == interval)].mean() for interval in x_binned.unique()]\n",
    "    binned_means = [y[x_binned == interval].mean() for interval in x_binned.unique()]\n",
    "    \n",
    "    # Plot the binned means\n",
    "    plt.scatter(bin_centers, binned_means, label=label, alpha=0.7, s=50)\n",
    "\n",
    "    # Add a 45-degree line for reference:\n",
    "    #plt.plot([min(x), max(x)], [min(x), max(x)], linestyle='--', color='black', alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main[[ 'IDRSSD', 'Date', 'Financial Institution Name',             # Dates and IDS \n",
    "            'Total Deposits', 'Deposit Share', 'Total Assets',          # Bank specific quantity variables\n",
    "            'Total Loans',\n",
    "            'Deposit Rate', 'Deposit Spread',                           # Bank specific rate variable\n",
    "            'Cash', 'Securities AC',                                    # Bank specific asset variables\n",
    "            'FEDFUNDS', 'High Inflation', 'FF Hike', 'Recession',\n",
    "            'CPI', 'Positive FF Shock'                                  # Macro variables\n",
    "            ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'Securities Share'] = df['Securities AC'] / df['Total Assets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "svb_securities = df[(df['IDRSSD'] == 802866) & (df['Date'] == '2022-12-31')]['Securities Share'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell me the IDs of the banks that have a 'Securities Share' above svb_securities:\n",
    "right_tail_banks = df[(df['Date'] == '2022-12-31') & \n",
    "                      (df[df['Date'] == '2022-12-31']['Securities Share'] > svb_securities)]['IDRSSD'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_tail_df = df[ (df['Date'] == '2022-12-31') & \n",
    "    (df['IDRSSD'].isin(right_tail_banks))][['Financial Institution Name', 'Total Assets', 'Total Deposits']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Date'] == '2022-12-31')][['Financial Institution Name', 'Total Assets', 'Total Deposits']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_tail_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of securities share for 03/31/2023:\n",
    "sns.histplot(df[df['Date'] == '2022-12-31']['Securities Share'], bins=20, kde=True)\n",
    "# add a vertical line for the bank with IDRSSD=802866:\n",
    "plt.axvline(x=df[(df['IDRSSD'] == 802866) & (df['Date'] == '2022-12-31')]['Securities Share'].values[0], \n",
    "            color='red', linestyle='--', linewidth=2)       \n",
    "plt.title('Distribution of Securities Share on 12/31/2022')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the correlation between FF Hike and Positive FF Shock:\n",
    "df[['FF Hike', 'Positive FF Shock']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = compute_growth(df, transformations, window=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Loan_Growth'].describe())\n",
    "print(df['Loan_Growth'].quantile([0.01, 0.99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Deposit_Growth'].describe())\n",
    "print(df['Deposit_Growth'].quantile([0.01, 0.99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask the outliers (top and bottom 0.1%) of the distribution of 'Deposit Growth':\n",
    "df['Deposit_Growth'] = df['Deposit_Growth'].mask((df['Deposit_Growth'] < df['Deposit_Growth'].quantile(0.01)) | \n",
    "                                                 (df['Deposit_Growth'] > df['Deposit_Growth'].quantile(0.99)), np.nan)\n",
    "\n",
    "df['Loan_Growth'] = df['Loan_Growth'].mask((df['Loan_Growth'] < df['Loan_Growth'].quantile(0.01)) | \n",
    "                                                 (df['Loan_Growth'] > df['Loan_Growth'].quantile(0.99)), np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Securities Growth'] = df.groupby('IDRSSD')['Securities AC'].pct_change(fill_method=None)\n",
    "print(df['Securities Growth'].describe())\n",
    "# if the 'Securities Growth' is in either top or bottom 1% of the distribution, set it to NaN:\n",
    "df['Securities Growth'] = df['Securities Growth'].mask((df['Securities Growth'] < df['Securities Growth'].quantile(0.01)) | (df['Securities Growth'] > df['Securities Growth'].quantile(0.99)))\n",
    "print(df['Securities Growth'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Real Cash'] = df['Cash'] / df['CPI'] * 100\n",
    "df['Cash Growth'] = df.groupby('IDRSSD')['Real Cash'].pct_change(fill_method=None)\n",
    "print(df['Cash Growth'].describe())\n",
    "# if the 'Securities Growth' is in either top or bottom 1% of the distribution, set it to NaN:\n",
    "df['Cash Growth'] = df['Cash Growth'].mask((df['Cash Growth'] < df['Cash Growth'].quantile(0.01)) | (df['Cash Growth'] > df['Cash Growth'].quantile(0.99)))\n",
    "print(df['Cash Growth'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_sectional_plots(  df,                     # Dataframe with bank-level data \n",
    "                            criteria,               # Criteria to define the interest rate shock\n",
    "                            num_quantiles=100):     # Number of quantiles for the binned scatter plot\n",
    "\n",
    "    # Define the interest rate criteria:\n",
    "    # 1. 'ff_hike': FF Hike is a simple increase in the FFR.\n",
    "    # 2. 'mp_shock': MP Shock is a positive shock to the FFR.\n",
    "    if criteria == 'ff_hike':\n",
    "        # Filter conditions for Expansion and Contraction\n",
    "        expansion_condition = (\n",
    "                              (df['Recession'] == 0) & \n",
    "                              (df['FF Hike'] == 1) &\n",
    "                              (df['High Inflation'] == 1)\n",
    "                              )\n",
    "        contraction_condition = (\n",
    "                                (df['Recession'] == 1) &\n",
    "                                (df['FF Hike'] == 1) &\n",
    "                                (df['High Inflation'] == 1)\n",
    "                                )\n",
    "\n",
    "    elif criteria == 'mp_shock':\n",
    "        # Filter conditions for Expansion and Contraction\n",
    "        expansion_condition = (\n",
    "                            (df['Recession'] == 0) &\n",
    "                            (df['Positive FF Shock'] == 1) &\n",
    "                            (df['High Inflation'] == 1)\n",
    "                            )\n",
    "        contraction_condition = (\n",
    "                            (df['Recession'] == 1) &\n",
    "                            (df['Positive FF Shock'] == 1) & \n",
    "                            (df['High Inflation'] == 1)\n",
    "                            )\n",
    "\n",
    "    else:\n",
    "        print('Criteria not found')\n",
    "        return None\n",
    "    \n",
    "    # --------------------------------- Histograms --------------------------------- #\n",
    "\n",
    "    # make a histogram of the de-trended loans when the inflation is high, FF hike and Boom vs. Recession:\n",
    "    lin = np.linspace(-0.25, 0.25, 150)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(df[expansion_condition]['Loan_Growth'], \n",
    "                label='Expansion', bins=lin, stat='density', alpha=0.6)\n",
    "    plt.axvline(df[expansion_condition]['Loan_Growth'].mean(), linestyle='--', linewidth=2, color='blue')\n",
    "    sns.histplot(df[contraction_condition]['Loan_Growth'], \n",
    "                label='Contraction', bins=lin, alpha=0.6, stat='density')\n",
    "    plt.axvline(df[contraction_condition]['Loan_Growth'].mean(), linestyle='--', linewidth=2, color='orange')\n",
    "    plt.title('Loan Growth (High Inflation, FF Hike)')\n",
    "    plt.xlabel('Loan Growth')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    # print the std deviation of both distributions in the (-0.2,8) coordinate:\n",
    "    plt.text(0.1, 7, 'Mean Expansion:             ' + str(round(df[expansion_condition]['Loan_Growth'].mean(), 4)))\n",
    "    plt.text(0.1, 6.5, 'Std. Expansion:             ' + str(round(df[expansion_condition]['Loan_Growth'].std(), 4)))\n",
    "    plt.text(0.1, 6, 'Mean Contraction:           ' + str(round(df[contraction_condition]['Loan_Growth'].mean(), 4)))\n",
    "    plt.text(0.1, 5.5, 'Std. Contraction:           ' + str(round(df[contraction_condition]['Loan_Growth'].std(), 4)))\n",
    "    plt.grid(True, which='both', linestyle='--', lw=0.5, alpha=0.5, color='lightgrey')\n",
    "    plt.xlim(-0.13, 0.22)\n",
    "    plt.show()\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    lin = np.linspace(-0.25, 0.25, 150)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(df[expansion_condition]['Deposit_Growth'], \n",
    "                label='Expansion', bins=lin, stat='density', alpha=0.6)\n",
    "    plt.axvline(df[expansion_condition]['Deposit_Growth'].mean(), linestyle='--', linewidth=2, color='blue')\n",
    "    sns.histplot(df[contraction_condition]['Deposit_Growth'], \n",
    "                label='Contraction', bins=lin, alpha=0.6, stat='density')\n",
    "    plt.axvline(df[contraction_condition]['Deposit_Growth'].mean(), linestyle='--', linewidth=2, color='orange')\n",
    "    plt.title('Deposits Growth (High Inflation, FF Hike)')\n",
    "    plt.xlabel('Deposits Growth')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    # print the std deviation of both distributions in the (-0.2,8) coordinate:\n",
    "    plt.text(0.1, 7, 'Mean Expansion:             ' + str(round(df[expansion_condition]['Deposit_Growth'].mean(), 4)))\n",
    "    plt.text(0.1, 6.5, 'Std. Expansion:             ' + str(round(df[expansion_condition]['Deposit_Growth'].std(), 4)))\n",
    "    plt.text(0.1, 6, 'Mean Contraction:           ' + str(round(df[contraction_condition]['Deposit_Growth'].mean(), 4)))\n",
    "    plt.text(0.1, 5.5, 'Std. Contraction:           ' + str(round(df[contraction_condition]['Deposit_Growth'].std(), 4)))\n",
    "    plt.grid(True, which='both', linestyle='--', lw=0.5, alpha=0.5, color='lightgrey')\n",
    "    plt.xlim(-0.13, 0.22)\n",
    "    plt.show()\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    # make a histogram of the de-trended loans when the inflation is high, FF hike and Boom vs. Recession:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(df[expansion_condition]['Securities Growth'], \n",
    "                label='Expansion', bins=lin, stat='density', alpha=0.6)\n",
    "    plt.axvline(df[expansion_condition]['Securities Growth'].mean(), linestyle='--', linewidth=2, color='blue')\n",
    "    sns.histplot(df[contraction_condition]['Securities Growth'], \n",
    "                label='Contraction', bins=lin, alpha=0.6, stat='density')\n",
    "    plt.axvline(df[contraction_condition]['Securities Growth'].mean(), linestyle='--', linewidth=2, color='orange')\n",
    "    plt.title('Securities Growth (High Inflation, FF Hike)')\n",
    "    plt.xlabel('Securities Growth')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    # print the std deviation of both distributions in the (-0.2,8) coordinate:\n",
    "    plt.text(0.1, 7.5, 'Mean Expansion:             ' + str(round(df[expansion_condition]['Securities Growth'].mean(), 4)))\n",
    "    plt.text(0.1, 6.5, 'Std. Expansion:             ' + str(round(df[expansion_condition]['Securities Growth'].std(), 4)))\n",
    "    plt.text(0.1, 5.5, 'Mean Contraction:           ' + str(round(df[contraction_condition]['Securities Growth'].mean(), 4)))\n",
    "    plt.text(0.1, 4.5, 'Std. Contraction:           ' + str(round(df[contraction_condition]['Securities Growth'].std(), 4)))\n",
    "    plt.grid(True, which='both', linestyle='--', lw=0.5, alpha=0.5, color='lightgrey')\n",
    "    plt.xlim(-0.25, 0.25)\n",
    "    plt.show()\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    # make a histogram of the de-trended loans when the inflation is high, FF hike and Boom vs. Recession:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    lin = np.linspace(df['Cash Growth'].min(), 2, 150)\n",
    "    sns.histplot(df[expansion_condition]['Cash Growth'], \n",
    "                label='Expansion', bins=lin, stat='density', alpha=0.6)\n",
    "    plt.axvline(df[expansion_condition]['Cash Growth'].mean(), linestyle='--', linewidth=2, color='blue')\n",
    "    sns.histplot(df[contraction_condition]['Cash Growth'], \n",
    "                label='Contraction', bins=lin, alpha=0.6, stat='density')\n",
    "    plt.axvline(df[contraction_condition]['Cash Growth'].mean(), linestyle='--', linewidth=2, color='orange')\n",
    "    plt.title('Cash Growth (High Inflation, FF Hike)')\n",
    "    plt.xlabel('Cash Growth')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    # print the std deviation of both distributions in the (-0.2,8) coordinate:\n",
    "    # print the std deviation of both distributions in the (-0.2,8) coordinate:\n",
    "    plt.text(1, 1.4, 'Mean Expansion:             ' + str(round(df[expansion_condition]['Cash Growth'].mean(), 4)))\n",
    "    plt.text(1, 1.3, 'Std. Expansion:             ' + str(round(df[expansion_condition]['Cash Growth'].std(), 4)))\n",
    "    plt.text(1, 1.2, 'Mean Contraction:           ' + str(round(df[contraction_condition]['Cash Growth'].mean(), 4)))\n",
    "    plt.text(1, 1.1, 'Std. Contraction:           ' + str(round(df[contraction_condition]['Cash Growth'].std(), 4)))\n",
    "    plt.grid(True, which='both', linestyle='--', lw=0.5, alpha=0.5, color='lightgrey')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # --------------------------------- Scatter Plots --------------------------------- #\n",
    "    #-------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    # Create the figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Binned scatter for expansion\n",
    "    binned_scatter(\n",
    "    df.loc[expansion_condition, 'Loan_Growth'], \n",
    "    df.loc[expansion_condition, 'Securities Growth'], \n",
    "    q=num_quantiles, \n",
    "    #color='blue', \n",
    "    label='Expansion'\n",
    "    )\n",
    "\n",
    "    # Binned scatter for contraction\n",
    "    binned_scatter(\n",
    "    df.loc[contraction_condition, 'Loan_Growth'], \n",
    "    df.loc[contraction_condition, 'Securities Growth'], \n",
    "    q=num_quantiles, \n",
    "    #color='orange', \n",
    "    label='Contraction'\n",
    "    )\n",
    "\n",
    "    # Plot settings\n",
    "    plt.title('Binned Loan Growth vs. Securities Growth (Quantile Bins)')\n",
    "    plt.ylabel('Loan Growth')\n",
    "    plt.xlabel('Securities Growth')\n",
    "    plt.ylim(-0.05, 0.12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', linestyle='--', lw=0.5, alpha=0.5, color='lightgrey')\n",
    "    plt.show()\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------#\n",
    "    # Create the figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Binned scatter for expansion\n",
    "    binned_scatter(\n",
    "    df.loc[expansion_condition, 'Deposit_Growth'], \n",
    "    df.loc[expansion_condition, 'Loan_Growth'], \n",
    "    q=num_quantiles, \n",
    "    #color='blue', \n",
    "    label='Expansion'\n",
    "    )\n",
    "\n",
    "    # Binned scatter for contraction\n",
    "    binned_scatter(\n",
    "    df.loc[contraction_condition, 'Deposit_Growth'], \n",
    "    df.loc[contraction_condition, 'Loan_Growth'], \n",
    "    q=num_quantiles, \n",
    "    #color='orange', \n",
    "    label='Contraction'\n",
    "    )\n",
    "\n",
    "    # Plot settings\n",
    "    plt.title('Binned Deposits Growth vs. Loan Growth (Quantile Bins)')\n",
    "    plt.ylabel('Loan Growth')\n",
    "    plt.xlabel('Deposits Growth')\n",
    "    plt.ylim(-0.01, 0.05)\n",
    "    plt.xlim(-0.1, 0.2)\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', linestyle='--', lw=0.5, alpha=0.5, color='lightgrey')\n",
    "    plt.show()\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------#\n",
    "    # Create the figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Binned scatter for expansion\n",
    "    binned_scatter(\n",
    "    df.loc[expansion_condition, 'Deposit_Growth'], \n",
    "    df.loc[expansion_condition, 'Cash Growth'], \n",
    "    q=num_quantiles, \n",
    "    #color='blue', \n",
    "    label='Expansion'\n",
    "    )\n",
    "\n",
    "    # Binned scatter for contraction\n",
    "    binned_scatter(\n",
    "    df.loc[contraction_condition, 'Deposit_Growth'], \n",
    "    df.loc[contraction_condition, 'Cash Growth'], \n",
    "    q=num_quantiles, \n",
    "    #color='orange', \n",
    "    label='Contraction'\n",
    "    )\n",
    "\n",
    "    # Plot settings\n",
    "    plt.title('Binned Deposits Growth vs. Cash Growth (Quantile Bins)')\n",
    "    plt.ylabel('Cash Growth')\n",
    "    plt.xlabel('Deposits Growth')\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', linestyle='--', lw=0.5, alpha=0.5, color='lightgrey')\n",
    "    plt.show()\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------#\n",
    "    # Create the figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Binned scatter for expansion\n",
    "    binned_scatter(\n",
    "    df.loc[expansion_condition, 'Deposit_Growth'], \n",
    "    df.loc[expansion_condition, 'Securities Growth'], \n",
    "    q=num_quantiles, \n",
    "    #color='blue', \n",
    "    label='Expansion'\n",
    "    )\n",
    "\n",
    "    # Binned scatter for contraction\n",
    "    binned_scatter(\n",
    "    df.loc[contraction_condition, 'Deposit_Growth'], \n",
    "    df.loc[contraction_condition, 'Securities Growth'], \n",
    "    q=num_quantiles, \n",
    "    #color='orange', \n",
    "    label='Contraction'\n",
    "    )\n",
    "\n",
    "    # Plot settings\n",
    "    plt.title('Binned Deposits Growth vs. Securities Growth (Quantile Bins)')\n",
    "    plt.ylabel('Securities Growth')\n",
    "    plt.xlabel('Deposits Growth')\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', linestyle='--', lw=0.5, alpha=0.5, color='lightgrey')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_sectional_plots(df, 'ff_hike', num_quantiles=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_sectional_plots(df, 'mp_shock', num_quantiles=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
