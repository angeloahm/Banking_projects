{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call Reports Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Housekeeping and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from linearmodels import PanelOLS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/angel/Documents/Economics/Research/Banking Project/data/clean'\n",
    "path_output = 'C:/Users/angel/Documents/Economics/Research/Banking Project/data/output'\n",
    "\n",
    "# set colorblind theme for plots:\n",
    "sns.set_theme(context='notebook', style=\"ticks\", palette='colorblind')\n",
    "sns.set_color_codes(palette='colorblind')\n",
    "\n",
    "# Set path to be the directory:\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RCFD1754_x',\n",
       " 'RCFD1773_x',\n",
       " 'RCON1754_x',\n",
       " 'Unnamed: 79_x',\n",
       " 'Unnamed: 241_x',\n",
       " 'Unnamed: 88_x',\n",
       " 'RCFD1754_y',\n",
       " 'RCFD1773_y',\n",
       " 'RCON1754_y',\n",
       " 'Unnamed: 79_y',\n",
       " 'Unnamed: 241_y',\n",
       " 'Unnamed: 88_y']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read just the first row in the 'call_reports.csv' file:\n",
    "sample = pd.read_csv('call_reports.csv', nrows=1)\n",
    "\n",
    "# list the columns that have '_x' and '_y' in them:\n",
    "cols_x = [col for col in sample.columns if '_x' in col]\n",
    "cols_y = [col for col in sample.columns if '_y' in col]\n",
    "\n",
    "problem_cols = cols_x + cols_y\n",
    "problem_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the list of variables that will be used\n",
    "variables = ['RCON2170', 'RCFD2170',                                    # Total Assets\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCON2122', 'RCFD2122',                                    # Total Loans\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCON2200',                                                # Total Deposits\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCON1754', 'RCFD1754',                                    # HTM Securities Ammortized Cost\n",
    "             'RCFD1754_x', 'RCFD1754_y', 'RCON1754_x', 'RCON1754_y',\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCON1772',                                                # AFS Securities Ammortized Cost\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCFD1773_x', 'RCFD1773_y', 'RCON1773',                    # AFS Securities Fair Value\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCON0010', 'RCFD0010',                                    # Cash and balances due from depository institutions                                                \n",
    "             'RCON0071', 'RCON0081',                                    \n",
    "             'RCFD0071', 'RCFD0081',                                    \n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RIAD4073', 'RIAD4200', 'RIAD4185', 'RIAD4180', 'RIAD4172',# Income Variables\n",
    "             # ------------------------------------------------------------------------------------------------ \n",
    "             'Date', 'IDRSSD', 'Financial Institution Name'             # Identifier Variables\n",
    "             ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file that contains only the variables of interest, specify that the column 'Date' is a date:\n",
    "main = pd.read_csv('call_reports.csv', parse_dates = ['Date'], usecols=variables)\n",
    "main['Year'] = main['Date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---------------------------------------------- AMMORTIZED COST SECURITIES ----------------------------------------------\n",
      "Min Date in which RCFD1754_x or RCFD1754_y are not null: 2001-03-31 00:00:00\n",
      "Max Date in which RCFD1754_x or RCFD1754_y are not null: 2018-12-31 00:00:00\n",
      "Min Date in which RCFD1754 is not null: 2019-03-31 00:00:00\n",
      "Max Date in which RCFD1754 is not null: 2024-09-30 00:00:00\n",
      "------------------------------------------------------------------------------------------------\n",
      "Min Date in which RCON1754_x or RCON1754_y are not null: 2001-03-31 00:00:00\n",
      "Max Date in which RCON1754_x or RCON1754_y are not null: 2018-12-31 00:00:00\n",
      "Min Date in which RCON1754 is not null: 2019-03-31 00:00:00\n",
      "Max Date in which RCON1754 is not null: 2024-09-30 00:00:00\n",
      "------------------------------------------------------------------------------------------------\n",
      "The number of rows in which RCON1754_x and RCON1754_y are both reported and different is: 0\n",
      "The number of rows in which RCFD1754_x and RCFD1754_y are both reported and different is: 0\n"
     ]
    }
   ],
   "source": [
    "print(' ---------------------------------------------- AMMORTIZED COST SECURITIES ----------------------------------------------')\n",
    "\n",
    "# print the latest 'Date' for which either 'RCON1754_x' or 'RCON1754_y' is reported:\n",
    "print('Min Date in which RCFD1754_x or RCFD1754_y are not null:', \n",
    "      main[main['RCFD1754_x'].notnull() | main['RCFD1754_y'].notnull()]['Date'].min())\n",
    "print('Max Date in which RCFD1754_x or RCFD1754_y are not null:',\n",
    "      main[main['RCFD1754_x'].notnull() | main['RCFD1754_y'].notnull()]['Date'].max())\n",
    "\n",
    "print('Min Date in which RCFD1754 is not null:', main[main['RCFD1754'].notnull()]['Date'].min())\n",
    "print('Max Date in which RCFD1754 is not null:', main[main['RCFD1754'].notnull()]['Date'].max())\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------')\n",
    "\n",
    "# print the latest 'Date' for which either 'RCON1754_x' or 'RCON1754_y' is reported:\n",
    "print('Min Date in which RCON1754_x or RCON1754_y are not null:',\n",
    "      main[main['RCON1754_x'].notnull() | main['RCON1754_y'].notnull()]['Date'].min())\n",
    "print('Max Date in which RCON1754_x or RCON1754_y are not null:',\n",
    "      main[main['RCON1754_x'].notnull() | main['RCON1754_y'].notnull()]['Date'].max())\n",
    "\n",
    "print('Min Date in which RCON1754 is not null:',main[main['RCON1754'].notnull()]['Date'].min())\n",
    "print('Max Date in which RCON1754 is not null:', main[main['RCON1754'].notnull()]['Date'].max())\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------')\n",
    "\n",
    "print('The number of rows in which RCON1754_x and RCON1754_y are both reported and different is:',\n",
    "    len(main[main['RCON1754_x'].notnull() & main['RCON1754_y'].notnull() & (main['RCON1754_x']-main['RCON1754_y'] != 0)]))\n",
    "\n",
    "print('The number of rows in which RCFD1754_x and RCFD1754_y are both reported and different is:',\n",
    "    len(main[main['RCFD1754_x'].notnull() & main['RCFD1754_y'].notnull() & (main['RCFD1754_x']-main['RCFD1754_y'] != 0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---------------------------------------------- FAIR VALUE SECURITIES ----------------------------------------------\n",
      "Min Date in which RCFD1773_x and RCFD1773_y are not null: 2001-03-31 00:00:00\n",
      "Max Date in which RCFD1773_x and RCFD1773_y are not null: 2024-09-30 00:00:00\n",
      "For how many non-null obs. the difference between RCFD1773_x and RCFD1773_y is not zero: 0\n",
      "We can treat _x and _y as the same variable, since the difference is zero for all non-null obs.\n",
      "------------------------------------------------------------------------------------------------\n",
      "For how many non-null obs. RCFD1773_x and RCON1773 are both reported and different: 1466\n",
      "For how many non-null obs. RCFD1773_x and RCON1773 are both reported and the same: 3437\n",
      "For how many non-null obs. RCFD1773_x is reported and RCON1773 is not: 4686\n",
      "For how many non-null obs. RCFD1773_x is not reported and RCON1773 is: 630313\n",
      "------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(' ---------------------------------------------- FAIR VALUE SECURITIES ----------------------------------------------')\n",
    "\n",
    "# print the latest 'Date' for which either 'RCON1754_x' or 'RCON1754_y' is reported:\n",
    "print('Min Date in which RCFD1773_x and RCFD1773_y are not null:', \n",
    "      main[main['RCFD1773_x'].notnull() & main['RCFD1773_y'].notnull()]['Date'].min())\n",
    "print('Max Date in which RCFD1773_x and RCFD1773_y are not null:',\n",
    "      main[main['RCFD1773_x'].notnull() & main['RCFD1773_y'].notnull()]['Date'].max())\n",
    "\n",
    "print('For how many non-null obs. the difference between RCFD1773_x and RCFD1773_y is not zero:',\n",
    "      len(main[main['RCFD1773_x'].notnull() & \n",
    "     main['RCFD1773_y'].notnull() & \n",
    "     (main['RCFD1773_x']-main['RCFD1773_y'] != 0)]))\n",
    "print('We can treat _x and _y as the same variable, since the difference is zero for all non-null obs.')\n",
    "print('------------------------------------------------------------------------------------------------')\n",
    "# print the amount of obs for which RCFD1773_x and RCON1773 are both reported and different:\n",
    "print('For how many non-null obs. RCFD1773_x and RCON1773 are both reported and different:',\n",
    "      len(main[main['RCFD1773_x'].notnull() & \n",
    "     main['RCON1773'].notnull() & \n",
    "     (main['RCFD1773_x']-main['RCON1773'] != 0)]))\n",
    "# print the amount of obs for which RCFD1773_x and RCON1773 are both reported and are the same:\n",
    "print('For how many non-null obs. RCFD1773_x and RCON1773 are both reported and the same:',\n",
    "      len(main[main['RCFD1773_x'].notnull() & \n",
    "     main['RCON1773'].notnull() & \n",
    "     (main['RCFD1773_x']-main['RCON1773'] == 0)]))\n",
    "\n",
    "# print the amount of obs for which RCFD1773_x is reported and RCON1773 is not:\n",
    "print('For how many non-null obs. RCFD1773_x is reported and RCON1773 is not:',\n",
    "      len(main[main['RCFD1773_x'].notnull() & main['RCON1773'].isnull()]))\n",
    "\n",
    "# print the amount of obs for which RCFD1773_x is not reported and RCON1773 is:\n",
    "print('For how many non-null obs. RCFD1773_x is not reported and RCON1773 is:',\n",
    "      len(main[main['RCFD1773_x'].isnull() & main['RCON1773'].notnull()]))\n",
    "\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---------------------------------------------- Cash ----------------------------------------------\n",
      "For how many non-null obs. RCON0071 is reported and RCON0081 is not: 0\n",
      "For how many non-null obs. RCON0071 and RCON0081 are both reported: 630313\n",
      "For how many non-null obs. RCON0010, RCON0071, and RCON0081 are all reported: 472858\n",
      "For how many non-null obs. RCON0010 is reported and RCON0071 or RCON0081 are not: 9506\n",
      "For how many non-null obs. RCON0010 is not reported and RCON0071 and RCON0081 are: 157455\n",
      "For how many non-null obs. none of RCON0010, RCON0071, and RCON0081 are reported: 83\n",
      "------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(' ---------------------------------------------- Cash ----------------------------------------------')\n",
    "\n",
    "# print the obs in which 'RCON0071' is reported and 'RCON0081' is not:\n",
    "print('For how many non-null obs. RCON0071 is reported and RCON0081 is not:',\n",
    "      len(main[main['RCON0071'].notnull() & main['RCON0081'].isnull()]))\n",
    "\n",
    "# print the obs in which 'RCON0071' and 'RCON0081' are both reported:\n",
    "print('For how many non-null obs. RCON0071 and RCON0081 are both reported:',\n",
    "      len(main[main['RCON0071'].notnull() & main['RCON0081'].notnull()]))\n",
    "\n",
    "# print the obs in which 'RCON0010', 'RCON0071', and 'RCON0081' are all reported:\n",
    "print('For how many non-null obs. RCON0010, RCON0071, and RCON0081 are all reported:',\n",
    "      len(main[main['RCON0010'].notnull() & main['RCON0071'].notnull() & main['RCON0081'].notnull()]))\n",
    "\n",
    "# print the obs in which 'RCON0010' is reported and 'RCON0071' or 'RCON0081' are not:\n",
    "print('For how many non-null obs. RCON0010 is reported and RCON0071 or RCON0081 are not:',\n",
    "      len(main[main['RCON0010'].notnull() & (main['RCON0071'].isnull() | main['RCON0081'].isnull())]))\n",
    "\n",
    "# print the obs in which 'RCON0010' is not reported and 'RCON0071' and 'RCON0081' are:\n",
    "print('For how many non-null obs. RCON0010 is not reported and RCON0071 and RCON0081 are:',\n",
    "      len(main[main['RCON0010'].isnull() & main['RCON0071'].notnull() & main['RCON0081'].notnull()]))\n",
    "\n",
    "# print the obs in which none is reported:\n",
    "print('For how many non-null obs. none of RCON0010, RCON0071, and RCON0081 are reported:',\n",
    "      len(main[main['RCON0010'].isnull() & main['RCON0071'].isnull() & main['RCON0081'].isnull()]))\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Balance sheet definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "main['RCON1754_right'] = main['RCON1754_x'].combine_first(main['RCON1754'])\n",
    "main['RCFD1754_right'] = main['RCFD1754_x'].combine_first(main['RCFD1754'])\n",
    "\n",
    "# Create the new column '1754_right' and initialize with NaN\n",
    "main['1754_right'] = np.nan\n",
    "\n",
    "# Case 1: Both columns are not null\n",
    "mask_both_notnull = main['RCFD1754_right'].notna() & main['RCON1754_right'].notna()\n",
    "main.loc[mask_both_notnull, '1754_right'] = main.loc[mask_both_notnull, ['RCFD1754_right', 'RCON1754_right']].min(axis=1)\n",
    "\n",
    "# Case 2: Only one column is not null\n",
    "mask_col1_notnull = main['RCFD1754_right'].notna() & main['RCON1754_right'].isna()\n",
    "main.loc[mask_col1_notnull, '1754_right'] = main.loc[mask_col1_notnull, 'RCFD1754_right']\n",
    "\n",
    "mask_col2_notnull = main['RCON1754_right'].notna() & main['RCFD1754_right'].isna()\n",
    "main.loc[mask_col2_notnull, '1754_right'] = main.loc[mask_col2_notnull, 'RCON1754_right']\n",
    "\n",
    "# Case 3: Both columns are null (already handled by initialization to NaN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6.352160e+05\n",
      "mean     9.870183e+04\n",
      "std      4.310712e+06\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      2.419000e+03\n",
      "max      6.830540e+08\n",
      "Name: RCON1754_right, dtype: float64\n",
      "count    9.589000e+03\n",
      "mean     5.765784e+06\n",
      "std      3.534790e+07\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      1.258600e+04\n",
      "75%      3.546600e+05\n",
      "max      6.830540e+08\n",
      "Name: RCFD1754_right, dtype: float64\n",
      "count    6.399020e+05\n",
      "mean     1.072001e+05\n",
      "std      4.359587e+06\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      2.494000e+03\n",
      "max      6.830540e+08\n",
      "Name: 1754_right, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(main['RCON1754_right'].describe())\n",
    "print(main['RCFD1754_right'].describe())\n",
    "print(main['1754_right'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>RCON1754_right</th>\n",
       "      <th>RCFD1754_right</th>\n",
       "      <th>1754_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73687</th>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>17935977.0</td>\n",
       "      <td>19830720.0</td>\n",
       "      <td>17935977.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74601</th>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>852099.0</td>\n",
       "      <td>885365.0</td>\n",
       "      <td>852099.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74611</th>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>1247462.0</td>\n",
       "      <td>1247561.0</td>\n",
       "      <td>1247462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74706</th>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>11095.0</td>\n",
       "      <td>13014.0</td>\n",
       "      <td>11095.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74773</th>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28413.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637906</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>8485388.0</td>\n",
       "      <td>8485389.0</td>\n",
       "      <td>8485388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637919</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>47931.0</td>\n",
       "      <td>47946.0</td>\n",
       "      <td>47931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638179</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>4984830.0</td>\n",
       "      <td>4994835.0</td>\n",
       "      <td>4984830.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638399</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>358532000.0</td>\n",
       "      <td>369942000.0</td>\n",
       "      <td>358532000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639801</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>336653.0</td>\n",
       "      <td>336654.0</td>\n",
       "      <td>336653.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date  RCON1754_right  RCFD1754_right   1754_right\n",
       "73687  2010-03-31      17935977.0      19830720.0   17935977.0\n",
       "74601  2010-03-31        852099.0        885365.0     852099.0\n",
       "74611  2010-03-31       1247462.0       1247561.0    1247462.0\n",
       "74706  2010-03-31         11095.0         13014.0      11095.0\n",
       "74773  2010-03-31             0.0         28413.0          0.0\n",
       "...           ...             ...             ...          ...\n",
       "637906 2023-12-31       8485388.0       8485389.0    8485388.0\n",
       "637919 2023-12-31         47931.0         47946.0      47931.0\n",
       "638179 2023-12-31       4984830.0       4994835.0    4984830.0\n",
       "638399 2023-12-31     358532000.0     369942000.0  358532000.0\n",
       "639801 2023-12-31        336653.0        336654.0     336653.0\n",
       "\n",
       "[760 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main[main['RCON1754_right'].notnull() & \n",
    "     main['RCFD1754_right'].notnull() & \n",
    "     (main['RCON1754_right']-main['RCFD1754_right'] != 0)][['Date', 'RCON1754_right', 'RCFD1754_right', '1754_right']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6.192770e+05\n",
      "mean     2.205622e+05\n",
      "std      4.532424e+06\n",
      "min      1.000000e+00\n",
      "25%      1.113100e+04\n",
      "50%      2.878200e+04\n",
      "75%      7.518300e+04\n",
      "max      6.830540e+08\n",
      "Name: Securities AC, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create 'Securities AC' summing RCON1754 and RCON1772. If both are NaN, fill with NaN. If only one is available, use that one. If both \n",
    "# are available sum them:\n",
    "main['Securities AC'] = main[['1754_right', 'RCON1772']].apply(\n",
    "    lambda row: np.nan if pd.isna(row['1754_right']) and pd.isna(row['RCON1772']) else (row.fillna(0).sum()),\n",
    "    axis=1\n",
    ")\n",
    "main['Securities AC'] = main['Securities AC'].mask(main['Securities AC'] <= 0, np.nan)\n",
    "print(main['Securities AC'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    5.860780e+05\n",
      "mean     3.501374e+05\n",
      "std      5.407126e+06\n",
      "min      1.000000e+00\n",
      "25%      1.042600e+04\n",
      "50%      2.752400e+04\n",
      "75%      7.273300e+04\n",
      "max      4.479270e+08\n",
      "Name: 1773_right, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "main['1773_right'] = main['RCON1773'].combine_first(main['RCFD1773_x'])\n",
    "# mask the <= 0 values with NaN:\n",
    "main['1773_right'] = main['1773_right'].mask(main['1773_right'] <= 0, np.nan)\n",
    "print(main['1773_right'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6.225050e+05\n",
      "mean     4.398445e+05\n",
      "std      8.449511e+06\n",
      "min      1.000000e+00\n",
      "25%      1.129900e+04\n",
      "50%      2.919000e+04\n",
      "75%      7.686000e+04\n",
      "max      9.299180e+08\n",
      "Name: Total Securities, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Define 'Total Securities' using the sum of '1754_right' and '1773_right' (amortized cost + fair value):\n",
    "main['Total Securities'] = main[['1754_right', '1773_right']].apply(\n",
    "    lambda row: np.nan if pd.isna(row['1754_right']) and pd.isna(row['1773_right']) else (row.fillna(0).sum()),\n",
    "    axis=1\n",
    ")\n",
    "main['Total Securities'] = main['Total Securities'].mask(main['Total Securities'] <= 0, np.nan)\n",
    "print(main['Total Securities'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6.351330e+05\n",
      "mean     9.755156e+05\n",
      "std      1.244043e+07\n",
      "min      0.000000e+00\n",
      "25%      6.975000e+04\n",
      "50%      1.522690e+05\n",
      "75%      3.686870e+05\n",
      "max      1.445545e+09\n",
      "Name: RCON2170, dtype: float64\n",
      "count    9.589000e+03\n",
      "mean     1.036920e+08\n",
      "std      3.150145e+08\n",
      "min      4.264000e+03\n",
      "25%      1.455077e+06\n",
      "50%      1.235404e+07\n",
      "75%      6.758438e+07\n",
      "max      3.584105e+09\n",
      "Name: RCFD2170, dtype: float64\n",
      "count    6.399020e+05\n",
      "mean     2.114301e+06\n",
      "std      3.944563e+07\n",
      "min      0.000000e+00\n",
      "25%      7.020225e+04\n",
      "50%      1.539290e+05\n",
      "75%      3.772038e+05\n",
      "max      3.584105e+09\n",
      "Name: Total Assets, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create 'Total Assets' variable. If the bank fills the FFIEC41 (only RCON series available). Large banks may also have the \n",
    "# RCFD series available. If both are NaN, fill with NaN. If both are available, use the RCON series. If only RCFD is available,\n",
    "# use RCFD. \n",
    "main['Total Assets'] = main['RCON2170'].combine_first(main['RCFD2170'])\n",
    "\n",
    "print(main['RCON2170'].describe())\n",
    "print(main['RCFD2170'].describe())\n",
    "print(main['Total Assets'].describe())\n",
    "\n",
    "main['Total Assets'] = main['Total Assets'].mask(main['Total Assets'] == 0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.loc[:, 'Securities Share'] = main['Total Securities'] / main['Total Assets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6.225050e+05\n",
       "mean     2.269777e-01\n",
       "std      1.569241e-01\n",
       "min      7.399239e-09\n",
       "25%      1.093705e-01\n",
       "50%      1.981180e-01\n",
       "75%      3.137277e-01\n",
       "max      2.642542e+00\n",
       "Name: Securities Share, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main['Securities Share'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>IDRSSD</th>\n",
       "      <th>Financial Institution Name</th>\n",
       "      <th>Total Securities</th>\n",
       "      <th>Total Assets</th>\n",
       "      <th>Securities Share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337820</th>\n",
       "      <td>2002-09-30</td>\n",
       "      <td>656733.0</td>\n",
       "      <td>MB FINANCIAL BANK, NATIONAL ASSOCIATION</td>\n",
       "      <td>852196.0</td>\n",
       "      <td>322491.0</td>\n",
       "      <td>2.642542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date    IDRSSD               Financial Institution Name  \\\n",
       "337820 2002-09-30  656733.0  MB FINANCIAL BANK, NATIONAL ASSOCIATION   \n",
       "\n",
       "        Total Securities  Total Assets  Securities Share  \n",
       "337820          852196.0      322491.0          2.642542  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main[main['Securities Share']>1][['Date', 'IDRSSD', 'Financial Institution Name', 'Total Securities', 'Total Assets', 'Securities Share']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6.399020e+05\n",
      "mean     1.115855e+06\n",
      "std      1.638202e+07\n",
      "min      0.000000e+00\n",
      "25%      3.991900e+04\n",
      "50%      9.623600e+04\n",
      "75%      2.468268e+05\n",
      "max      1.219816e+09\n",
      "Name: RCON2122, dtype: float64\n",
      "count    9.589000e+03\n",
      "mean     5.150065e+07\n",
      "std      1.402738e+08\n",
      "min      0.000000e+00\n",
      "25%      7.367520e+05\n",
      "50%      7.377421e+06\n",
      "75%      3.715684e+07\n",
      "max      1.353071e+09\n",
      "Name: RCFD2122, dtype: float64\n",
      "count    6.399020e+05\n",
      "mean     1.115855e+06\n",
      "std      1.638202e+07\n",
      "min      0.000000e+00\n",
      "25%      3.991900e+04\n",
      "50%      9.623600e+04\n",
      "75%      2.468268e+05\n",
      "max      1.219816e+09\n",
      "Name: Total Loans, dtype: float64\n",
      "count    6.294910e+05\n",
      "mean     1.134310e+06\n",
      "std      1.651630e+07\n",
      "min      1.000000e+00\n",
      "25%      4.195200e+04\n",
      "50%      9.887900e+04\n",
      "75%      2.515910e+05\n",
      "max      1.219816e+09\n",
      "Name: Total Loans, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angel\\AppData\\Local\\Temp\\ipykernel_21072\\2193418771.py:1: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  main['Total Loans'] = main['RCON2122'].combine_first(main['RCFD2122'])\n"
     ]
    }
   ],
   "source": [
    "main['Total Loans'] = main['RCON2122'].combine_first(main['RCFD2122'])\n",
    "\n",
    "print(main['RCON2122'].describe())\n",
    "print(main['RCFD2122'].describe())\n",
    "print(main['Total Loans'].describe())\n",
    "\n",
    "main['Total Loans'] = main['Total Loans'].mask(main['Total Loans'] == 0, np.nan)\n",
    "print(main['Total Loans'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6.333120e+05\n",
      "mean     1.459541e+06\n",
      "std      2.552438e+07\n",
      "min      1.000000e+00\n",
      "25%      5.953400e+04\n",
      "50%      1.298275e+05\n",
      "75%      3.129310e+05\n",
      "max      2.201118e+09\n",
      "Name: Total Deposits, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create 'Total Deposits'\n",
    "main.rename(columns = {'RCON2200':'Total Deposits'}, inplace = True)\n",
    "main['Total Deposits'] = main['Total Deposits'].mask(main['Total Deposits'] == 0, np.nan)\n",
    "print(main['Total Deposits'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6.390710e+05\n",
      "mean     1.715995e+05\n",
      "std      4.239690e+06\n",
      "min      1.000000e+00\n",
      "25%      3.374000e+03\n",
      "50%      8.435000e+03\n",
      "75%      2.253550e+04\n",
      "max      5.436850e+08\n",
      "Name: Cash, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create 'Cash' summing RCON0020 and RCON0080:\n",
    "main['Cash'] = (main['RCON0071']+main['RCON0081']).combine_first(main['RCON0010'])\n",
    "main['Cash'] = main['Cash'].mask(main['Cash'] <= 0, np.nan)\n",
    "print(main['Cash'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6.390710e+05\n",
      "mean     8.074127e-02\n",
      "std      9.582002e-02\n",
      "min      3.945225e-07\n",
      "25%      2.846594e-02\n",
      "50%      4.894672e-02\n",
      "75%      9.637697e-02\n",
      "max      1.000000e+00\n",
      "Name: Cash Share, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create 'Cash Share' variable:\n",
    "main.loc[:, 'Cash Share'] = main['Cash'] / main['Total Assets']\n",
    "print(main['Cash Share'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6.293540e+05\n",
      "mean     6.335982e-01\n",
      "std      1.623766e-01\n",
      "min      5.649079e-07\n",
      "25%      5.379652e-01\n",
      "50%      6.576725e-01\n",
      "75%      7.530094e-01\n",
      "max      9.998557e-01\n",
      "Name: Loans Share, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "main.loc[:, 'Loans Share'] = main['Total Loans'] / main['Total Assets']\n",
    "#mask loans share > 1 with NaN:\n",
    "main['Loans Share'] = main['Loans Share'].mask(main['Loans Share'] > 1, np.nan)\n",
    "print(main['Loans Share'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Income Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the variable above avoiding the SettingWithCopyWarning:\n",
    "main.loc[:, 'Deposit Expenditure'] = (main['RIAD4073'].fillna(0) - main['RIAD4200'].fillna(0) - main['RIAD4185'].fillna(0) - \n",
    "                                      main['RIAD4180'].fillna(0) - main['RIAD4172'].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.loc[:, 'Actual Deposit Exp'] = main.groupby(['IDRSSD', 'Year'])['Deposit Expenditure'].diff().fillna(main['Deposit Expenditure'])\n",
    "main.loc[:, 'Actual Deposit Exp'] = main['Actual Deposit Exp'].mask(main['Actual Deposit Exp'] <= 0, np.nan)\n",
    "main['Actual Deposit Exp'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute deposit rates:\n",
    "main.loc[:,'Deposit Rate'] = main['Actual Deposit Exp'] / main['Total Deposits']\n",
    "print(main['Deposit Rate'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an extra column in df3 with the avg. deposit rate per Date:\n",
    "main.loc[:,'Avg. Deposit Rate'] = main.groupby('Date')['Deposit Rate'].transform('mean')\n",
    "main.loc[:,'Std. Deposit Rate'] = main.groupby('Date')['Deposit Rate'].transform('std')\n",
    "main.loc[:,'R_hat'] = (main['Deposit Rate'] - main['Avg. Deposit Rate']) / main['Std. Deposit Rate']\n",
    "main['R_hat'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_panel = 0\n",
    "\n",
    "if balanced_panel == 1:\n",
    "\n",
    "    # Step 1: Count the total number of unique dates in the dataset\n",
    "    total_dates = main['Date'].nunique()\n",
    "    print('Number of dates:', total_dates)\n",
    "\n",
    "    # Step 2: Count the number of unique dates each bank shows up\n",
    "    bank_date_counts = main.groupby('IDRSSD')['Date'].nunique()\n",
    "    print('Banks that show up in all dates:', sum(bank_date_counts==total_dates))\n",
    "\n",
    "    # Step 3: Identify banks that are present in all dates with positive 'Total Deposit':\n",
    "    banks = bank_date_counts[bank_date_counts == total_dates].index\n",
    "    main = main[main['IDRSSD'].isin(banks)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVB Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVB story: \n",
    "svb_date = main[(main['Date'] == '2022-12-31')]\n",
    "# create a log of the total assets using .loc:\n",
    "svb_date.loc[:, 'Log Assets'] = np.log(svb_date['Total Assets'])\n",
    "svb_share = svb_date[svb_date['IDRSSD'] == 802866]['Securities Share'].values[0]\n",
    "svb_share_cash = svb_date[svb_date['IDRSSD'] == 802866]['Cash Share'].values[0]\n",
    "svb_share_loans = svb_date[svb_date['IDRSSD'] == 802866]['Loans Share'].values[0]\n",
    "sns.histplot(data=svb_date, x='Securities Share', bins=25, kde=True, stat='density')\n",
    "# plot a vertical line at the ID=802866 (SVB):\n",
    "plt.axvline(x=svb_date[svb_date['IDRSSD'] == 802866]['Securities Share'].values[0], color='red', linestyle='--', linewidth=2)\n",
    "# print the value of the SVB securities share:\n",
    "plt.text(x=0.6,\n",
    "          y=2.5, s=f'SVB: {np.round(svb_share,2)}', color='red')\n",
    "plt.title('Distribution of Securities Share in at 12/31/2022')\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=svb_date, x='Log Assets', bins=25, kde=True, stat='density')\n",
    "# plot a vertical line at the ID=802866 (SVB):\n",
    "plt.axvline(x=svb_date[svb_date['IDRSSD'] == 802866]['Log Assets'].values[0], color='red', linestyle='--', linewidth=2)\n",
    "# print the value of the SVB securities share:\n",
    "plt.title('Distribution of Log Total Assets in at 12/31/2022')\n",
    "plt.show()\n",
    "\n",
    "# plot the distribution of the securities share for the banks with log assets larger than SVB:\n",
    "sns.histplot(data=svb_date[svb_date['Log Assets'] >= svb_date[svb_date['IDRSSD'] == 802866]['Log Assets'].values[0]],\n",
    "              x='Securities Share', bins=5, kde=False, stat='density')\n",
    "plt.title('Distribution of Securities Share for Banks with Log Assets >= SVB')\n",
    "# plot a vertical line at the ID=802866 (SVB):\n",
    "plt.axvline(x=svb_date[svb_date['IDRSSD'] == 802866]['Securities Share'].values[0], color='red', linestyle='--', linewidth=2)\n",
    "# print the value of the SVB securities share:\n",
    "plt.text(x=0.6,\n",
    "          y=2.5, s=f'SVB: {np.round(svb_share,2)}', color='red')\n",
    "plt.xlabel('Securities Share')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# plot a histogram of the 'Cash Share' variable for banks with 'Securities Share' greater than SVB:\n",
    "sns.histplot(data=svb_date[svb_date['Securities Share'] >= svb_share], x='Cash Share', bins=25, kde=True, stat='density')\n",
    "plt.title('Distribution of Cash Share for Banks with Securities Share >= SVB')\n",
    "# plot a vertical line at the ID=802866 (SVB):\n",
    "plt.axvline(x=svb_date[svb_date['IDRSSD'] == 802866]['Cash Share'].values[0], color='red', linestyle='--', linewidth=2)\n",
    "# print the value of the SVB securities share:\n",
    "plt.text(x=0.1,\n",
    "          y=10, s=f'SVB: {np.round(svb_share_cash,2)}', color='red')\n",
    "\n",
    "plt.xlabel('Cash Share')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# plot a histogram of the 'Loan Share' variable for banks with 'Securities Share' greater than SVB:\n",
    "sns.histplot(data=svb_date[svb_date['Securities Share'] >= svb_share], x='Loans Share', bins=10, kde=True, stat='density')\n",
    "plt.title('Distribution of Loans Share for Banks with Securities Share >= SVB')\n",
    "# plot a vertical line at the ID=802866 (SVB):\n",
    "plt.axvline(x=svb_date[svb_date['IDRSSD'] == 802866]['Loans Share'].values[0], color='red', linestyle='--', linewidth=2)\n",
    "# print the value of the SVB securities share:\n",
    "plt.text(x=0.1,\n",
    "          y=4, s=f'SVB: {np.round(svb_share_loans,2)}', color='red')\n",
    "plt.xlabel('Loans Share')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# plot the average securities share by year:\n",
    "sns.lineplot(data=main.groupby('Year').agg({'Securities Share': 'mean'}).reset_index(), x='Year', y='Securities Share')\n",
    "plt.title('Average Securities Share by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Securities Share')\n",
    "plt.ylim(0.1, 0.35)\n",
    "plt.grid(True, linestyle='--', alpha=0.5, linewidth=0.5, color='lightgrey')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load monetary policy shock data:\n",
    "mp_shocks = pd.read_csv('brw-shock-series.csv')\n",
    "\n",
    "# Drop column that has 'Unnamed' in it:\n",
    "mp_shocks = mp_shocks.loc[:, ~mp_shocks.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# keep only the first 4 columns:\n",
    "mp_shocks = mp_shocks.iloc[:, 0:4]\n",
    "\n",
    "# rename columns:\n",
    "mp_shocks.columns = mp_shocks.columns.str.replace(' (updated)', '')\n",
    "mp_shocks.loc[:, 'month'] = mp_shocks['month'].str.replace('m', '-')\n",
    "mp_shocks = mp_shocks[['month', 'BRW_monthly']]\n",
    "\n",
    "# drop the 'NaT' row:\n",
    "mp_shocks = mp_shocks.dropna()\n",
    "mp_shocks['month'] = pd.to_datetime(mp_shocks['month'], format='%Y-%m')\n",
    "# compute the quarterly average of the monthly shocks:\n",
    "mp_shocks['quarter'] = mp_shocks['month'].dt.to_period('Q')\n",
    "mp_shocks['BRW_quarterly'] = mp_shocks.groupby('quarter')['BRW_monthly'].transform('sum')\n",
    "\n",
    "# keep only one observation for 'month' and 'BRW_quarterly' for each quarter:\n",
    "mp_shocks = mp_shocks.drop_duplicates(subset='quarter', keep='first')\n",
    "mp_shocks['Date'] = mp_shocks['month'] - pd.DateOffset(days = 1)\n",
    "\n",
    "mp_shocks = mp_shocks[['Date', 'BRW_quarterly']]\n",
    "mp_shocks.rename(columns={'BRW_quarterly': 'MP Shocks'}, inplace=True)\n",
    "\n",
    "mp_shocks.loc[:,'Positive FF Shock'] = 0\n",
    "mp_shocks.loc[mp_shocks['MP Shocks'] > 0, 'Positive FF Shock'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excess Bond Premium data:\n",
    "ebp = pd.read_csv('ebp_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fredgraph data:\n",
    "aggregates = pd.read_csv('fredgraph.csv')\n",
    "\n",
    "# rename some variables\n",
    "aggregates.rename(columns = {'DATE':'Date', \n",
    "                             'NGDPSAXDCUSQ': 'Nominal GDP', \n",
    "                             'CPIAUCSL_NBD19840101': 'CPI',\n",
    "                             'GDPDEF': 'Deflator'}, inplace = True)\n",
    "\n",
    "# drop the first row:\n",
    "aggregates = aggregates.iloc[1:,:]\n",
    "\n",
    "# for all entries with '.' substitute with NaN:\n",
    "aggregates = aggregates.replace('.', np.nan)\n",
    "\n",
    "# make 'Deflator' and 'Nominal GDP' floats:\n",
    "aggregates['Deflator'] = aggregates['Deflator'].astype(float)\n",
    "aggregates['Nominal GDP'] = aggregates['Nominal GDP'].astype(float)\n",
    "aggregates['FEDFUNDS'] = aggregates['FEDFUNDS'].astype(float)\n",
    "aggregates['CPI'] = aggregates['CPI'].astype(float)\n",
    "\n",
    "# make 'Date' a datetime object:\n",
    "aggregates['Date'] = pd.to_datetime(aggregates['Date'])\n",
    "\n",
    "# create 'Real GDP' variable:\n",
    "aggregates['Real GDP'] = aggregates['Nominal GDP'] / aggregates['CPI'] * 100\n",
    "aggregates = aggregates.dropna()\n",
    "\n",
    "# adjust the FF rate: \n",
    "aggregates['FEDFUNDS'] = aggregates['FEDFUNDS'] / 100\n",
    "aggregates['Date'] = aggregates['Date'] - pd.DateOffset(days = 1)\n",
    "\n",
    "# create 'Inflation' as the growth rate of the CPI:\n",
    "aggregates['Inflation'] = aggregates['CPI'].pct_change(fill_method=None)\n",
    "\n",
    "# create a variable named 'High Inflation' as 1 if the inflation is above the average, and 0 otherwise:\n",
    "aggregates['High Inflation'] = 0\n",
    "aggregates.loc[aggregates['Inflation'] > aggregates['Inflation'].mean(), 'High Inflation'] = 1\n",
    "\n",
    "# create a variable named 'FF Hike' as 1 if the FF rate increased, and 0 otherwise:\n",
    "aggregates['FF Hike'] = 0\n",
    "aggregates.loc[aggregates['FEDFUNDS'] > aggregates['FEDFUNDS'].shift(1), 'FF Hike'] = 1\n",
    "\n",
    "param = 1600\n",
    "\n",
    "# De-trend the variables using an HP filter:\n",
    "aggregates['De-trended Real GDP'] = sm.tsa.filters.hpfilter(np.log(aggregates['Real GDP']), lamb=param)[0]\n",
    "\n",
    "# create a variable named 'Boom' that is 1, if the De-trended Real GDP is above 0, and 0 otherwise:\n",
    "aggregates['Recession'] = 0\n",
    "aggregates.loc[aggregates['De-trended Real GDP'] < 0, 'Recession'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data on mergers and acquisitions:\n",
    "transformations = pd.read_csv('CSV_TRANSFORMATIONS.csv')\n",
    "\n",
    "# rename the columns:\n",
    "transformations = transformations.rename(columns={'#ID_RSSD_PREDECESSOR': 'Predecessor ID', \n",
    "                                                  'ID_RSSD_SUCCESSOR': 'Successor ID',\n",
    "                                                 'DT_TRANS': 'Transaction Date',\n",
    "                                                 'TRNSFM_CD': 'Transaction Code',})\n",
    "\n",
    "# convert the 'transaction_date' to datetime format:\n",
    "transformations['Transaction Date'] = pd.to_datetime(transformations['Transaction Date'], format='%Y%m%d')\n",
    "transformations = transformations[['Predecessor ID', 'Successor ID', 'Transaction Date', 'Transaction Code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main = pd.merge(main, aggregates, how = 'left', on = 'Date').sort_values(by = ['IDRSSD', 'Date'])\n",
    "#main = pd.merge(main, mp_shocks, how = 'left', on = 'Date').sort_values(by = ['IDRSSD', 'Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_growth(df, transformations, window=1):\n",
    "    \"\"\"\n",
    "    Compute the log difference of deposits while accounting for mergers, acquisitions, and failures.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): Dataframe containing bank-level balance sheet data.\n",
    "    - transformations (pd.DataFrame): Dataframe containing information about transformations.\n",
    "    - window (int): Number of quarters before and after a transaction to set as NaN for growth rate.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The updated 'df' with a 'deposit_growth' column.\n",
    "    \"\"\"\n",
    "    # Sort the dataframe by bank ID and date to ensure proper lag calculation\n",
    "    df = df.sort_values(by=['IDRSSD', 'Date'])\n",
    "    df['Real Deposits'] = df['Total Deposits'] / df['CPI'] * 100\n",
    "    df['Real Loans'] = df['Total Loans'] / df['CPI'] * 100\n",
    "\n",
    "\n",
    "    # Calculate log difference (log growth rate) of deposits\n",
    "    df['Deposit_Growth'] = df.groupby('IDRSSD')['Real Deposits'].transform(lambda x: np.log(x).diff())\n",
    "    df['Loan_Growth'] = df.groupby('IDRSSD')['Real Loans'].transform(lambda x: np.log(x).diff())\n",
    "    \n",
    "    # Create a mask to identify rows to be set to NaN\n",
    "    for _, row in transformations.iterrows():\n",
    "        predecessor_id = row['Predecessor ID']\n",
    "        successor_id = row['Successor ID']\n",
    "        transaction_date = row['Transaction Date']\n",
    "        \n",
    "        # Identify date range around the transaction\n",
    "        start_date = transaction_date - pd.DateOffset(months=3 * window)\n",
    "        end_date = transaction_date + pd.DateOffset(months=3 * window)\n",
    "        \n",
    "        # Apply NaN to the specified window for predecessor and successor banks\n",
    "        df.loc[\n",
    "            ((df['IDRSSD'] == predecessor_id) | (df['IDRSSD'] == successor_id)) & \n",
    "            (df['Date'].between(start_date, end_date)),\n",
    "            'Deposit_Growth'\n",
    "        ] = np.nan\n",
    "\n",
    "        df.loc[\n",
    "            ((df['IDRSSD'] == predecessor_id) | (df['IDRSSD'] == successor_id)) & \n",
    "            (df['Date'].between(start_date, end_date)),\n",
    "            'Loan_Growth'\n",
    "        ] = np.nan\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Define function to compute binned averages using qcut\n",
    "def binned_scatter(x, y, q, label):\n",
    "    # Create quantile bins using qcut\n",
    "    x_binned, bin_edges = pd.qcut(x, q=q, retbins=True, duplicates='drop')\n",
    "    bin_centers = [x[(x_binned == interval)].mean() for interval in x_binned.unique()]\n",
    "    binned_means = [y[x_binned == interval].mean() for interval in x_binned.unique()]\n",
    "    \n",
    "    # Plot the binned means\n",
    "    plt.scatter(bin_centers, binned_means, label=label, alpha=0.7, s=50)\n",
    "\n",
    "    # Add a 45-degree line for reference:\n",
    "    #plt.plot([min(x), max(x)], [min(x), max(x)], linestyle='--', color='black', alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main[[ 'IDRSSD', 'Date', 'Financial Institution Name',             # Dates and IDS \n",
    "            'Total Deposits', 'Deposit Share', 'Total Assets',          # Bank specific quantity variables\n",
    "            'Total Loans',\n",
    "            'Deposit Rate', 'Deposit Spread',                           # Bank specific rate variable\n",
    "            'Cash', 'Securities AC',                                    # Bank specific asset variables\n",
    "            'FEDFUNDS', 'High Inflation', 'FF Hike', 'Recession',\n",
    "            'CPI', 'Positive FF Shock'                                  # Macro variables\n",
    "            ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'Securities Share'] = df['Securities AC'] / df['Total Assets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svb_securities = df[(df['IDRSSD'] == 802866) & (df['Date'] == '2022-12-31')]['Securities Share'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell me the IDs of the banks that have a 'Securities Share' above svb_securities:\n",
    "right_tail_banks = df[(df['Date'] == '2022-12-31') & \n",
    "                      (df[df['Date'] == '2022-12-31']['Securities Share'] > svb_securities)]['IDRSSD'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_tail_df = df[ (df['Date'] == '2022-12-31') & \n",
    "    (df['IDRSSD'].isin(right_tail_banks))][['Financial Institution Name', 'Total Assets', 'Total Deposits']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Date'] == '2022-12-31')][['Financial Institution Name', 'Total Assets', 'Total Deposits']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_tail_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of securities share for 03/31/2023:\n",
    "sns.histplot(df[df['Date'] == '2022-12-31']['Securities Share'], bins=20, kde=True)\n",
    "# add a vertical line for the bank with IDRSSD=802866:\n",
    "plt.axvline(x=df[(df['IDRSSD'] == 802866) & (df['Date'] == '2022-12-31')]['Securities Share'].values[0], \n",
    "            color='red', linestyle='--', linewidth=2)       \n",
    "plt.title('Distribution of Securities Share on 12/31/2022')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the correlation between FF Hike and Positive FF Shock:\n",
    "df[['FF Hike', 'Positive FF Shock']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = compute_growth(df, transformations, window=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Loan_Growth'].describe())\n",
    "print(df['Loan_Growth'].quantile([0.01, 0.99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Deposit_Growth'].describe())\n",
    "print(df['Deposit_Growth'].quantile([0.01, 0.99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask the outliers (top and bottom 0.1%) of the distribution of 'Deposit Growth':\n",
    "df['Deposit_Growth'] = df['Deposit_Growth'].mask((df['Deposit_Growth'] < df['Deposit_Growth'].quantile(0.01)) | \n",
    "                                                 (df['Deposit_Growth'] > df['Deposit_Growth'].quantile(0.99)), np.nan)\n",
    "\n",
    "df['Loan_Growth'] = df['Loan_Growth'].mask((df['Loan_Growth'] < df['Loan_Growth'].quantile(0.01)) | \n",
    "                                                 (df['Loan_Growth'] > df['Loan_Growth'].quantile(0.99)), np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Securities Growth'] = df.groupby('IDRSSD')['Securities AC'].pct_change(fill_method=None)\n",
    "print(df['Securities Growth'].describe())\n",
    "# if the 'Securities Growth' is in either top or bottom 1% of the distribution, set it to NaN:\n",
    "df['Securities Growth'] = df['Securities Growth'].mask((df['Securities Growth'] < df['Securities Growth'].quantile(0.01)) | (df['Securities Growth'] > df['Securities Growth'].quantile(0.99)))\n",
    "print(df['Securities Growth'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Real Cash'] = df['Cash'] / df['CPI'] * 100\n",
    "df['Cash Growth'] = df.groupby('IDRSSD')['Real Cash'].pct_change(fill_method=None)\n",
    "print(df['Cash Growth'].describe())\n",
    "# if the 'Securities Growth' is in either top or bottom 1% of the distribution, set it to NaN:\n",
    "df['Cash Growth'] = df['Cash Growth'].mask((df['Cash Growth'] < df['Cash Growth'].quantile(0.01)) | (df['Cash Growth'] > df['Cash Growth'].quantile(0.99)))\n",
    "print(df['Cash Growth'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_sectional_plots(  df,                     # Dataframe with bank-level data \n",
    "                            criteria,               # Criteria to define the interest rate shock\n",
    "                            num_quantiles=100):     # Number of quantiles for the binned scatter plot\n",
    "\n",
    "    # Define the interest rate criteria:\n",
    "    # 1. 'ff_hike': FF Hike is a simple increase in the FFR.\n",
    "    # 2. 'mp_shock': MP Shock is a positive shock to the FFR.\n",
    "    if criteria == 'ff_hike':\n",
    "        # Filter conditions for Expansion and Contraction\n",
    "        expansion_condition = (\n",
    "                              (df['Recession'] == 0) & \n",
    "                              (df['FF Hike'] == 1) &\n",
    "                              (df['High Inflation'] == 1)\n",
    "                              )\n",
    "        contraction_condition = (\n",
    "                                (df['Recession'] == 1) &\n",
    "                                (df['FF Hike'] == 1) &\n",
    "                                (df['High Inflation'] == 1)\n",
    "                                )\n",
    "\n",
    "    elif criteria == 'mp_shock':\n",
    "        # Filter conditions for Expansion and Contraction\n",
    "        expansion_condition = (\n",
    "                            (df['Recession'] == 0) &\n",
    "                            (df['Positive FF Shock'] == 1) &\n",
    "                            (df['High Inflation'] == 1)\n",
    "                            )\n",
    "        contraction_condition = (\n",
    "                            (df['Recession'] == 1) &\n",
    "                            (df['Positive FF Shock'] == 1) & \n",
    "                            (df['High Inflation'] == 1)\n",
    "                            )\n",
    "\n",
    "    else:\n",
    "        print('Criteria not found')\n",
    "        return None\n",
    "    \n",
    "    # --------------------------------- Histograms --------------------------------- #\n",
    "\n",
    "    # make a histogram of the de-trended loans when the inflation is high, FF hike and Boom vs. Recession:\n",
    "    lin = np.linspace(-0.25, 0.25, 150)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(df[expansion_condition]['Loan_Growth'], \n",
    "                label='Expansion', bins=lin, stat='density', alpha=0.6)\n",
    "    plt.axvline(df[expansion_condition]['Loan_Growth'].mean(), linestyle='--', linewidth=2, color='blue')\n",
    "    sns.histplot(df[contraction_condition]['Loan_Growth'], \n",
    "                label='Contraction', bins=lin, alpha=0.6, stat='density')\n",
    "    plt.axvline(df[contraction_condition]['Loan_Growth'].mean(), linestyle='--', linewidth=2, color='orange')\n",
    "    plt.title('Loan Growth (High Inflation, FF Hike)')\n",
    "    plt.xlabel('Loan Growth')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    # print the std deviation of both distributions in the (-0.2,8) coordinate:\n",
    "    plt.text(0.1, 7, 'Mean Expansion:             ' + str(round(df[expansion_condition]['Loan_Growth'].mean(), 4)))\n",
    "    plt.text(0.1, 6.5, 'Std. Expansion:             ' + str(round(df[expansion_condition]['Loan_Growth'].std(), 4)))\n",
    "    plt.text(0.1, 6, 'Mean Contraction:           ' + str(round(df[contraction_condition]['Loan_Growth'].mean(), 4)))\n",
    "    plt.text(0.1, 5.5, 'Std. Contraction:           ' + str(round(df[contraction_condition]['Loan_Growth'].std(), 4)))\n",
    "    plt.grid(True, which='both', linestyle='--', lw=0.5, alpha=0.5, color='lightgrey')\n",
    "    plt.xlim(-0.13, 0.22)\n",
    "    plt.show()\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    lin = np.linspace(-0.25, 0.25, 150)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(df[expansion_condition]['Deposit_Growth'], \n",
    "                label='Expansion', bins=lin, stat='density', alpha=0.6)\n",
    "    plt.axvline(df[expansion_condition]['Deposit_Growth'].mean(), linestyle='--', linewidth=2, color='blue')\n",
    "    sns.histplot(df[contraction_condition]['Deposit_Growth'], \n",
    "                label='Contraction', bins=lin, alpha=0.6, stat='density')\n",
    "    plt.axvline(df[contraction_condition]['Deposit_Growth'].mean(), linestyle='--', linewidth=2, color='orange')\n",
    "    plt.title('Deposits Growth (High Inflation, FF Hike)')\n",
    "    plt.xlabel('Deposits Growth')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    # print the std deviation of both distributions in the (-0.2,8) coordinate:\n",
    "    plt.text(0.1, 7, 'Mean Expansion:             ' + str(round(df[expansion_condition]['Deposit_Growth'].mean(), 4)))\n",
    "    plt.text(0.1, 6.5, 'Std. Expansion:             ' + str(round(df[expansion_condition]['Deposit_Growth'].std(), 4)))\n",
    "    plt.text(0.1, 6, 'Mean Contraction:           ' + str(round(df[contraction_condition]['Deposit_Growth'].mean(), 4)))\n",
    "    plt.text(0.1, 5.5, 'Std. Contraction:           ' + str(round(df[contraction_condition]['Deposit_Growth'].std(), 4)))\n",
    "    plt.grid(True, which='both', linestyle='--', lw=0.5, alpha=0.5, color='lightgrey')\n",
    "    plt.xlim(-0.13, 0.22)\n",
    "    plt.show()\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    # make a histogram of the de-trended loans when the inflation is high, FF hike and Boom vs. Recession:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(df[expansion_condition]['Securities Growth'], \n",
    "                label='Expansion', bins=lin, stat='density', alpha=0.6)\n",
    "    plt.axvline(df[expansion_condition]['Securities Growth'].mean(), linestyle='--', linewidth=2, color='blue')\n",
    "    sns.histplot(df[contraction_condition]['Securities Growth'], \n",
    "                label='Contraction', bins=lin, alpha=0.6, stat='density')\n",
    "    plt.axvline(df[contraction_condition]['Securities Growth'].mean(), linestyle='--', linewidth=2, color='orange')\n",
    "    plt.title('Securities Growth (High Inflation, FF Hike)')\n",
    "    plt.xlabel('Securities Growth')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    # print the std deviation of both distributions in the (-0.2,8) coordinate:\n",
    "    plt.text(0.1, 7.5, 'Mean Expansion:             ' + str(round(df[expansion_condition]['Securities Growth'].mean(), 4)))\n",
    "    plt.text(0.1, 6.5, 'Std. Expansion:             ' + str(round(df[expansion_condition]['Securities Growth'].std(), 4)))\n",
    "    plt.text(0.1, 5.5, 'Mean Contraction:           ' + str(round(df[contraction_condition]['Securities Growth'].mean(), 4)))\n",
    "    plt.text(0.1, 4.5, 'Std. Contraction:           ' + str(round(df[contraction_condition]['Securities Growth'].std(), 4)))\n",
    "    plt.grid(True, which='both', linestyle='--', lw=0.5, alpha=0.5, color='lightgrey')\n",
    "    plt.xlim(-0.25, 0.25)\n",
    "    plt.show()\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    # make a histogram of the de-trended loans when the inflation is high, FF hike and Boom vs. Recession:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    lin = np.linspace(df['Cash Growth'].min(), 2, 150)\n",
    "    sns.histplot(df[expansion_condition]['Cash Growth'], \n",
    "                label='Expansion', bins=lin, stat='density', alpha=0.6)\n",
    "    plt.axvline(df[expansion_condition]['Cash Growth'].mean(), linestyle='--', linewidth=2, color='blue')\n",
    "    sns.histplot(df[contraction_condition]['Cash Growth'], \n",
    "                label='Contraction', bins=lin, alpha=0.6, stat='density')\n",
    "    plt.axvline(df[contraction_condition]['Cash Growth'].mean(), linestyle='--', linewidth=2, color='orange')\n",
    "    plt.title('Cash Growth (High Inflation, FF Hike)')\n",
    "    plt.xlabel('Cash Growth')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    # print the std deviation of both distributions in the (-0.2,8) coordinate:\n",
    "    # print the std deviation of both distributions in the (-0.2,8) coordinate:\n",
    "    plt.text(1, 1.4, 'Mean Expansion:             ' + str(round(df[expansion_condition]['Cash Growth'].mean(), 4)))\n",
    "    plt.text(1, 1.3, 'Std. Expansion:             ' + str(round(df[expansion_condition]['Cash Growth'].std(), 4)))\n",
    "    plt.text(1, 1.2, 'Mean Contraction:           ' + str(round(df[contraction_condition]['Cash Growth'].mean(), 4)))\n",
    "    plt.text(1, 1.1, 'Std. Contraction:           ' + str(round(df[contraction_condition]['Cash Growth'].std(), 4)))\n",
    "    plt.grid(True, which='both', linestyle='--', lw=0.5, alpha=0.5, color='lightgrey')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # --------------------------------- Scatter Plots --------------------------------- #\n",
    "    #-------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    # Create the figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Binned scatter for expansion\n",
    "    binned_scatter(\n",
    "    df.loc[expansion_condition, 'Loan_Growth'], \n",
    "    df.loc[expansion_condition, 'Securities Growth'], \n",
    "    q=num_quantiles, \n",
    "    #color='blue', \n",
    "    label='Expansion'\n",
    "    )\n",
    "\n",
    "    # Binned scatter for contraction\n",
    "    binned_scatter(\n",
    "    df.loc[contraction_condition, 'Loan_Growth'], \n",
    "    df.loc[contraction_condition, 'Securities Growth'], \n",
    "    q=num_quantiles, \n",
    "    #color='orange', \n",
    "    label='Contraction'\n",
    "    )\n",
    "\n",
    "    # Plot settings\n",
    "    plt.title('Binned Loan Growth vs. Securities Growth (Quantile Bins)')\n",
    "    plt.ylabel('Loan Growth')\n",
    "    plt.xlabel('Securities Growth')\n",
    "    plt.ylim(-0.05, 0.12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', linestyle='--', lw=0.5, alpha=0.5, color='lightgrey')\n",
    "    plt.show()\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------#\n",
    "    # Create the figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Binned scatter for expansion\n",
    "    binned_scatter(\n",
    "    df.loc[expansion_condition, 'Deposit_Growth'], \n",
    "    df.loc[expansion_condition, 'Loan_Growth'], \n",
    "    q=num_quantiles, \n",
    "    #color='blue', \n",
    "    label='Expansion'\n",
    "    )\n",
    "\n",
    "    # Binned scatter for contraction\n",
    "    binned_scatter(\n",
    "    df.loc[contraction_condition, 'Deposit_Growth'], \n",
    "    df.loc[contraction_condition, 'Loan_Growth'], \n",
    "    q=num_quantiles, \n",
    "    #color='orange', \n",
    "    label='Contraction'\n",
    "    )\n",
    "\n",
    "    # Plot settings\n",
    "    plt.title('Binned Deposits Growth vs. Loan Growth (Quantile Bins)')\n",
    "    plt.ylabel('Loan Growth')\n",
    "    plt.xlabel('Deposits Growth')\n",
    "    plt.ylim(-0.01, 0.05)\n",
    "    plt.xlim(-0.1, 0.2)\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', linestyle='--', lw=0.5, alpha=0.5, color='lightgrey')\n",
    "    plt.show()\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------#\n",
    "    # Create the figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Binned scatter for expansion\n",
    "    binned_scatter(\n",
    "    df.loc[expansion_condition, 'Deposit_Growth'], \n",
    "    df.loc[expansion_condition, 'Cash Growth'], \n",
    "    q=num_quantiles, \n",
    "    #color='blue', \n",
    "    label='Expansion'\n",
    "    )\n",
    "\n",
    "    # Binned scatter for contraction\n",
    "    binned_scatter(\n",
    "    df.loc[contraction_condition, 'Deposit_Growth'], \n",
    "    df.loc[contraction_condition, 'Cash Growth'], \n",
    "    q=num_quantiles, \n",
    "    #color='orange', \n",
    "    label='Contraction'\n",
    "    )\n",
    "\n",
    "    # Plot settings\n",
    "    plt.title('Binned Deposits Growth vs. Cash Growth (Quantile Bins)')\n",
    "    plt.ylabel('Cash Growth')\n",
    "    plt.xlabel('Deposits Growth')\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', linestyle='--', lw=0.5, alpha=0.5, color='lightgrey')\n",
    "    plt.show()\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------#\n",
    "    # Create the figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Binned scatter for expansion\n",
    "    binned_scatter(\n",
    "    df.loc[expansion_condition, 'Deposit_Growth'], \n",
    "    df.loc[expansion_condition, 'Securities Growth'], \n",
    "    q=num_quantiles, \n",
    "    #color='blue', \n",
    "    label='Expansion'\n",
    "    )\n",
    "\n",
    "    # Binned scatter for contraction\n",
    "    binned_scatter(\n",
    "    df.loc[contraction_condition, 'Deposit_Growth'], \n",
    "    df.loc[contraction_condition, 'Securities Growth'], \n",
    "    q=num_quantiles, \n",
    "    #color='orange', \n",
    "    label='Contraction'\n",
    "    )\n",
    "\n",
    "    # Plot settings\n",
    "    plt.title('Binned Deposits Growth vs. Securities Growth (Quantile Bins)')\n",
    "    plt.ylabel('Securities Growth')\n",
    "    plt.xlabel('Deposits Growth')\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', linestyle='--', lw=0.5, alpha=0.5, color='lightgrey')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_sectional_plots(df, 'ff_hike', num_quantiles=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_sectional_plots(df, 'mp_shock', num_quantiles=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
