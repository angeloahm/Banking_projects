{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/angel/Documents/Economics/Research/Banking Project/data/intermediate/sod'\n",
    "\n",
    "# Set path to be the directory:\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the list of county codes:\n",
    "cw = pd.read_excel('qcew-county-msa-csa-crosswalk.xlsx', sheet_name='Feb. 2013 Crosswalk')\n",
    "\n",
    "cw['STCNTYBR'] = cw['County Code'].astype(str)\n",
    "cw.loc[cw['STCNTYBR'].str.len() == 4, 'STCNTYBR'] = '0' + cw['STCNTYBR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angel\\AppData\\Local\\Temp\\ipykernel_20364\\2809252724.py:2: DtypeWarning: Columns (13,28,50,59,60,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sod = pd.read_csv('sod_data.csv', header=0, sep=',')\n"
     ]
    }
   ],
   "source": [
    "# Load branch data:\n",
    "sod = pd.read_csv('sod_data.csv', header=0, sep=',')\n",
    "#inst = pd.read_csv('sod_data_ins.csv', header=0, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sod['STCNTYBR'] = sod['STCNTYBR'].astype(str)\n",
    "sod.loc[sod['STCNTYBR'].str.len() == 4, 'STCNTYBR'] = '0' + sod['STCNTYBR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'list' on 'STCNTYBR' with the sod data:\n",
    "sod = pd.merge(sod, cw, on='STCNTYBR', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEPSUMBR    object\n",
       "NECNAMB     object\n",
       "ASSET       object\n",
       "DEPDOM      object\n",
       "DEPSUM      object\n",
       "ESCROW      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show columns 13,28,50,59,60,62:\n",
    "cols = [13,28,50,59,60,62]\n",
    "\n",
    "# Specify dtypes for col 13, 28, 50, 59, 60, 62:\n",
    "sod.iloc[:,cols].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take commas away from columns 13, 28, 50, 59, 60, 62 so we can convert them to numeric:\n",
    "sod.iloc[:,cols] = sod.iloc[:,cols].replace(',', '', regex=True)\n",
    "#inst.iloc[:,cols] = inst.iloc[:,cols].replace(',', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DEPSUMBR to numeric:\n",
    "sod['DEPSUMBR'] = pd.to_numeric(sod['DEPSUMBR'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sod.to_csv('sod_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ID variable that is equal to RSSDHCR, and if RSSDHCR==0 then ID=RSSDID:\n",
    "sod['ID'] = np.where(sod['RSSDHCR']==0, sod['RSSDID'], sod['RSSDHCR']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sod.groupby('RSSDID')['RSSDID'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there a 1 to 1 map between RSSDID and CERT numbers?\n",
    "sod.groupby('RSSDID').CERT.nunique().value_counts()\n",
    "\n",
    "\n",
    "# Matches with Jason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sod[sod['RSSDID']==480228]['CERT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sod[sod['RSSDID']==480228]['NAMEFULL'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sod[(sod['RSSDID']==480228) & (sod['NAMEFULL']=='Bank of America, National Association') & (sod['CERT']==3510)]['YEAR'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sod[(sod['RSSDID']==480228) & (sod['NAMEFULL']=='NationsBank, National Association') & (sod['CERT']==15802)]['YEAR'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sod[(sod['RSSDID']==480228) & (sod['NAMEFULL']=='NationsBank, National Association (Carolinas)') & (sod['CERT']==15802)]['YEAR'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sod[(sod['RSSDID']==480228) & (sod['NAMEFULL']=='Nationsbank of North Carolina, National Association') & (sod['CERT']==4892)]['YEAR'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value in USD \n",
    "print('Deposits in 1996:', sod[sod['YEAR']==1996]['DEPSUMBR'].sum())\n",
    "\n",
    "# Matches with Jason "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset excluding the HQ and NaN for the MSA Title:\n",
    "df = sod[(sod['BKMO']==0) & (sod['MSA Title'].notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate deposits over MSA per year, it will be useful later...\n",
    "df_grouped_msa = df.groupby(['MSA Title', 'YEAR'])['DEPSUMBR'].sum().reset_index(name='total_msa')\n",
    "\n",
    "# Aggregate all deposits over US per year:\n",
    "df_grouped_msa['total_US'] = df_grouped_msa.groupby('YEAR')['total_msa'].transform('sum')\n",
    "\n",
    "# Share of deposits in each MSA, per year:\n",
    "df_grouped_msa['share_msa'] = df_grouped_msa['total_msa']/df_grouped_msa['total_US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Share of deposits in each MSA, per year:\n",
    "df_grouped_msa['share_msa'] = df_grouped_msa['total_msa']/df_grouped_msa['total_US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check, sum of share_msa per year should be 1:\n",
    "df_grouped_msa.groupby('YEAR')['share_msa'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the share of deposits per ID and year, note that the total deposits per MSANAMB is in the df_grouped dataset:\n",
    "df = pd.merge(df, df_grouped_msa, on=['MSA Title', 'YEAR'], how='left')\n",
    "\n",
    "# Sort values by MSA and year:\n",
    "df = df.sort_values(by=['MSA Title', 'YEAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['ID']==0] # matches with jason until here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a .csv file with df[df['ID']==0]:\n",
    "df[df['ID']==0].to_csv('sod_data_no_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['ID']==0]['RSSDHCR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the total amount of deposits per NAMEHCR, in each MSA and year:\n",
    "df_grouped_id = df.groupby(['ID', 'MSA Title', 'YEAR'])['DEPSUMBR'].sum().reset_index(name='total_id')\n",
    "\n",
    "df = pd.merge(df, df_grouped_id, on=['ID', 'MSA Title', 'YEAR'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute share of deposits per NAMEHCR, in each MSA and year:\n",
    "df['share_id'] = 100*(df['total_id']/df['total_msa'])\n",
    "df['share_id_sq'] = df['share_id']**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the columns ID, YEAR, MSANAMB, and share_id_sq and take uniques on IDs, keep only those columns:\n",
    "df_grouped_id_sq = df[['ID', 'YEAR', 'MSA Title','share_id_sq']].drop_duplicates()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum all the share_id_sq per MSANAMB and year:\n",
    "df_grouped_id_sq = df_grouped_id_sq.groupby(['MSA Title', 'YEAR'])['share_id_sq'].sum().reset_index(name='HHI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_id_sq[df_grouped_id_sq['HHI']==10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_id_sq[df_grouped_id_sq['HHI']==10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum the squared shares of deposits per MSA, per year:\n",
    "df_HHI = df_grouped_id_sq[['YEAR', 'MSA Title', 'HHI']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HHI = pd.merge(df_HHI, df_grouped_msa, on=['MSA Title', 'YEAR'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a scatter plot of the HHI per share_msa per year, I want the dots for each year to have different collors, and \n",
    "# to be in different plots:\n",
    "df_HHI_some_years = df_HHI[(df_HHI['YEAR']==1994) | (df_HHI['YEAR']==2010) | (df_HHI['YEAR']==2020) ]\n",
    "sns.scatterplot(data=df_HHI_some_years, x='share_msa', y='HHI', hue='YEAR', palette='seismic')\n",
    "plt.legend()\n",
    "plt.title('HHI vs Share of deposits per year')\n",
    "plt.xlabel('Share of deposits')\n",
    "plt.ylabel('HHI')\n",
    "plt.savefig('HHI_vs_share_deposits.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to make the same plot as above, but only for 1994 and 2022:\n",
    "df_HHI_2000 = df_HHI[(df_HHI['YEAR']==2000)]\n",
    "\n",
    "sns.scatterplot(data=df_HHI_2000, x='share_msa', y='HHI', hue='YEAR', palette='seismic')\n",
    "plt.legend()\n",
    "plt.title('HHI vs Share of deposits per year')\n",
    "plt.xlabel('Share of deposits')\n",
    "plt.ylabel('HHI')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to make the same plot as above, but only for 1994 and 2022:\n",
    "df_HHI_2010 = df_HHI[(df_HHI['YEAR']==2010)]\n",
    "\n",
    "sns.scatterplot(data=df_HHI_2010, x='share_msa', y='HHI', hue='YEAR', palette='seismic')\n",
    "plt.legend()\n",
    "plt.title('HHI vs Share of deposits per year')\n",
    "plt.xlabel('Share of deposits')\n",
    "plt.ylabel('HHI')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to make the same plot as above, but only for 1994 and 2022:\n",
    "df_HHI_2020 = df_HHI[(df_HHI['YEAR']==2020)]\n",
    "\n",
    "sns.scatterplot(data=df_HHI_2020, x='share_msa', y='HHI', hue='YEAR', palette='seismic')\n",
    "plt.legend()\n",
    "plt.title('HHI vs Share of deposits per year')\n",
    "plt.xlabel('Share of deposits')\n",
    "plt.ylabel('HHI')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate to get one HHI per year, averaging over MSAs:\n",
    "df_HHI = df_HHI.groupby('YEAR')['HHI'].mean().reset_index(name='HHI')\n",
    "\n",
    "# Plot HHI over time:\n",
    "plt.plot(df_HHI['YEAR'], df_HHI['HHI'], color='black')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('HHI')\n",
    "plt.title('HHI over time')\n",
    "plt.grid(True, color='lightgray', linestyle='-', linewidth=0.5, alpha=0.5)\n",
    "plt.savefig('HHI_over_time.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of HHI for 1994, 2010, and 2020. Please use fraction of observations in the y-axis:\n",
    "plt.hist(df_HHI_2000['HHI'], bins=100, alpha=1, label='2000', density=True)\n",
    "plt.hist(df_HHI_2010['HHI'], bins=100, alpha=1, label='2010', density=True)\n",
    "plt.hist(df_HHI_2020['HHI'], bins=100, alpha=1, label='2020', density=True)\n",
    "plt.legend()\n",
    "plt.xlabel('HHI')\n",
    "plt.ylabel('Density')\n",
    "plt.title('HHI distribution for 1994, 2010, and 2020')\n",
    "plt.savefig('HHI_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary dataset\n",
    "temp = df[['ID', 'YEAR', 'MSA Title', 'share_id_sq', 'share_msa']].drop_duplicates()\n",
    "\n",
    "# compute HHI per MSA and year\n",
    "wHHI = temp.groupby(['MSA Title', 'YEAR'])['share_id_sq'].sum().reset_index(name='HHI')\n",
    "\n",
    "df_wHHI = pd.merge(df[['MSA Title', 'YEAR', 'share_msa']], wHHI, on=['MSA Title', 'YEAR'], how='left').drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average HHI over MSAs, weighting by 'share_msa' to get one value per year:\n",
    "df_wHHI['wHHI'] = df_wHHI['HHI']*df_wHHI['share_msa']\n",
    "\n",
    "# sum wHHI variable per year:\n",
    "df_wHHI = df_wHHI.groupby('YEAR')['wHHI'].sum().reset_index(name='wHHI')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot wHHI over time:\n",
    "plt.plot(df_wHHI['YEAR'], df_wHHI['wHHI'], color='black')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Weighted HHI')\n",
    "plt.title('HHI weighted by deposits over time')\n",
    "plt.grid(True, color='lightgray', linestyle='-', linewidth=0.5, alpha=0.5)\n",
    "plt.savefig('wHHI_over_time.svg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
