{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edbee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# ignore warnings:\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "sns.set_theme(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24116c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binned_scatter(x, y, q, marker='o', dispersion=False):\n",
    "    # Convert x to a pandas Series if needed\n",
    "    if not isinstance(x, pd.Series):\n",
    "        x = pd.Series(x)\n",
    "    # Compute percentile rank for each observation (values between 0 and 1)\n",
    "    x_pct = x.rank(method='average', pct=True)\n",
    "    \n",
    "    # Create quantile bins on the percentile ranks\n",
    "    x_binned, bin_edges = pd.qcut(x_pct, q=q, retbins=True, duplicates='drop')\n",
    "    bin_centers = []\n",
    "    binned_means = []\n",
    "    binned_median = []\n",
    "    binned_min = []\n",
    "    binned_max = []\n",
    "    \n",
    "    # Compute statistics within each bin (using the percentile x-values)\n",
    "    for interval in x_binned.unique():\n",
    "        x_in_bin = x_pct[x_binned == interval]\n",
    "        y_in_bin = y[x_binned == interval]\n",
    "        bin_center = x_in_bin.mean()\n",
    "        mean_val = y_in_bin.mean()\n",
    "        median_val = y_in_bin.median()\n",
    "        # Dispersion: 25th and 75th percentiles of y\n",
    "        min_val = y_in_bin.quantile(0.25)\n",
    "        max_val = y_in_bin.quantile(0.75)\n",
    "        bin_centers.append(bin_center)\n",
    "        binned_means.append(mean_val)\n",
    "        binned_median.append(median_val)\n",
    "        binned_min.append(min_val)\n",
    "        binned_max.append(max_val)\n",
    "    \n",
    "    # Sort results by bin centers\n",
    "    sorted_indices = np.argsort(bin_centers)\n",
    "    bin_centers = np.array(bin_centers)[sorted_indices]\n",
    "    binned_means = np.array(binned_means)[sorted_indices]\n",
    "    binned_median = np.array(binned_median)[sorted_indices]\n",
    "    binned_min = np.array(binned_min)[sorted_indices]\n",
    "    binned_max = np.array(binned_max)[sorted_indices]\n",
    "    \n",
    "    # Plot the mean values\n",
    "    plt.scatter(bin_centers, binned_means, label='mean', marker=marker, alpha=1, s=50, edgecolors='black')\n",
    "    \n",
    "    # Optionally plot additional dispersion markers\n",
    "    if dispersion:\n",
    "        plt.scatter(bin_centers, binned_median, label='median', marker=marker, alpha=0.7, s=50, color='green')\n",
    "        plt.scatter(bin_centers, binned_min, label='25th percentile', marker=marker, alpha=0.7, s=50, color='grey')\n",
    "        plt.scatter(bin_centers, binned_max, label='75th percentile', marker=marker, alpha=0.7, s=50, color='grey')\n",
    "    \n",
    "    # Label the axes\n",
    "    xlabel = f'Percentile Rank of {x.name}' if x.name else 'Percentile Rank'\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(y.name if hasattr(y, 'name') else 'y')\n",
    "    plt.grid(True, linestyle='--', alpha=0.5, linewidth=0.5, color='lightgrey')\n",
    "    \n",
    "    # Set x-ticks from 0 to 100\n",
    "    tick_positions = np.linspace(0, 1, 6)\n",
    "    tick_labels = [f'{int(val*100)}' for val in tick_positions]\n",
    "    plt.xticks(tick_positions, tick_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbddf007",
   "metadata": {},
   "source": [
    "### Class and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc57c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallReports:\n",
    "    def __init__(self, folder_path, essential_vars=None):\n",
    "        \"\"\"\n",
    "        Initialize the analysis class with the folder path where 'call_reports.csv' is stored.\n",
    "        \n",
    "        Parameters:\n",
    "          folder_path (str): Path to the folder containing 'call_reports.csv'.\n",
    "          essential_vars (list, optional): List of columns that must always be included.\n",
    "                Defaults to ['IDRSSD', 'Financial Institution Name', 'Date'].\n",
    "        \"\"\"\n",
    "        self.folder_path = folder_path\n",
    "        # Build full path for the call_reports.csv file.\n",
    "        self.file_path = os.path.join(folder_path, \"call_reports.csv\")\n",
    "        \n",
    "        if essential_vars is None:\n",
    "            self.essential_vars = ['IDRSSD', 'Financial Institution Name', 'Date']\n",
    "        else:\n",
    "            self.essential_vars = essential_vars\n",
    "        \n",
    "        # DataFrames will be loaded later, once variables to select are provided.\n",
    "        self.df_selected = None\n",
    "        self.df_constructed = None\n",
    "        self.df_balanced = None\n",
    "\n",
    "    def select_variables(self, variables=None):\n",
    "        \"\"\"\n",
    "        Select a subset of columns for analysis and load only those columns from the CSV file.\n",
    "        Essential variables are always included.\n",
    "        \n",
    "        Also, check for duplicate columns that come in pairs ending with '_x' and '_y'. For each pair,\n",
    "        compute the maximum gap (absolute difference) between the entries. The maximum gap is printed,\n",
    "        and if the gap is zero, the '_y' column is dropped (keeping the '_x' column).\n",
    "        \n",
    "        Finally, reorder the columns so that the essential variables (self.essential_vars)\n",
    "        and the 'Year' column (if it exists) are the first columns in the DataFrame.\n",
    "        \n",
    "        Parameters:\n",
    "        variables (list, optional): Additional variable names to include besides essential ones.\n",
    "                                        If None, only essential variables will be selected.\n",
    "        \n",
    "        Returns:\n",
    "        DataFrame with the selected (and cleaned) columns, with essential_vars and 'Year' ordered first.\n",
    "        \"\"\"\n",
    "        # Combine the essential variables and any additional requested variables.\n",
    "        if variables is None:\n",
    "            vars_to_select = self.essential_vars.copy()\n",
    "        else:\n",
    "            vars_to_select = list(set(self.essential_vars + variables))\n",
    "        \n",
    "        # Read only the header of the CSV to know which columns exist.\n",
    "        try:\n",
    "            df_header = pd.read_csv(self.file_path, nrows=0)\n",
    "        except Exception as e:\n",
    "            raise IOError(f\"Error reading file header from {self.file_path}: {e}\")\n",
    "        \n",
    "        available_in_file = df_header.columns.tolist()\n",
    "        \n",
    "        # Warn if some requested variables are not in the file.\n",
    "        missing_vars = [v for v in vars_to_select if v not in available_in_file]\n",
    "        if missing_vars:\n",
    "            print(\"Warning: The following variables are not in the data and will be skipped:\", missing_vars)\n",
    "        \n",
    "        # Determine the final list of columns to load.\n",
    "        available_vars = [v for v in vars_to_select if v in available_in_file]\n",
    "        \n",
    "        # Load only the selected columns from the CSV.\n",
    "        self.df_selected = pd.read_csv(self.file_path, usecols=available_vars)\n",
    "        \n",
    "        # Ensure the 'Date' column is converted to datetime if present.\n",
    "        if 'Date' in self.df_selected.columns:\n",
    "            self.df_selected['Date'] = pd.to_datetime(self.df_selected['Date'], errors='coerce')\n",
    "        \n",
    "        # Check for duplicate variables that come with suffixes '_x' and '_y'.\n",
    "        for col in self.df_selected.columns:\n",
    "            if col.endswith(\"_x\"):\n",
    "                base = col[:-2]  # Remove the '_x' suffix\n",
    "                col_y = base + \"_y\"\n",
    "                if col_y in self.df_selected.columns:\n",
    "                    try:\n",
    "                        # Compute maximum absolute difference (\"gap\") between the two columns.\n",
    "                        gap = (self.df_selected[col] - self.df_selected[col_y]).abs().max()\n",
    "                    except Exception as e:\n",
    "                        # If subtraction fails (e.g., non-numeric data), compare equality.\n",
    "                        diff = self.df_selected[col] != self.df_selected[col_y]\n",
    "                        gap = 0 if not diff.any() else \"Mismatch\"\n",
    "                    \n",
    "                    print(f\"Duplicate variable {base}: max gap between {col} and {col_y} is {gap}\")\n",
    "                    \n",
    "                    # If the gap is zero, drop the duplicate '_y' column.\n",
    "                    if gap == 0:\n",
    "                        print(f\"Dropping duplicate column {col_y} as it is identical to {col}.\")\n",
    "                        self.df_selected.drop(columns=[col_y], inplace=True)\n",
    "        \n",
    "        # Reorder columns: ensure that the columns in essential_vars and 'Year'\n",
    "        # are the first columns, followed by the rest in their original order.\n",
    "        order_cols = []\n",
    "        for col in self.essential_vars:\n",
    "            if col in self.df_selected.columns:\n",
    "                order_cols.append(col)\n",
    "        if 'Year' in self.df_selected.columns:\n",
    "            order_cols.append('Year')\n",
    "        # Append any remaining columns that were not in order_cols.\n",
    "        other_cols = [col for col in self.df_selected.columns if col not in order_cols]\n",
    "        self.df_selected = self.df_selected[order_cols + other_cols]\n",
    "        \n",
    "        return self.df_selected\n",
    "        \n",
    "        \n",
    "    def compare_variables(self, var_RCFD, var_RCON):\n",
    "        \"\"\"\n",
    "        Compare two columns (e.g., a RCFD column and a RCON column).\n",
    "        \n",
    "        Returns:\n",
    "          A dictionary with counts for:\n",
    "            - both_valid: Observations where both are not NaN.\n",
    "            - RCFD_only: Observations where only var_RCFD is not NaN.\n",
    "            - RCON_only: Observations where only var_RCON is not NaN.\n",
    "            - both_NaN: Observations where both are NaN.\n",
    "          \n",
    "        Note: This function requires that select_variables() has been run.\n",
    "        \"\"\"\n",
    "        if self.df_selected is None:\n",
    "            raise ValueError(\"Data has not been subset. Please run select_variables() first.\")\n",
    "        \n",
    "        for var in [var_RCFD, var_RCON]:\n",
    "            if var not in self.df_selected.columns:\n",
    "                raise ValueError(f\"Column {var} is not available in the selected DataFrame.\")\n",
    "        \n",
    "        df_subset = self.df_selected[[var_RCFD, var_RCON]]\n",
    "        both_valid = df_subset.dropna().shape[0]\n",
    "        rcf_only = ((df_subset[var_RCFD].notna()) & (df_subset[var_RCON].isna())).sum()\n",
    "        rcon_only = ((df_subset[var_RCON].notna()) & (df_subset[var_RCFD].isna())).sum()\n",
    "        both_nan = ((df_subset[var_RCFD].isna()) & (df_subset[var_RCON].isna())).sum()\n",
    "        \n",
    "        return {\n",
    "            \"both_valid\": both_valid,\n",
    "            \"RCFD_only\": rcf_only,\n",
    "            \"RCON_only\": rcon_only,\n",
    "            \"both_NaN\": both_nan\n",
    "        }\n",
    "\n",
    "    def construct_definitions(self, mappings):\n",
    "        \"\"\"\n",
    "        Construct new variables, handling MDRM code changes at specific switch_dates.\n",
    "        \n",
    "        Parameters:\n",
    "            mappings (list): Each mapping dictionary may contain:\n",
    "                - 'new_var': Name of the new variable.\n",
    "                - 'first_col', 'second_col': Column names for initial period.\n",
    "                - 'method': (optional) Combination method ('secondary', 'first', 'min', 'max', 'mean', 'sum').\n",
    "                - 'mask_zeros': (optional) if True, mask zeros as NaN.\n",
    "                - 'switch_date': (optional) date the MDRM codes change.\n",
    "                - 'first_col_post', 'second_col_post': (optional) Column names after switch_date.\n",
    "                If these are not provided, the original columns are used throughout.\n",
    "                \n",
    "        Returns:\n",
    "            DataFrame with constructed variables appended.\n",
    "            \n",
    "        -------------------------------------- Examples --------------------------------------\n",
    "        1) For a variable that changes MDRM codes, we use the 'switch_date' to determine when to switch columns.\n",
    "        Suppose the variable \"Held-to-maturity securities\" changes MDRM codes on 2019-03-31:        \n",
    "            mappings = [\n",
    "                {\n",
    "                    \"new_var\": \"Held-to-maturity securities\",\n",
    "                    \"first_col\": \"RCFD1754\",\n",
    "                    \"second_col\": \"RCON1754\",\n",
    "                    \"switch_date\": \"2019-03-31\",\n",
    "                    \"first_col_post\": \"RCFDJJ34\",\n",
    "                    \"second_col_post\": \"RCONJJ34\",\n",
    "                    \"method\": \"secondary\",\n",
    "                    \"mask_zeros\": True\n",
    "                }\n",
    "            ]\n",
    "        \n",
    "        Then, the resulting series is constructed as:\n",
    "        \n",
    "            Date          Columns used\n",
    "            -------------------------------------\n",
    "            2018-12-31 → RCFD1754 & RCON1754\n",
    "            2019-03-30 → RCFD1754 & RCON1754\n",
    "            ------------------------------------- switch_date = 2019-03-31\n",
    "            2019-03-31 → RCFDJJ34 & RCONJJ34\n",
    "            2020-06-30 → RCFDJJ34 & RCONJJ34\n",
    "        \n",
    "        For a variable without code changes, such as \"Total Loans\":\n",
    "        \n",
    "            mappings = [\n",
    "                {\n",
    "                    \"new_var\": \"Total Loans\",\n",
    "                    \"first_col\": \"RCON2122\",\n",
    "                    \"second_col\": \"RCON2122\",\n",
    "                    \"method\": \"secondary\",\n",
    "                    \"mask_zeros\": True\n",
    "                }\n",
    "            ]\n",
    "        \n",
    "        The resulting series uses the same columns across all dates:\n",
    "        \n",
    "            Date          Columns used\n",
    "            -------------------------------------\n",
    "            2005-12-31 → RCON2122\n",
    "            2019-03-31 → RCON2122\n",
    "            2023-12-31 → RCON2122\n",
    "        \"\"\"\n",
    "        if self.df_selected is None:\n",
    "            raise ValueError(\"Please run select_variables() first.\")\n",
    "            \n",
    "        df = self.df_selected.copy()\n",
    "\n",
    "        for mapping in mappings:\n",
    "            new_var = mapping['new_var']\n",
    "            df[new_var] = np.nan\n",
    "\n",
    "            method = mapping.get('method', 'secondary')\n",
    "            mask_zeros = mapping.get('mask_zeros', False)\n",
    "            \n",
    "            switch_date = pd.Timestamp(mapping.get('switch_date', '2100-01-01'))\n",
    "\n",
    "            # Before switch_date\n",
    "            first_col = mapping['first_col']\n",
    "            second_col = mapping['second_col']\n",
    "            \n",
    "            pre_mask = df['Date'] < switch_date\n",
    "            \n",
    "            # Function to combine two columns\n",
    "            def combine_cols(df_slice, col1, col2, method):\n",
    "                if method == \"min\":\n",
    "                    return df_slice[[col1, col2]].min(axis=1)\n",
    "                elif method == \"max\":\n",
    "                    return df_slice[[col1, col2]].max(axis=1)\n",
    "                elif method == \"mean\":\n",
    "                    return df_slice[[col1, col2]].mean(axis=1, skipna=True)\n",
    "                elif method == \"sum\":\n",
    "                    return df_slice[col1].fillna(0) + df_slice[col2].fillna(0)\n",
    "                elif method == \"first\":\n",
    "                    return df_slice[col1].combine_first(df_slice[col2])\n",
    "                elif method == \"secondary\":\n",
    "                    return df_slice[col2].combine_first(df_slice[col1])\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown method '{method}'\")\n",
    "\n",
    "            # Apply to pre-switch dates\n",
    "            result_pre = combine_cols(df.loc[pre_mask], first_col, second_col, method)\n",
    "            if mask_zeros:\n",
    "                result_pre = result_pre.mask(result_pre == 0, np.nan)\n",
    "            df.loc[pre_mask, new_var] = result_pre\n",
    "\n",
    "            # Apply post-switch if columns provided\n",
    "            if 'switch_date' in mapping:\n",
    "                first_col_post = mapping.get('first_col_post', first_col)\n",
    "                second_col_post = mapping.get('second_col_post', second_col)\n",
    "                \n",
    "                post_mask = df['Date'] >= switch_date\n",
    "                result_post = combine_cols(df.loc[post_mask], first_col_post, second_col_post, method)\n",
    "                if mask_zeros:\n",
    "                    result_post = result_post.mask(result_post == 0, np.nan)\n",
    "                df.loc[post_mask, new_var] = result_post\n",
    "\n",
    "        self.df_constructed = df\n",
    "        return df\n",
    "\n",
    "\n",
    "    def create_balanced_panel(self, df_input=None):\n",
    "        \"\"\"\n",
    "        Transform the given dataset (or the constructed dataset) into a balanced panel by retaining\n",
    "        only banks (identified by 'IDRSSD') that appear in all dates.\n",
    "        \n",
    "        Parameters:\n",
    "          df_input (DataFrame, optional): The DataFrame to convert. Defaults to using self.df_constructed.\n",
    "        \n",
    "        Returns:\n",
    "          A balanced panel DataFrame.\n",
    "        \"\"\"\n",
    "        if df_input is None:\n",
    "            if self.df_constructed is None:\n",
    "                raise ValueError(\"No constructed DataFrame available. Please run construct_definitions() first.\")\n",
    "            df_input = self.df_constructed\n",
    "        \n",
    "        if \"IDRSSD\" not in df_input.columns or \"Date\" not in df_input.columns:\n",
    "            raise ValueError(\"Both 'IDRSSD' and 'Date' columns must be in the DataFrame for creating a balanced panel.\")\n",
    "        \n",
    "        n_dates = df_input[\"Date\"].nunique()\n",
    "        valid_banks = df_input.groupby(\"IDRSSD\")[\"Date\"].nunique()[lambda x: x == n_dates].index\n",
    "        balanced_df = df_input[df_input[\"IDRSSD\"].isin(valid_banks)].copy()\n",
    "        self.df_balanced = balanced_df\n",
    "        return balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb94d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/angel/Documents/Economics/Research/Banking Project/data/clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb1fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = CallReports(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510dce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define maturity variables:\n",
    "loans_mat_vars = [\n",
    "                'RCONA564', 'RCONA565', 'RCONA566', 'RCONA567', 'RCONA568', 'RCONA569',     # used\n",
    "                #'RCFDA564', 'RCFDA565', 'RCFDA566', 'RCFDA567', 'RCFDA568', 'RCFDA569',     # to be tested\n",
    "                # ------------------------------------------------------------------------------------------------\n",
    "                'RCFDA570', 'RCFDA571', 'RCFDA572', 'RCFDA573', 'RCFDA574', 'RCFDA575',     # used \n",
    "                #'RCONA570', 'RCONA571', 'RCONA572', 'RCONA573', 'RCONA574', 'RCONA575',     # to be tested  \n",
    "                ]\n",
    "\n",
    "securities_mat_vars = [\n",
    "             # --------------------------------------  Treasuries  --------------------------------------\n",
    "                'RCFDA549', 'RCFDA550', 'RCFDA551', 'RCFDA552', 'RCFDA553', 'RCFDA554',     # used\n",
    "                'RCONA549', 'RCONA550', 'RCONA551', 'RCONA552', 'RCONA553', 'RCONA554',     # to be tested\n",
    "            # --------------------------------------  MBS  --------------------------------------\n",
    "                'RCFDA555', 'RCFDA556', 'RCFDA557', 'RCFDA558', 'RCFDA559', 'RCFDA560',     # used\n",
    "                'RCONA555', 'RCONA556', 'RCONA557', 'RCONA558', 'RCONA559', 'RCONA560',     # to be tested\n",
    "                ]\n",
    "\n",
    "\n",
    "# define the list of variables that will be used\n",
    "vars = [\n",
    "             # ------------------------------------------------------------------------------------------------ \n",
    "             'Date', 'IDRSSD', 'Financial Institution Name',            # Identifier Variables\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "            'RCON2170', 'RCFD2170',                                     # Total Assets\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCON2122', 'RCFD2122',                                    # Total Loans\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCON2200', 'RCFN2200',                                    # Total Deposits\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCONF045', 'RCONF046', 'RCONF047', \n",
    "             'RCONF048', 'RCONF049', 'RCONF050',\n",
    "             'RCONF051', 'RCONF052', 'RCON3645',                        # Uninsured Deposits\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCON3210', 'RCFD3210',                                    # Total Equity Capital\n",
    "             'RCONB530', 'RCFDB530',                                    # AOCI\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCON1754', 'RCFD1754',                                    # HTM Securities Ammortized Cost\n",
    "             'RCFD1754_x', 'RCFD1754_y', 'RCON1754_x', 'RCON1754_y',\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCON1771', 'RCFD1771',                                    # HTM Securities Fair Value\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCON1772', 'RCFD1772',                                    # AFS Securities Ammortized Cost\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCONJJ34', 'RCFDJJ34',                                    \n",
    "             'RCONJA22', 'RCFDJA22',                                    # Booked Securities\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCFD1773_x', 'RCFD1773_y', 'RCON1773',                    # AFS Securities Fair Value\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCONB987',                                                # FF sold in domestic offices\n",
    "             'RCONB989', 'RCFDB989',                                    # Resell agreements                                  \n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCFD0081', 'RCON0081',                                    # Cash and Balances Due from Depository Institutions\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RIAD4073', 'RIAD4200', 'RIAD4185', 'RIAD4180', 'RIAD4172',# Income Variables\n",
    "             ] \n",
    "\n",
    "# create a list putting together 'vars', 'loans_mat_vars', and 'securities_mat_vars':\n",
    "all_vars = vars + loans_mat_vars + securities_mat_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedee49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = cr.select_variables(all_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e9f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cr.df_selected.head(10)\n",
    "# Matches the other file! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a292f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#last_digits = sorted(list(set([var[-3:] for var in securities_mat_vars])))\n",
    "\n",
    "#for x in last_digits:\n",
    "#    print('---------------------------------------------------------------------------------')\n",
    "#    print('For x = ', x)\n",
    "#    vars = [\n",
    "#    'RCFDA' + str(int(x)), 'RCONA' + str(int(x))\n",
    "#    ]\n",
    "#    print(cr.compare_variables(vars[0], vars[1]))\n",
    "# Matches the other file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ee4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#last_digits = sorted(list(set([var[-3:] for var in loans_mat_vars])))\n",
    "#last_digits = [int(x) for x in last_digits]\n",
    "#last_digits = [x for x in last_digits if x < 570]\n",
    "\n",
    "#for x in last_digits:\n",
    "#    print('---------------------------------------------------------------------------------')\n",
    "#    vars = [\n",
    "#    'RCFDA' + str(x+6), 'RCONA' + str(x)\n",
    "#    ]\n",
    "#    print(vars[0], vars[1])\n",
    "#    print(cr.compare_variables(vars[0], vars[1]))\n",
    "\n",
    "# Matches the other file!   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a01e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = [\n",
    "    # Loans: Total Loans = RCON2122.combine_first(RCFD2122), then mask zeros.\n",
    "    {\n",
    "        \"first_col\": \"RCON2122\",\n",
    "        \"second_col\": \"RCON2122\",\n",
    "        \"new_var\": \"Total Loans\",\n",
    "        \"method\": \"secondary\",   # Gives RCON2122 if available, else RCFD2122.\n",
    "        \"mask_zeros\": True\n",
    "    },\n",
    "    # Assets: Create Total Assets from RCON2170 and mask zeros.\n",
    "    {\n",
    "        \"first_col\": \"RCFD2170\",\n",
    "        \"second_col\": \"RCON2170\",\n",
    "        \"new_var\": \"Total Assets\",\n",
    "        \"method\": \"secondary\",   # Since both are the same, this simply copies RCON2170.\n",
    "        \"mask_zeros\": True\n",
    "    },\n",
    "    # Equity Capital: Create Total Equity Capital from RCON3210 and RCFD3210 and mask zeros.\n",
    "    {\n",
    "        \"first_col\": \"RCON3210\",\n",
    "        \"second_col\": \"RCFD3210\",\n",
    "        \"new_var\": \"Total Equity Capital\",\n",
    "        \"method\": \"secondary\",   # Since both are the same, this simply copies RCON3210.\n",
    "        \"mask_zeros\": True\n",
    "    },\n",
    "    # AOCI: Create AOCI from RCONB530 and RCFDB530 and mask zeros.\n",
    "    {\n",
    "        \"first_col\": \"RCONB530\",\n",
    "        \"second_col\": \"RCFDB530\",\n",
    "        \"new_var\": \"AOCI\",\n",
    "        \"method\": \"secondary\",   # Since both are the same, this simply copies RCONB530.\n",
    "        \"mask_zeros\": True\n",
    "    },\n",
    "    # ********************************************************************************************************\n",
    "    # ****************************************** Security Variables ******************************************\n",
    "    # ********************************************************************************************************\n",
    "    # ------------------------------------------ INTERMEDIATE STEPS ------------------------------------------\n",
    "    # Create RCON1754_right = RCON1754_x.combine_first(RCON1754)\n",
    "    {\n",
    "        \"new_var\":              \"RCON1754_right\",\n",
    "        \"first_col\":            \"RCON1754\",      # fallback column\n",
    "        \"second_col\":           \"RCON1754_x\",   # primary column\n",
    "        \"method\":               \"secondary\"\n",
    "    },\n",
    "    # Create RCFD1754_right = RCFD1754_x.combine_first(RCFD1754)\n",
    "    {\n",
    "        \"new_var\":              \"RCFD1754_right\",\n",
    "        \"first_col\":            \"RCFD1754\",      # fallback column\n",
    "        \"second_col\":           \"RCFD1754_x\",   # primary column\n",
    "        \"method\":               \"secondary\"\n",
    "    },\n",
    "    # Create 1754_right from RCFD1754_right and RCON1754_right\n",
    "    # This takes the row-wise minimum:\n",
    "    {\n",
    "        \"new_var\":              \"1754_right\",\n",
    "        \"first_col\":            \"RCFD1754_right\",\n",
    "        \"second_col\":           \"RCON1754_right\",\n",
    "        \"method\":               \"secondary\"\n",
    "    },\n",
    "        # Create '1771_right' from RCON1771 and RCFD1771:\n",
    "    {\n",
    "        \"new_var\":              \"1771_right\",\n",
    "        \"first_col\":            \"RCFD1771\",\n",
    "        \"second_col\":           \"RCON1771\",\n",
    "        \"method\":               \"secondary\"\n",
    "    },\n",
    "    # Create 1772_right from RCFD1772 and RCON1772:\n",
    "    {\n",
    "        \"new_var\":              \"1772_right\",\n",
    "        \"first_col\":            \"RCFD1772\",\n",
    "        \"second_col\":           \"RCON1772\",\n",
    "        \"method\":               \"secondary\"\n",
    "    },\n",
    "    # Create B989_right from RCFDB989 and RCONB989:\n",
    "    {\n",
    "        \"new_var\":              \"B989_right\",\n",
    "        \"first_col\":            \"RCFDB989\",\n",
    "        \"second_col\":           \"RCONB989\",\n",
    "        \"method\":               \"secondary\",\n",
    "      },\n",
    "    # ------------------------------------------ VARIABLES ------------------------------------------\n",
    "    {\n",
    "        \"new_var\":          \"HTM Securities\",\n",
    "        \"first_col\":        \"1754_right\",       \n",
    "        \"second_col\":       \"1754_right\",\n",
    "        \"switch_date\":      \"2019-03-31\",           # First date with the new MDRM code.\n",
    "        \"first_col_post\":   \"RCFDJJ34\",\n",
    "        \"second_col_post\":  \"RCONJJ34\",\n",
    "        \"method\":           \"secondary\",\n",
    "    },\n",
    "    # Create AFS Securities from RCON1773 and RCFD1773_x:\n",
    "    {\n",
    "        \"new_var\":          \"AFS Securities\",\n",
    "        \"first_col\":        \"RCFD1773_x\",\n",
    "        \"second_col\":       \"RCON1773\",\n",
    "        \"method\":           \"secondary\",\n",
    "    },\n",
    "    # Create 'Securities AC' from 1754_right and 1772_right:\n",
    "    {\n",
    "        \"new_var\":          \"Securities AC\",\n",
    "        \"first_col\":        \"1754_right\",\n",
    "        \"second_col\":       \"1772_right\",\n",
    "        \"method\":           \"sum\",\n",
    "        \"mask_zeros\":       True\n",
    "    },\n",
    "    # Create 'Securities Fair Value' from 1771_right and AFS Securities:\n",
    "    {\n",
    "        \"new_var\":          \"Securities FV\",\n",
    "        \"first_col\":        \"1771_right\",\n",
    "        \"second_col\":       \"AFS Securities\",\n",
    "        \"method\":           \"sum\",\n",
    "        \"mask_zeros\":       True\n",
    "    },\n",
    "    # Create 'Equity Securities' from 'RCFDJA22' and 'RCONJA22':\n",
    "    {\n",
    "        \"new_var\":          \"Equity Securities\",\n",
    "        \"first_col\":        \"RCFDJA22\",\n",
    "        \"second_col\":       \"RCONJA22\",\n",
    "        \"method\":           \"secondary\",\n",
    "    },\n",
    "    # Create FFS from B989_right and RCONB987:\n",
    "    {\n",
    "        \"new_var\":          \"FFS\",\n",
    "        \"first_col\":        \"B989_right\",\n",
    "        \"second_col\":       \"RCONB987\",\n",
    "        \"method\":           \"sum\",\n",
    "        \"mask_zeros\":       True\n",
    "    },\n",
    "    # ********************************************************************************************************\n",
    "    # ************************************************* Cash *************************************************\n",
    "    # ********************************************************************************************************\n",
    "    # Create cash from RCFD0081 and RCON0081:\n",
    "    {\n",
    "        \"new_var\":          \"Cash\",\n",
    "        \"first_col\":        \"RCFD0081\",\n",
    "        \"second_col\":       \"RCON0081\",\n",
    "        \"method\":           \"secondary\",   \n",
    "    },\n",
    "    # ------------------------------------------ Deposit Variables ------------------------------------------\n",
    "    # Deposits: Create Total Deposits from RCON2200 (a simple copy) and mask zeros.\n",
    "    {\n",
    "        \"new_var\":          \"Total Deposits\",\n",
    "        \"first_col\":        \"RCON2200\",\n",
    "        \"second_col\":       \"RCON2200\",\n",
    "        \"method\":           \"secondary\",   # Since both are the same, this simply copies RCON2200.\n",
    "        \"mask_zeros\":       True\n",
    "    },\n",
    "    # Create 'Insured Deposit Accounts' from RCONF049 and RCONF045:\n",
    "    {\n",
    "        \"new_var\":          \"Insured Deposit Accounts\",\n",
    "        \"first_col\":        \"RCONF049\",\n",
    "        \"second_col\":       \"RCONF045\",\n",
    "        \"method\":           \"sum\",\n",
    "        \"mask_zeros\":       True\n",
    "    },\n",
    "    # Create 'Number of Insured Deposit Accounts' from RCONF050 and RCONF046:\n",
    "    {\n",
    "        \"new_var\":          \"Number of Insured Deposit Accounts\",\n",
    "        \"first_col\":        \"RCONF050\",\n",
    "        \"second_col\":       \"RCONF046\",\n",
    "        \"method\":           \"sum\",\n",
    "    },\n",
    "    # Create 'Uninsured Deposit Accounts' from RCONF051 and RCONF047:\n",
    "    {\n",
    "        \"new_var\":          \"Uninsured Deposit Accounts\",\n",
    "        \"first_col\":        \"RCONF051\",\n",
    "        \"second_col\":       \"RCONF047\",\n",
    "        \"method\":           \"sum\",\n",
    "    },\n",
    "    # Creat 'Number of Uninsured Deposit Accounts' from RCONF052 and RCONF048:\n",
    "    {\n",
    "        \"new_var\":          \"Number of Uninsured Deposit Accounts\",\n",
    "        \"first_col\":        \"RCONF052\",\n",
    "        \"second_col\":       \"RCONF048\",\n",
    "        \"method\":           \"sum\",\n",
    "    },\n",
    "    ]\n",
    "# Create all the new variables:\n",
    "main = cr.construct_definitions(mappings=mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d34954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'Insured Deposit Accounts' and 'Number of Insured Deposit Accounts'\n",
    "main['Insured Deposit Accounts'] = main['RCONF045'] + main['RCONF049']\n",
    "main['Number of Insured Deposit Accounts'] = main['RCONF046'] + main['RCONF050']\n",
    "\n",
    "# Create 'Uninsured Deposit Accounts' and 'Number of Uninsured Deposit Accounts'\n",
    "main['Uninsured Deposit Accounts'] = main['RCONF047'] + main['RCONF051']\n",
    "main['Number of Uninsured Deposit Accounts'] = main['RCONF048'] + main['RCONF052']\n",
    "\n",
    "# Correct insurance coverage threshold based on date:\n",
    "main['Insurance Coverage'] = np.where(main['Date'] < pd.Timestamp('2010-03-01'), 100, 250)\n",
    "\n",
    "# Recalculate 'Insured Deposits' considering coverage threshold:\n",
    "main['Insured Deposits'] = (\n",
    "    main['Insured Deposit Accounts'] +\n",
    "    main['Number of Uninsured Deposit Accounts'] * main['Insurance Coverage']\n",
    ")\n",
    "\n",
    "# Recalculate 'Uninsured Deposits':\n",
    "main['Uninsured Deposits'] = (\n",
    "    main['Uninsured Deposit Accounts'] -\n",
    "    main['Number of Uninsured Deposit Accounts'] * main['Insurance Coverage']\n",
    ")\n",
    "\n",
    "# Create 'Total Deposits 2':\n",
    "main['Total Deposits 2'] = main['Insured Deposits'] + main['Uninsured Deposits']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f68f5e",
   "metadata": {},
   "source": [
    "## Begenau et. al (2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d03b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main[['Date', 'IDRSSD', 'Financial Institution Name', 'Total Assets', 'HTM Securities', 'AFS Securities', 'FFS', 'Equity Securities', 'Cash']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3fae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep 2010Q1 to 2022Q4:\n",
    "df = df[(df['Date'] >= '2010-01-01') & (df['Date'] <= '2022-12-31')]\n",
    "\n",
    "df['Log Total Assets'] = np.log(df['Total Assets'])\n",
    "\n",
    "# Create 'Securities and FFS per Asset':\n",
    "df['Total Securities'] = df['HTM Securities'].fillna(0) + df['AFS Securities'].fillna(0) + df['Equity Securities'].fillna(0)\n",
    "df['Securities per Assets'] = df['Total Securities'] / df['Total Assets']\n",
    "df['Securities and FFS per Asset'] = (df['Total Securities'] + df['FFS']) / df['Total Assets']\n",
    "df['Cash, Securities and FFS per Asset'] = (df['Cash'] + df['Total Securities'] + df['FFS']) / df['Total Assets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32144f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a scatter plot of 'Cash, Securities and FFS per Asset' vs 'Total Assets' using seaborn:\n",
    "plt.figure(figsize=(8, 8))\n",
    "binned_scatter(df['Total Assets'], df['Cash, Securities and FFS per Asset'], q=100, marker='o', dispersion=True)\n",
    "# Add a vertical line for the x-tick 99:\n",
    "plt.axvline(x=.995, color='lightcoral', linestyle='--', label='99th Percentile of Total Assets')\n",
    "plt.title('Cash, Securities and FFS per Asset vs Total Assets')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f27776",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=df, x='Log Total Assets', y='Cash, Securities and FFS per Asset', marker='o', edgecolor='black')\n",
    "# plot a vertical line in the 99th percentile of 'Log Total Assets':\n",
    "plt.axvline(df['Log Total Assets'].quantile(0.99), color='lightcoral', linestyle='--', label='99th Percentile', linewidth=2)\n",
    "plt.title('Cash, Securities and FFS per Asset vs Log Total Assets')\n",
    "plt.xlabel('Log Total Assets')\n",
    "plt.ylabel('Cash, Securities and FFS per Asset')\n",
    "plt.grid(True, linestyle='--', alpha=0.5, linewidth=0.5, color='lightgrey')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8c1b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only top 1% of 'Total Assets' for the latest date:\n",
    "df_top = df[df['Total Assets'] >= df['Total Assets'].quantile(0.99)].copy()\n",
    "\n",
    "# plot the distribution of 'Securities and FFS per Asset' for the top 1% of 'Total Assets':\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(df_top['Cash, Securities and FFS per Asset'], bins=30, kde=False, color='skyblue', edgecolor='black', stat='density', linewidth=0.5)\n",
    "# add a vertical line for the mean:\n",
    "mean_value = df_top['Cash, Securities and FFS per Asset'].mean()\n",
    "plt.axvline(mean_value, color='lightcoral', linestyle='--', label=f'Mean: {mean_value:.2f}', linewidth=3)\n",
    "plt.title('Distribution of Cash, Securities and FFS per Asset for Top 1% of Total Assets')\n",
    "plt.xlabel('Cash, Securities and FFS per Asset')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True, linestyle='--', alpha=0.5, linewidth=0.5, color='lightgrey')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7381a6b",
   "metadata": {},
   "source": [
    "## Regional Banking Crisis (2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e576612c",
   "metadata": {},
   "source": [
    "### Scatter plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a14430",
   "metadata": {},
   "source": [
    "#### Plots for the whole sample of banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f8833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main[['Date', 'IDRSSD', 'Financial Institution Name', 'Total Loans', 'Total Deposits', 'Total Assets', 'Uninsured Deposits',\n",
    "           'AOCI', 'Total Equity Capital',\n",
    "           'Securities AC',  'Securities FV']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d576f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Date']=='2019-03-31') | (df['Date']=='2021-12-31')]\n",
    "df = df.sort_values(by=['IDRSSD', 'Date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c3ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total number of unique dates in the DataFrame\n",
    "total_dates = df['Date'].nunique()\n",
    "\n",
    "# Identify banks that appear in all dates\n",
    "banks_all_dates = df.groupby('IDRSSD')['Date'].nunique() == total_dates\n",
    "banks_to_keep = banks_all_dates[banks_all_dates].index\n",
    "\n",
    "# Filter the DataFrame to keep only these banks\n",
    "df = df[df['IDRSSD'].isin(banks_to_keep)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a067543",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_banks = [802866, 4114567, 3437483]\n",
    "#failed_banks = [802866, 4114567]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adf54bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main[main['IDRSSD']==4114567.0][['Date', 'IDRSSD', 'Financial Institution Name', 'RCON1772', 'RCFD1772', '1772_right']].sort_values(by='Date')\n",
    "#main[main['IDRSSD']==4114567.0][['Date', 'IDRSSD', 'Financial Institution Name', 'RCON1754_right', 'RCFD1754_right', '1754_right']].sort_values(by='Date')\n",
    "#main[main['IDRSSD']==4114567.0][['Date', 'IDRSSD', 'Financial Institution Name', '1772_right', '1754_right', 'Securities AC']].sort_values(by='Date')\n",
    "#main[main['IDRSSD']==4114567.0][['Date', 'IDRSSD', 'Financial Institution Name', 'RCON2170', 'RCFD2170']].sort_values(by='Date')\n",
    "#main[main['IDRSSD']==4114567.0][['Date', 'IDRSSD', 'Financial Institution Name', 'RCON3210', 'RCFD3210']].sort_values(by='Date')\n",
    "#main[main['IDRSSD']==4114567.0][['Date', 'IDRSSD', 'Financial Institution Name', 'RCONB530', 'RCFDB530']].sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7629a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the growth rate of 'Securities AC' and 'Total Loans', and 'Total Deposits':\n",
    "df['Securities AC Growth'] = df.groupby('IDRSSD')['Securities AC'].pct_change(fill_method=None)\n",
    "df['Securities FV Growth'] = df.groupby('IDRSSD')['Securities FV'].pct_change(fill_method=None)\n",
    "df['Loans Growth'] = df.groupby('IDRSSD')['Total Loans'].pct_change(fill_method=None)\n",
    "df['Deposits Growth'] = df.groupby('IDRSSD')['Total Deposits'].pct_change(fill_method=None)\n",
    "df['Uninsured Deposits Growth'] = df.groupby('IDRSSD')['Uninsured Deposits'].pct_change(fill_method=None)\n",
    "df['Equity Capital Growth'] = df.groupby('IDRSSD')['Total Equity Capital'].pct_change(fill_method=None)\n",
    "df['AOCI Growth'] = df.groupby('IDRSSD')['AOCI'].pct_change(fill_method=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227a4970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with NaN values in the 'Securities AC Growth' column\n",
    "df = df.dropna(subset=['Securities AC Growth', 'Securities FV Growth', 'Equity Capital Growth', 'AOCI Growth', 'Uninsured Deposits Growth',\n",
    "                        'Loans Growth', 'Deposits Growth', 'Total Assets'])\n",
    "\n",
    "# show the top 20 banks with the highest growth rate in 'Securities AC Growth':\n",
    "df.sort_values(by='Securities AC Growth', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf45efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[['IDRSSD', 'Financial Institution Name', 'Total Assets', 'Deposits Growth', 'Securities AC Growth', 'Loans Growth']].head(100)\n",
    "# take the minimum assets of test:\n",
    "print(test['Total Assets'].min()*1000/10e5, test['Total Assets'].max()*1000/10e5)\n",
    "print(test['Securities AC Growth'].min(), test['Securities AC Growth'].max())\n",
    "test['Total Assets (Millions)'] = test['Total Assets'].apply(lambda x: x*1000/10e5)\n",
    "outliers_securities = test[['IDRSSD', 'Financial Institution Name', 'Total Assets (Millions)', 'Deposits Growth', 'Securities AC Growth', 'Loans Growth']].head(100)['IDRSSD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40923192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude outliers_securities from the main DataFrame:\n",
    "df2 = df[~df['IDRSSD'].isin(outliers_securities)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29caf742",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "# Plot 1: Deposits Growth vs. Securities AC Growth\n",
    "ax1.scatter(df2['Deposits Growth'], df2['Securities AC Growth'], marker='.')\n",
    "ax1.scatter(df2[df2['IDRSSD'].isin(failed_banks)]['Deposits Growth'],\n",
    "            df2[df2['IDRSSD'].isin(failed_banks)]['Securities AC Growth'],\n",
    "            marker='s', s=100, color='orange')\n",
    "ax1.set_xlabel('Deposit Growth', fontsize=16)\n",
    "ax1.set_ylabel('Securities Growth', fontsize=16)\n",
    "ax1.set_title('Deposits and Securities Growth (AC)', fontsize=18)\n",
    "ax1.grid(color='lightgrey', ls=':', alpha=0.5, lw=1)\n",
    "# Force similar tick spacing on both axes\n",
    "#ticks1 = ax1.get_yticks()\n",
    "#ax1.set_xticks(ticks1)\n",
    "lims1 = [min(ax1.get_xlim()[0], ax1.get_ylim()[0]),\n",
    "         max(ax1.get_xlim()[1], ax1.get_ylim()[1])]\n",
    "ax1.plot(lims1, lims1, linestyle='--', color='black', alpha=0.5)\n",
    "ax1.set_xlim(-1.1, 8)\n",
    "ax1.set_ylim(-1.1, 8)\n",
    "ax1.tick_params(axis='both', labelsize=14)\n",
    "\n",
    "# Plot 2: Deposits Growth vs. Loans Growth\n",
    "ax2.scatter(df2['Deposits Growth'], df2['Loans Growth'], marker='.')\n",
    "ax2.scatter(df2[df2['IDRSSD'].isin(failed_banks)]['Deposits Growth'],\n",
    "            df2[df2['IDRSSD'].isin(failed_banks)]['Loans Growth'],\n",
    "            marker='s', s=100, color='orange')\n",
    "ax2.set_xlabel('Deposit Growth', fontsize=16)\n",
    "ax2.set_ylabel('Loans Growth', fontsize=16)\n",
    "ax2.set_title('Deposits and Loan Growth', fontsize=18)\n",
    "ax2.grid(color='lightgrey', ls=':', alpha=0.5, lw=1)\n",
    "ticks2 = ax2.get_yticks()\n",
    "ax2.set_xticks(ticks2)\n",
    "lims2 = [min(ax2.get_xlim()[0], ax2.get_ylim()[0]),\n",
    "         max(ax2.get_xlim()[1], ax2.get_ylim()[1])]\n",
    "ax2.plot(lims2, lims2, linestyle='--', color='black', alpha=0.5)\n",
    "ax2.set_xlim(-1.1, 8)\n",
    "ax2.set_ylim(-1.1, 8)\n",
    "ax2.tick_params(axis='both', labelsize=14)\n",
    "\n",
    "# Plot 3: Deposits Growth vs. Equity Capital Growth\n",
    "ax3.scatter(df2['Deposits Growth'], df2['Equity Capital Growth'], marker='.')\n",
    "ax3.scatter(df2[df2['IDRSSD'].isin(failed_banks)]['Deposits Growth'],\n",
    "            df2[df2['IDRSSD'].isin(failed_banks)]['Equity Capital Growth'],\n",
    "            marker='s', s=100, color='orange')\n",
    "ax3.set_xlabel('Deposit Growth', fontsize=16)\n",
    "ax3.set_ylabel('Equity Capital Growth', fontsize=16)\n",
    "ax3.set_title('Deposits and Equity Capital Growth', fontsize=18)\n",
    "ax3.grid(color='lightgrey', ls=':', alpha=0.5, lw=1)\n",
    "lims3 = [min(ax3.get_xlim()[0], ax3.get_ylim()[0]),\n",
    "         max(ax3.get_xlim()[1], ax3.get_ylim()[1])]\n",
    "ax3.plot(lims3, lims3, linestyle='--', color='black', alpha=0.5)\n",
    "ax3.tick_params(axis='both', labelsize=14)\n",
    "ax3.set_xlim(-1.1, 8)\n",
    "ax3.set_ylim(-1.1, 8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7610c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "# Plot 1: Deposits Growth vs. Securities AC Growth\n",
    "ax1.scatter(df2['Uninsured Deposits Growth'], df2['Securities AC Growth'], marker='.')\n",
    "ax1.scatter(df2[df2['IDRSSD'].isin(failed_banks)]['Uninsured Deposits Growth'],\n",
    "            df2[df2['IDRSSD'].isin(failed_banks)]['Securities AC Growth'],\n",
    "            marker='s', s=100, color='orange')\n",
    "ax1.set_xlabel('Uninsured Deposits Growth', fontsize=16)\n",
    "ax1.set_ylabel('Securities Growth', fontsize=16)\n",
    "ax1.set_title('Uninsured Deposits and Securities Growth (AC)', fontsize=18)\n",
    "ax1.grid(color='lightgrey', ls=':', alpha=0.5, lw=1)\n",
    "# Force similar tick spacing on both axes\n",
    "#ticks1 = ax1.get_yticks()\n",
    "#ax1.set_xticks(ticks1)\n",
    "lims1 = [min(ax1.get_xlim()[0], ax1.get_ylim()[0]),\n",
    "         max(ax1.get_xlim()[1], ax1.get_ylim()[1])]\n",
    "ax1.plot(lims1, lims1, linestyle='--', color='black', alpha=0.5)\n",
    "ax1.set_xlim(-1.1, 8)\n",
    "ax1.set_ylim(-1.1, 8)\n",
    "ax1.tick_params(axis='both', labelsize=14)\n",
    "\n",
    "# Plot 2: Deposits Growth vs. Loans Growth\n",
    "ax2.scatter(df2['Uninsured Deposits Growth'], df2['Loans Growth'], marker='.')\n",
    "ax2.scatter(df2[df2['IDRSSD'].isin(failed_banks)]['Uninsured Deposits Growth'],\n",
    "            df2[df2['IDRSSD'].isin(failed_banks)]['Loans Growth'],\n",
    "            marker='s', s=100, color='orange')\n",
    "ax2.set_xlabel('Uninsured Deposit Growth', fontsize=16)\n",
    "ax2.set_ylabel('Loans Growth', fontsize=16)\n",
    "ax2.set_title('Uninsured Deposits and Loan Growth', fontsize=18)\n",
    "ax2.grid(color='lightgrey', ls=':', alpha=0.5, lw=1)\n",
    "ticks2 = ax2.get_yticks()\n",
    "ax2.set_xticks(ticks2)\n",
    "lims2 = [min(ax2.get_xlim()[0], ax2.get_ylim()[0]),\n",
    "         max(ax2.get_xlim()[1], ax2.get_ylim()[1])]\n",
    "ax2.plot(lims2, lims2, linestyle='--', color='black', alpha=0.5)\n",
    "ax2.set_xlim(-1.1, 8)\n",
    "ax2.set_ylim(-1.1, 8)\n",
    "ax2.tick_params(axis='both', labelsize=14)\n",
    "\n",
    "# Plot 3: Deposits Growth vs. Equity Capital Growth\n",
    "ax3.scatter(df2['Uninsured Deposits Growth'], df2['Equity Capital Growth'], marker='.')\n",
    "ax3.scatter(df2[df2['IDRSSD'].isin(failed_banks)]['Uninsured Deposits Growth'],\n",
    "            df2[df2['IDRSSD'].isin(failed_banks)]['Equity Capital Growth'],\n",
    "            marker='s', s=100, color='orange')\n",
    "ax3.set_xlabel('Uninsured Deposit Growth', fontsize=16)\n",
    "ax3.set_ylabel('Equity Capital Growth', fontsize=16)\n",
    "ax3.set_title('Uninsured Deposits and Equity Capital Growth', fontsize=18)\n",
    "ax3.grid(color='lightgrey', ls=':', alpha=0.5, lw=1)\n",
    "lims3 = [min(ax3.get_xlim()[0], ax3.get_ylim()[0]),\n",
    "         max(ax3.get_xlim()[1], ax3.get_ylim()[1])]\n",
    "ax3.plot(lims3, lims3, linestyle='--', color='black', alpha=0.5)\n",
    "ax3.tick_params(axis='both', labelsize=14)\n",
    "ax3.set_xlim(-1.1, 8)\n",
    "ax3.set_ylim(-1.1, 8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e346b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the same scatter plot with 'Deposit Growth' in the x-axis and 'Uninsured Deposits Growth' in the y-axis:\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(df2['Deposits Growth'], df2['Uninsured Deposits Growth'], marker='.')\n",
    "ax.scatter(df2[df2['IDRSSD'].isin(failed_banks)]['Deposits Growth'],\n",
    "            df2[df2['IDRSSD'].isin(failed_banks)]['Uninsured Deposits Growth'],\n",
    "            marker='s', s=100, color='orange')\n",
    "ax.set_xlabel('Deposit Growth', fontsize=16)\n",
    "ax.set_ylabel('Uninsured Deposits Growth', fontsize=16)\n",
    "ax.set_title('Deposit Growth vs. Uninsured Deposits Growth', fontsize=18)\n",
    "ax.grid(color='lightgrey', ls=':', alpha=0.5, lw=1)\n",
    "# Force similar tick spacing on both axes\n",
    "#ticks = ax.get_yticks()\n",
    "#ax.set_xticks(ticks)\n",
    "lims = [min(ax.get_xlim()[0], ax.get_ylim()[0]),\n",
    "        max(ax.get_xlim()[1], ax.get_ylim()[1])]\n",
    "ax.plot(lims, lims, linestyle='--', color='black', alpha=0.5)\n",
    "ax.set_xlim(-1.1, 8)\n",
    "ax.set_ylim(-1.1, 8)\n",
    "ax.tick_params(axis='both', labelsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e69181",
   "metadata": {},
   "source": [
    "#### Plots for top X% banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986cfdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main[['Date', 'IDRSSD', 'Financial Institution Name', 'Total Loans', 'Total Deposits', 'Total Assets', 'Uninsured Deposits',\n",
    "           'AOCI', 'Total Equity Capital',\n",
    "           'Securities AC', 'Securities FV']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad6deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Date']=='2019-03-31') | (df['Date']=='2021-12-31')]\n",
    "df = df.sort_values(by=['IDRSSD', 'Date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f228e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total number of unique dates in the DataFrame\n",
    "total_dates = df['Date'].nunique()\n",
    "\n",
    "# Identify banks that appear in all dates\n",
    "banks_all_dates = df.groupby('IDRSSD')['Date'].nunique() == total_dates\n",
    "banks_to_keep = banks_all_dates[banks_all_dates].index\n",
    "\n",
    "# Filter the DataFrame to keep only these banks\n",
    "df = df[df['IDRSSD'].isin(banks_to_keep)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a0486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create auxiliar dataset with only '2019-03-31':\n",
    "df_aux = df[df['Date'] == '2019-03-31'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574e4582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the top 1% banks in 'Total Assets' in '2019-03-31':\n",
    "percentile = 0.99\n",
    "top_percentile_assets = df_aux['Total Assets'].quantile(percentile)\n",
    "top_percentile_deposits = df_aux['Total Deposits'].quantile(percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f20e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the DataFrame to keep only these banks:\n",
    "df_top_percentile = df_aux[df_aux['Total Assets'] >= top_percentile_assets].reset_index(drop=True)\n",
    "top_percent_banks = df_top_percentile['IDRSSD'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409eb465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1.  Prepare figure with 3 columns instead of 2 --------------------------\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(22, 6))\n",
    "\n",
    "# --- 2.  Your two cumulative-histogram panels (unchanged) --------------------\n",
    "ax1.hist(np.log(df['Total Assets']), bins=50, cumulative=True,\n",
    "         color='skyblue', alpha=0.7, density=True)\n",
    "ax1.set_title(f'Cumulative Distribution of Total Assets '\n",
    "              f'(Top {np.round(100*(1-percentile),1)}% Banks)', fontsize=18)\n",
    "ax1.set_xlabel('log(Total Assets)', fontsize=16);  ax1.set_ylabel('Density', fontsize=16)\n",
    "ax1.tick_params(axis='both', labelsize=14)\n",
    "ax1.grid(ls=':', color='lightgrey');  \n",
    "ax1.axvline(np.log(top_percentile_assets), ls='--', color='lightcoral',\n",
    "            label=f'{percentile}th Percentile')\n",
    "ax1.legend(fontsize=12)\n",
    "\n",
    "ax2.hist(np.log(df['Total Deposits']), bins=50, cumulative=True,\n",
    "         color='skyblue', alpha=0.7, density=True)\n",
    "ax2.set_title(f'Cumulative Distribution of Total Deposits '\n",
    "              f'(Top {np.round(100*(1-percentile),1)}% Banks)', fontsize=18)\n",
    "ax2.set_xlabel('log(Total Deposits)', fontsize=16);  ax2.set_ylabel('Density', fontsize=16)\n",
    "ax2.grid(ls=':', color='lightgrey')\n",
    "ax2.axvline(np.log(top_percentile_deposits), ls='--', color='lightcoral',\n",
    "            label=f'{percentile}th Percentile')\n",
    "ax2.legend(fontsize=14, frameon=False)\n",
    "\n",
    "# --- 3.  Lorenz-style concentration panel -----------------------------------\n",
    "def lorenz_points(series):\n",
    "    s = np.sort(series.values)                  # ascending order\n",
    "    cum_val  = np.cumsum(s) / s.sum()          # cumulative share of variable\n",
    "    cum_bank = np.arange(1, len(s)+1) / len(s) # cumulative share of banks\n",
    "    return cum_bank, cum_val\n",
    "\n",
    "plot_specs = [\n",
    "    ('Total Deposits', 'skyblue', 'Deposits'),\n",
    "    ('Total Assets',       'lightcoral',    'Assets'),\n",
    "#    ('Uninsured Deposits', 'green',   'Uninsured Deposits'),\n",
    "#    ('Securities AC',      'orange', 'Securities (AC)')\n",
    "]\n",
    "\n",
    "for col, clr, lbl in plot_specs:\n",
    "    x, y = lorenz_points(df[col].fillna(0))\n",
    "    ax3.scatter(x, y, s=18, color=clr, alpha=0.85, label=lbl)\n",
    "\n",
    "ax3.set_title('Concentration of Uninsured Deposits and Assets',\n",
    "              fontsize=18)\n",
    "ax3.set_xlabel('Share of Banks', fontsize=16);  ax3.set_ylabel('Share of Total', fontsize=16)\n",
    "ax3.tick_params(axis='both', labelsize=14)\n",
    "ax3.set_xlim(-0.02, 1.02);                ax3.set_ylim(-0.02, 1.02)\n",
    "ax3.grid(ls=':', color='lightgrey')\n",
    "ax3.legend(frameon=False, fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7165ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['IDRSSD'].isin(top_percent_banks)].sort_values(by='Total Assets', ascending=False)\n",
    "df2.sort_values(by=['Date', 'Total Assets'], ascending=[True, False], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee9e24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the growth rate of 'Securities AC' and 'Total Loans', and 'Total Deposits':\n",
    "df2['Securities AC Growth'] = df2.groupby('IDRSSD')['Securities AC'].pct_change(fill_method=None)\n",
    "df2['Securities FV Growth'] = df2.groupby('IDRSSD')['Securities FV'].pct_change(fill_method=None)\n",
    "df2['Loans Growth'] = df2.groupby('IDRSSD')['Total Loans'].pct_change(fill_method=None)\n",
    "df2['Deposits Growth'] = df2.groupby('IDRSSD')['Total Deposits'].pct_change(fill_method=None)\n",
    "df2['Uninsured Deposits Growth'] = df2.groupby('IDRSSD')['Uninsured Deposits'].pct_change(fill_method=None)\n",
    "df2['Equity Capital Growth'] = df2.groupby('IDRSSD')['Total Equity Capital'].pct_change(fill_method=None)\n",
    "df2['AOCI Growth'] = df2.groupby('IDRSSD')['AOCI'].pct_change(fill_method=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346c08c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "# Plot 1: Deposits Growth vs. Securities AC Growth\n",
    "ax1.scatter(df2['Deposits Growth'], df2['Securities AC Growth'], marker='o', s=50)\n",
    "ax1.scatter(df2[df2['IDRSSD'].isin(failed_banks)]['Deposits Growth'],\n",
    "            df2[df2['IDRSSD'].isin(failed_banks)]['Securities AC Growth'],\n",
    "            marker='s', s=100, color='orange')\n",
    "ax1.set_xlabel('Deposits Growth', fontsize=16)\n",
    "ax1.set_ylabel('Securities Growth', fontsize=16)\n",
    "ax1.set_title('Deposits and Securities Growth (AC)', fontsize=18)\n",
    "ax1.grid(color='lightgrey', ls=':', alpha=0.5, lw=1)\n",
    "# Force similar tick spacing on both axes\n",
    "ticks1 = ax1.get_yticks()\n",
    "ax1.set_xticks(ticks1)\n",
    "lims1 = [min(ax1.get_xlim()[0], ax1.get_ylim()[0]),\n",
    "         max(ax1.get_xlim()[1], ax1.get_ylim()[1])]\n",
    "ax1.plot(lims1, lims1, linestyle='--', color='black', alpha=0.5)\n",
    "ax1.set_xlim(-1.1, 6)\n",
    "ax1.set_ylim(-1.1, 6)\n",
    "ax1.tick_params(axis='both', labelsize=14)\n",
    "\n",
    "# Plot 2: Deposits Growth vs. Loans Growth\n",
    "ax2.scatter(df2['Deposits Growth'], df2['Loans Growth'], marker='o', s=50)\n",
    "ax2.scatter(df2[df2['IDRSSD'].isin(failed_banks)]['Deposits Growth'],\n",
    "            df2[df2['IDRSSD'].isin(failed_banks)]['Loans Growth'],\n",
    "            marker='s', s=100, color='orange')\n",
    "ax2.set_xlabel('Deposit Growth', fontsize=16)\n",
    "ax2.set_ylabel('Loans Growth', fontsize=16)\n",
    "ax2.set_title('Deposits and Loan Growth', fontsize=18)\n",
    "ax2.grid(color='lightgrey', ls=':', alpha=0.5, lw=1)\n",
    "ticks2 = ax2.get_yticks()\n",
    "lims2 = [min(ax2.get_xlim()[0]-1, ax2.get_ylim()[0]),\n",
    "         max(ax2.get_xlim()[1]-1, ax2.get_ylim()[1])]\n",
    "ax2.plot(lims2, lims2, linestyle='--', color='black', alpha=0.5)\n",
    "ax2.set_xticks(ticks2)\n",
    "ax2.set_yticks(ticks2)\n",
    "ax2.set_xlim(-0.5, 3)\n",
    "ax2.set_ylim(-0.5, 3)\n",
    "# use the same ticks for both axes\n",
    "ax2.tick_params(axis='both', labelsize=14)\n",
    "\n",
    "# Plot 3: Deposits Growth vs. Equity Capital Growth\n",
    "ax3.scatter(df2['Deposits Growth'], df2['Equity Capital Growth'], marker='o', s=50)\n",
    "ax3.scatter(df2[df2['IDRSSD'].isin(failed_banks)]['Deposits Growth'],\n",
    "            df2[df2['IDRSSD'].isin(failed_banks)]['Equity Capital Growth'],\n",
    "            marker='s', s=100, color='orange')\n",
    "ax3.set_xlabel('Deposit Growth', fontsize=16)\n",
    "ax3.set_ylabel('Equity Capital Growth', fontsize=16)\n",
    "ax3.set_title('Deposits and Equity Capital Growth', fontsize=18)\n",
    "ax3.grid(color='lightgrey', ls=':', alpha=0.5, lw=1)\n",
    "lims3 = [min(ax3.get_xlim()[0]-1, ax3.get_ylim()[0]),\n",
    "         max(ax3.get_xlim()[1]-1, ax3.get_ylim()[1])]\n",
    "ax3.plot(lims3, lims3, linestyle='--', color='black', alpha=0.5)\n",
    "ax3.tick_params(axis='both', labelsize=14)\n",
    "#ax3.set_xlim(-0.5, 2)\n",
    "#ax3.set_ylim(-0.5, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb429256",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "# Plot 1: Deposits Growth vs. Securities AC Growth\n",
    "ax1.scatter(df2['Uninsured Deposits Growth'], df2['Securities AC Growth'], marker='o', s=50)\n",
    "ax1.scatter(df2[df2['IDRSSD'].isin(failed_banks)]['Uninsured Deposits Growth'],\n",
    "            df2[df2['IDRSSD'].isin(failed_banks)]['Securities AC Growth'],\n",
    "            marker='s', s=100, color='orange')\n",
    "ax1.set_xlabel('Uninsured Deposit Growth', fontsize=16)\n",
    "ax1.set_ylabel('Securities Growth', fontsize=16)\n",
    "ax1.set_title('Uninsured Deposits and Securities Growth (AC)', fontsize=18)\n",
    "ax1.grid(color='lightgrey', ls=':', alpha=0.5, lw=1)\n",
    "# Force similar tick spacing on both axes\n",
    "#ticks1 = ax1.get_yticks()\n",
    "#ax1.set_xticks(ticks1)\n",
    "lims1 = [min(ax1.get_xlim()[0], ax1.get_ylim()[0]),\n",
    "         max(ax1.get_xlim()[1], ax1.get_ylim()[1])]\n",
    "ax1.plot(lims1, lims1, linestyle='--', color='black', alpha=0.5)\n",
    "ax1.set_xlim(-1.1, 6)\n",
    "ax1.set_ylim(-1.1, 6)\n",
    "ax1.tick_params(axis='both', labelsize=14)\n",
    "\n",
    "# Plot 2: Deposits Growth vs. Loans Growth\n",
    "ax2.scatter(df2['Uninsured Deposits Growth'], df2['Loans Growth'], marker='o', s=50)\n",
    "ax2.scatter(df2[df2['IDRSSD'].isin(failed_banks)]['Uninsured Deposits Growth'],\n",
    "            df2[df2['IDRSSD'].isin(failed_banks)]['Loans Growth'],\n",
    "            marker='s', s=100, color='orange')\n",
    "ax2.set_xlabel('Uninsured Deposits Growth', fontsize=16)\n",
    "ax2.set_ylabel('Loans Growth', fontsize=16)\n",
    "ax2.set_title('Uninsured Deposits and Loan Growth', fontsize=18)\n",
    "ax2.grid(color='lightgrey', ls=':', alpha=0.5, lw=1)\n",
    "ticks2 = ax2.get_yticks()\n",
    "lims2 = [min(ax2.get_xlim()[0]-1, ax2.get_ylim()[0]),\n",
    "         max(ax2.get_xlim()[1]-1, ax2.get_ylim()[1])]\n",
    "ax2.plot(lims2, lims2, linestyle='--', color='black', alpha=0.5)\n",
    "ax2.set_xticks(ticks2)\n",
    "ax2.set_yticks(ticks2)\n",
    "ax2.set_xlim(-0.5, 3)\n",
    "ax2.set_ylim(-0.5, 3)\n",
    "# use the same ticks for both axes\n",
    "ax2.tick_params(axis='both', labelsize=14)\n",
    "\n",
    "# Plot 3: Deposits Growth vs. Equity Capital Growth\n",
    "ax3.scatter(df2['Uninsured Deposits Growth'], df2['Equity Capital Growth'], marker='o', s=50)\n",
    "ax3.scatter(df2[df2['IDRSSD'].isin(failed_banks)]['Uninsured Deposits Growth'],\n",
    "            df2[df2['IDRSSD'].isin(failed_banks)]['Equity Capital Growth'],\n",
    "            marker='s', s=100, color='orange')\n",
    "ax3.set_xlabel('Uninsured Deposits Growth', fontsize=16)\n",
    "ax3.set_ylabel('Equity Capital Growth', fontsize=16)\n",
    "ax3.set_title('Uninsured Deposits and Equity Capital Growth', fontsize=18)\n",
    "ax3.grid(color='lightgrey', ls=':', alpha=0.5, lw=1)\n",
    "lims3 = [min(ax3.get_xlim()[0]-1, ax3.get_ylim()[0]),\n",
    "         max(ax3.get_xlim()[1]-1, ax3.get_ylim()[1])]\n",
    "ax3.plot(lims3, lims3, linestyle='--', color='black', alpha=0.5)\n",
    "ax3.tick_params(axis='both', labelsize=14)\n",
    "ax3.set_xlim(-1, 4)\n",
    "ax3.set_ylim(-1, 4)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55524cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the same scatter plot with 'Deposit Growth' in the x-axis and 'Uninsured Deposits Growth' in the y-axis:\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(df2['Deposits Growth'], df2['Uninsured Deposits Growth'], marker='.')\n",
    "ax.scatter(df2[df2['IDRSSD'].isin(failed_banks)]['Deposits Growth'],\n",
    "            df2[df2['IDRSSD'].isin(failed_banks)]['Uninsured Deposits Growth'],\n",
    "            marker='s', s=100, color='orange')\n",
    "ax.set_xlabel('Deposit Growth', fontsize=16)\n",
    "ax.set_ylabel('Uninsured Deposits Growth', fontsize=16)\n",
    "ax.set_title('Deposit Growth vs. Uninsured Deposits Growth', fontsize=18)\n",
    "ax.grid(color='lightgrey', ls=':', alpha=0.5, lw=1)\n",
    "# Force similar tick spacing on both axes\n",
    "#ticks = ax.get_yticks()\n",
    "#ax.set_xticks(ticks)\n",
    "lims = [min(ax.get_xlim()[0], ax.get_ylim()[0]),\n",
    "        max(ax.get_xlim()[1], ax.get_ylim()[1])]\n",
    "ax.plot(lims, lims, linestyle='--', color='black', alpha=0.5)\n",
    "ax.set_xlim(-1.1, 6)\n",
    "ax.set_ylim(-1.1, 6)\n",
    "ax.tick_params(axis='both', labelsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e3ff0f",
   "metadata": {},
   "source": [
    "### AOCI and MTM Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164d1fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = main.copy()\n",
    "#final_date = pd.Timestamp('2023-01-01')\n",
    "final_date = df_temp['Date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e15d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['Total Securities'] = df_temp['HTM Securities'].fillna(0) + df_temp['AFS Securities'].fillna(0) #+ df_temp['Equity Securities'].fillna(0)\n",
    "df_temp['AOCI %'] = (df_temp['AOCI'] / df_temp['Total Assets']) * 100\n",
    "# compute the difference between 'Securities Booked' and 'Securities FV':\n",
    "df_temp['MTM Losses HTM'] = -(df_temp['Total Securities'] - df_temp['Securities FV'])\n",
    "df_temp['MTM Losses %'] = 100*((df_temp['MTM Losses HTM']+df_temp['AOCI']) / df_temp['Total Assets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcbe981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute weighted average AOCI among other banks by total assets\n",
    "weighted_avg_aoci = (\n",
    "    df_temp[['Date', 'AOCI %', 'Total Assets']]\n",
    "    .groupby('Date')\n",
    "    .apply(lambda x: (x['AOCI %'] * x['Total Assets']).sum() / x['Total Assets'].sum())\n",
    "    .sort_index()\n",
    "    .reset_index(name='AOCI %')\n",
    ")\n",
    "\n",
    "# Compute simple average AOCI among other banks\n",
    "simple_avg_aoci = (\n",
    "    df_temp[['Date', 'AOCI %']]\n",
    "    .groupby('Date')\n",
    "    .mean()\n",
    "    .sort_index()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557f9be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_avg_mtm = (\n",
    "    df_temp[['Date', 'MTM Losses %', 'Total Assets']]\n",
    "    .groupby('Date')\n",
    "    .apply(lambda x: (x['MTM Losses %'] * x['Total Assets']).sum() / x['Total Assets'].sum())\n",
    "    .sort_index()\n",
    "    .reset_index(name='MTM Losses %')\n",
    ")\n",
    "\n",
    "# Compute simple average AOCI among other banks\n",
    "simple_avg_mtm = (\n",
    "    df_temp[['Date', 'MTM Losses %']]\n",
    "    .groupby('Date')\n",
    "    .mean()\n",
    "    .sort_index()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1a72b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the MTM losses by date and plot using df_temp['Date'] as x-axis:\n",
    "mtm_agg = df_temp.groupby('Date')['MTM Losses HTM'].sum().reset_index().sort_values('Date')\n",
    "# rename MTM Losses to MTM Losses HTM:\n",
    "mtm_agg['MTM Losses AFS'] = df_temp.groupby('Date')['AOCI'].sum().reset_index().sort_values('Date')['AOCI']\n",
    "# multiply by 1000 to convert to billions:\n",
    "mtm_agg['MTM Losses HTM'] = mtm_agg['MTM Losses HTM'] * 1000 / 1e9\n",
    "mtm_agg['MTM Losses AFS'] = mtm_agg['MTM Losses AFS'] * 1000 / 1e9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(25, 8))\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "# Plot 1: AOCI Time Series\n",
    "sns.lineplot(ax=axes[0], data=weighted_avg_aoci, x='Date', y='AOCI %', \n",
    "             label='Weighted Average AOCI', linewidth=4, color='skyblue')\n",
    "sns.lineplot(ax=axes[0], data=simple_avg_aoci, x='Date', y='AOCI %', \n",
    "             label='Simple Average AOCI', linewidth=4, linestyle='--')\n",
    "axes[0].grid(True, linestyle=':', linewidth=0.5, alpha=0.7)\n",
    "axes[0].axhline(0, color='black', linestyle='--', linewidth=2)\n",
    "axes[0].fill_betweenx(y=[-4, 1],\n",
    "                      x1=pd.Timestamp('2021-12-31'),\n",
    "                      x2=final_date,\n",
    "                      color='grey', alpha=0.2)\n",
    "axes[0].legend(fontsize=15, loc='lower left')\n",
    "axes[0].set_xlabel('Year', fontsize=16)\n",
    "axes[0].set_ylabel('AOCI/Total Assets (%)', fontsize=16)\n",
    "axes[0].set_title('AOCI Time Series', fontsize=18)\n",
    "axes[0].set_xlim(pd.Timestamp('2015-01-01'), final_date)\n",
    "axes[0].set_ylim(-3.5, 1)\n",
    "axes[0].tick_params(axis='x', labelsize=14, rotation=45)\n",
    "axes[0].tick_params(axis='y', labelsize=14)\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "# Plot 2: Weighted MTM Losses\n",
    "sns.lineplot(ax=axes[1], data=weighted_avg_mtm, x='Date', y='MTM Losses %',\n",
    "             lw=4, ci=False, label='Weighted average', linestyle='-', color='skyblue')\n",
    "sns.lineplot(ax=axes[1], data=simple_avg_mtm, x='Date', y='MTM Losses %',\n",
    "             lw=4, ci=False, linestyle='--', label='Simple average')\n",
    "axes[1].axhline(0, lw=1, ls=':', color='black')\n",
    "axes[1].legend(loc='lower left', fontsize=16)\n",
    "axes[1].grid(True, linestyle=':', linewidth=0.5, alpha=0.7)\n",
    "axes[1].fill_betweenx(y=[-11, 2.5],\n",
    "                      x1=pd.Timestamp('2021-12-31'),\n",
    "                      x2=final_date,\n",
    "                      color='grey', alpha=0.2)\n",
    "axes[1].set_xlabel('Date', fontsize=16)\n",
    "axes[1].set_ylabel('MTM Losses/Total Assets (%)', fontsize=16)\n",
    "axes[1].set_title('MTM Losses Time Series', fontsize=18)\n",
    "axes[1].set_xlim(pd.Timestamp('2015-01-01'), final_date)\n",
    "axes[1].set_ylim(-3.5, 1)\n",
    "axes[1].tick_params(axis='x', labelsize=14, rotation=45)\n",
    "axes[1].tick_params(axis='y', labelsize=14)\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "# Plot 3: stacked barplot of MTM losses\n",
    "\n",
    "# Define a thicker bar width\n",
    "bar_width = 60  # adjust as needed\n",
    "\n",
    "# Plot the first (bottom) bar: MTM Losses HTM using the same skyblue as in axes[0] and [2]\n",
    "axes[2].bar(mtm_agg['Date'], mtm_agg['MTM Losses HTM'], \n",
    "            width=bar_width, color='skyblue', label='MTM Losses HTM', edgecolor='black')\n",
    "\n",
    "# Plot the second bar on top: MTM Losses AFS using the default second palette color\n",
    "axes[2].bar(mtm_agg['Date'], mtm_agg['MTM Losses AFS'], \n",
    "            width=bar_width, bottom=mtm_agg['MTM Losses HTM'], \n",
    "            label='MTM Losses AFS', edgecolor='black')\n",
    "\n",
    "# Set title and labels directly on axes[1]\n",
    "axes[2].set_title('Total Security Losses', fontsize=18)\n",
    "axes[2].set_xlabel('Year', fontsize=16)\n",
    "axes[2].set_ylabel('MTM Losses (in billions)', fontsize=16)\n",
    "\n",
    "# Configure x-axis to show only years\n",
    "axes[2].tick_params(axis='x', labelsize=14, rotation=45)\n",
    "axes[2].fill_betweenx(y=[-800, 200],\n",
    "                      x1=pd.Timestamp('2021-12-31'),\n",
    "                      x2=final_date,\n",
    "                      color='grey', alpha=0.2)\n",
    "axes[2].legend(fontsize=14, loc='lower left')\n",
    "axes[2].grid(True, linestyle=':', linewidth=0.5, alpha=0.7)\n",
    "axes[2].set_xlim(pd.Timestamp('2015-01-01'), final_date)\n",
    "axes[2].set_ylim(-750, 150)\n",
    "axes[2].tick_params(axis='y', labelsize=14)\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f0be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last available date in 2022\n",
    "last_date = '2022-12-31'  # Assuming the last date is December 31, 2022\n",
    "\n",
    "# Select rows corresponding to this last date\n",
    "data_last = df_temp[df_temp['Date'] == last_date].copy()\n",
    "\n",
    "# Compute a weighted version of MTM Losses for each bank:\n",
    "#total_assets_last = data_last['Total Assets'].sum()\n",
    "#data_last['Weighted MTM Losses'] = data_last['MTM Losses %'] * (data_last['Total Assets'] / total_assets_last)\n",
    "\n",
    "\n",
    "# Plot the distribution of 'AOCI %'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=data_last, x='MTM Losses %', bins=50, kde=False, color='skyblue', \n",
    "             stat='density', edgecolor='black', linewidth=0.5)\n",
    "# place a vertical line at SVB's MTM Losses %:\n",
    "svb_mtm_loss = data_last[data_last['IDRSSD'] == 802866]['MTM Losses %'].values[0]\n",
    "plt.axvline(svb_mtm_loss, color='lightcoral', linestyle='--', linewidth=2, label='SVB')\n",
    "# write 'SVB' next to the vertical line:\n",
    "plt.text(svb_mtm_loss - 1.2, 0.25, 'SVB', color='lightcoral', fontsize=14)\n",
    "# place a vertical line at Signature Bank's MTM Losses %:\n",
    "sig_mtm_loss = data_last[data_last['IDRSSD'] == 3437483]['MTM Losses %'].values[0]\n",
    "plt.axvline(sig_mtm_loss, color='lightcoral', linestyle='--', linewidth=2, label='Signature Bank')\n",
    "# place a vertical line at First Republic's MTM Losses %:\n",
    "frb_mtm_loss = data_last[data_last['IDRSSD'] == 4114567]['MTM Losses %'].values[0]\n",
    "plt.axvline(frb_mtm_loss, color='lightcoral', linestyle='--', linewidth=2, label='First Republic')\n",
    "#plt.title('Distribution of MTM Losses/Total Assets (%)', fontsize=18)\n",
    "plt.grid(True, linestyle=':', linewidth=0.5, alpha=0.7, color='lightgrey')\n",
    "plt.xlabel('MTM Losses / Total Assets (%)', fontsize=16)\n",
    "plt.ylabel('Density', fontsize=16)\n",
    "plt.xlim(-13, 1.5)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
