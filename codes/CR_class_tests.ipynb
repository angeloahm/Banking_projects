{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8edbee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# ignore warnings:\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bc57c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallReports:\n",
    "    def __init__(self, folder_path, essential_vars=None):\n",
    "        \"\"\"\n",
    "        Initialize the analysis class with the folder path where 'call_reports.csv' is stored.\n",
    "        \n",
    "        Parameters:\n",
    "          folder_path (str): Path to the folder containing 'call_reports.csv'.\n",
    "          essential_vars (list, optional): List of columns that must always be included.\n",
    "                Defaults to ['IDRSSD', 'Financial Institution Name', 'Date'].\n",
    "        \"\"\"\n",
    "        self.folder_path = folder_path\n",
    "        # Build full path for the call_reports.csv file.\n",
    "        self.file_path = os.path.join(folder_path, \"call_reports.csv\")\n",
    "        \n",
    "        if essential_vars is None:\n",
    "            self.essential_vars = ['IDRSSD', 'Financial Institution Name', 'Date']\n",
    "        else:\n",
    "            self.essential_vars = essential_vars\n",
    "        \n",
    "        # DataFrames will be loaded later, once variables to select are provided.\n",
    "        self.df_selected = None\n",
    "        self.df_constructed = None\n",
    "        self.df_balanced = None\n",
    "\n",
    "    def select_variables(self, variables=None):\n",
    "        \"\"\"\n",
    "        Select a subset of columns for analysis and load only those columns from the CSV file.\n",
    "        Essential variables are always included.\n",
    "        \n",
    "        Also, check for duplicate columns that come in pairs ending with '_x' and '_y'. For each pair,\n",
    "        compute the maximum gap (absolute difference) between the entries. The maximum gap is printed,\n",
    "        and if the gap is zero, the '_y' column is dropped (keeping the '_x' column).\n",
    "        \n",
    "        Finally, reorder the columns so that the essential variables (self.essential_vars)\n",
    "        and the 'Year' column (if it exists) are the first columns in the DataFrame.\n",
    "        \n",
    "        Parameters:\n",
    "        variables (list, optional): Additional variable names to include besides essential ones.\n",
    "                                        If None, only essential variables will be selected.\n",
    "        \n",
    "        Returns:\n",
    "        DataFrame with the selected (and cleaned) columns, with essential_vars and 'Year' ordered first.\n",
    "        \"\"\"\n",
    "        # Combine the essential variables and any additional requested variables.\n",
    "        if variables is None:\n",
    "            vars_to_select = self.essential_vars.copy()\n",
    "        else:\n",
    "            vars_to_select = list(set(self.essential_vars + variables))\n",
    "        \n",
    "        # Read only the header of the CSV to know which columns exist.\n",
    "        try:\n",
    "            df_header = pd.read_csv(self.file_path, nrows=0)\n",
    "        except Exception as e:\n",
    "            raise IOError(f\"Error reading file header from {self.file_path}: {e}\")\n",
    "        \n",
    "        available_in_file = df_header.columns.tolist()\n",
    "        \n",
    "        # Warn if some requested variables are not in the file.\n",
    "        missing_vars = [v for v in vars_to_select if v not in available_in_file]\n",
    "        if missing_vars:\n",
    "            print(\"Warning: The following variables are not in the data and will be skipped:\", missing_vars)\n",
    "        \n",
    "        # Determine the final list of columns to load.\n",
    "        available_vars = [v for v in vars_to_select if v in available_in_file]\n",
    "        \n",
    "        # Load only the selected columns from the CSV.\n",
    "        self.df_selected = pd.read_csv(self.file_path, usecols=available_vars)\n",
    "        \n",
    "        # Ensure the 'Date' column is converted to datetime if present.\n",
    "        if 'Date' in self.df_selected.columns:\n",
    "            self.df_selected['Date'] = pd.to_datetime(self.df_selected['Date'], errors='coerce')\n",
    "        \n",
    "        # Check for duplicate variables that come with suffixes '_x' and '_y'.\n",
    "        for col in self.df_selected.columns:\n",
    "            if col.endswith(\"_x\"):\n",
    "                base = col[:-2]  # Remove the '_x' suffix\n",
    "                col_y = base + \"_y\"\n",
    "                if col_y in self.df_selected.columns:\n",
    "                    try:\n",
    "                        # Compute maximum absolute difference (\"gap\") between the two columns.\n",
    "                        gap = (self.df_selected[col] - self.df_selected[col_y]).abs().max()\n",
    "                    except Exception as e:\n",
    "                        # If subtraction fails (e.g., non-numeric data), compare equality.\n",
    "                        diff = self.df_selected[col] != self.df_selected[col_y]\n",
    "                        gap = 0 if not diff.any() else \"Mismatch\"\n",
    "                    \n",
    "                    print(f\"Duplicate variable {base}: max gap between {col} and {col_y} is {gap}\")\n",
    "                    \n",
    "                    # If the gap is zero, drop the duplicate '_y' column.\n",
    "                    if gap == 0:\n",
    "                        print(f\"Dropping duplicate column {col_y} as it is identical to {col}.\")\n",
    "                        self.df_selected.drop(columns=[col_y], inplace=True)\n",
    "        \n",
    "        # Reorder columns: ensure that the columns in essential_vars and 'Year'\n",
    "        # are the first columns, followed by the rest in their original order.\n",
    "        order_cols = []\n",
    "        for col in self.essential_vars:\n",
    "            if col in self.df_selected.columns:\n",
    "                order_cols.append(col)\n",
    "        if 'Year' in self.df_selected.columns:\n",
    "            order_cols.append('Year')\n",
    "        # Append any remaining columns that were not in order_cols.\n",
    "        other_cols = [col for col in self.df_selected.columns if col not in order_cols]\n",
    "        self.df_selected = self.df_selected[order_cols + other_cols]\n",
    "        \n",
    "        return self.df_selected\n",
    "        \n",
    "        \n",
    "    def compare_variables(self, var_RCFD, var_RCON):\n",
    "        \"\"\"\n",
    "        Compare two columns (e.g., a RCFD column and a RCON column).\n",
    "        \n",
    "        Returns:\n",
    "          A dictionary with counts for:\n",
    "            - both_valid: Observations where both are not NaN.\n",
    "            - RCFD_only: Observations where only var_RCFD is not NaN.\n",
    "            - RCON_only: Observations where only var_RCON is not NaN.\n",
    "            - both_NaN: Observations where both are NaN.\n",
    "          \n",
    "        Note: This function requires that select_variables() has been run.\n",
    "        \"\"\"\n",
    "        if self.df_selected is None:\n",
    "            raise ValueError(\"Data has not been subset. Please run select_variables() first.\")\n",
    "        \n",
    "        for var in [var_RCFD, var_RCON]:\n",
    "            if var not in self.df_selected.columns:\n",
    "                raise ValueError(f\"Column {var} is not available in the selected DataFrame.\")\n",
    "        \n",
    "        df_subset = self.df_selected[[var_RCFD, var_RCON]]\n",
    "        both_valid = df_subset.dropna().shape[0]\n",
    "        rcf_only = ((df_subset[var_RCFD].notna()) & (df_subset[var_RCON].isna())).sum()\n",
    "        rcon_only = ((df_subset[var_RCON].notna()) & (df_subset[var_RCFD].isna())).sum()\n",
    "        both_nan = ((df_subset[var_RCFD].isna()) & (df_subset[var_RCON].isna())).sum()\n",
    "        \n",
    "        return {\n",
    "            \"both_valid\": both_valid,\n",
    "            \"RCFD_only\": rcf_only,\n",
    "            \"RCON_only\": rcon_only,\n",
    "            \"both_NaN\": both_nan\n",
    "        }\n",
    "\n",
    "    def construct_definitions(self, mappings):\n",
    "        \"\"\"\n",
    "        Construct new variables from pairs of existing columns based on provided mappings.\n",
    "        \n",
    "        Parameters:\n",
    "        mappings (list): A list of dictionaries. Each dictionary should specify:\n",
    "            - \"first_col\": Name of the first column.\n",
    "            - \"second_col\": Name of the second column.\n",
    "            - \"new_var\": Desired name for the new variable.\n",
    "            Optional keys:\n",
    "            - \"mask_zeros\": (bool) If True, replace zeros with NaN.\n",
    "            - \"apply_diff\": (bool) If True, compute the difference over time.\n",
    "            - \"method\": (str) Specifies how to combine the two columns when both are non-null.\n",
    "                        Options are: \"secondary\", \"first\", \"min\", \"max\", \"mean\", or \"sum\".\n",
    "                        Default is \"secondary\".\n",
    "        \n",
    "        Returns:\n",
    "        A new DataFrame with the constructed variables appended.\n",
    "        \"\"\"\n",
    "        if self.df_selected is None:\n",
    "            raise ValueError(\"Data has not been subset. Please run select_variables() first.\")\n",
    "            \n",
    "        new_df = self.df_selected.copy()\n",
    "        \n",
    "        for mapping_item in mappings:\n",
    "            first_col = mapping_item.get(\"first_col\")\n",
    "            second_col = mapping_item.get(\"second_col\")\n",
    "            new_var = mapping_item.get(\"new_var\")\n",
    "            \n",
    "            # Ensure the specified columns exist.\n",
    "            for col in [first_col, second_col]:\n",
    "                if col not in new_df.columns:\n",
    "                    raise ValueError(f\"Column {col} is not in the selected DataFrame.\")\n",
    "                    \n",
    "            # Determine the method for combining the two columns.\n",
    "            method = mapping_item.get(\"method\", \"secondary\")\n",
    "            if method == \"min\":\n",
    "                new_df[new_var] = new_df[[first_col, second_col]].min(axis=1)\n",
    "            elif method == \"max\":\n",
    "                new_df[new_var] = new_df[[first_col, second_col]].max(axis=1)\n",
    "            elif method == \"mean\":\n",
    "                new_df[new_var] = new_df[[first_col, second_col]].mean(axis=1, skipna=True)\n",
    "            elif method == \"sum\":\n",
    "                new_df[new_var] = new_df[first_col] + new_df[second_col]\n",
    "            elif method == \"first\":\n",
    "                new_df[new_var] = new_df[first_col].combine_first(new_df[second_col])\n",
    "            elif method == \"secondary\":\n",
    "                new_df[new_var] = new_df[second_col].combine_first(new_df[first_col])\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown method provided: {method}\")\n",
    "            \n",
    "            # Optionally mask zeros.\n",
    "            if mapping_item.get(\"mask_zeros\", False):\n",
    "                new_df[new_var] = new_df[new_var].mask(new_df[new_var] == 0, np.nan)\n",
    "            \n",
    "            # Optionally apply differencing over time.\n",
    "            if mapping_item.get(\"apply_diff\", False):\n",
    "                if \"IDRSSD\" not in new_df.columns or \"Date\" not in new_df.columns:\n",
    "                    raise ValueError(\"Both 'IDRSSD' and 'Date' columns are required to compute differences.\")\n",
    "                new_df = new_df.sort_values(\"Date\")\n",
    "                new_df[new_var] = new_df.groupby(\"IDRSSD\")[new_var].diff()\n",
    "        \n",
    "        self.df_constructed = new_df\n",
    "\n",
    "        return new_df\n",
    "\n",
    "\n",
    "    def create_balanced_panel(self, df_input=None):\n",
    "        \"\"\"\n",
    "        Transform the given dataset (or the constructed dataset) into a balanced panel by retaining\n",
    "        only banks (identified by 'IDRSSD') that appear in all dates.\n",
    "        \n",
    "        Parameters:\n",
    "          df_input (DataFrame, optional): The DataFrame to convert. Defaults to using self.df_constructed.\n",
    "        \n",
    "        Returns:\n",
    "          A balanced panel DataFrame.\n",
    "        \"\"\"\n",
    "        if df_input is None:\n",
    "            if self.df_constructed is None:\n",
    "                raise ValueError(\"No constructed DataFrame available. Please run construct_definitions() first.\")\n",
    "            df_input = self.df_constructed\n",
    "        \n",
    "        if \"IDRSSD\" not in df_input.columns or \"Date\" not in df_input.columns:\n",
    "            raise ValueError(\"Both 'IDRSSD' and 'Date' columns must be in the DataFrame for creating a balanced panel.\")\n",
    "        \n",
    "        n_dates = df_input[\"Date\"].nunique()\n",
    "        valid_banks = df_input.groupby(\"IDRSSD\")[\"Date\"].nunique()[lambda x: x == n_dates].index\n",
    "        balanced_df = df_input[df_input[\"IDRSSD\"].isin(valid_banks)].copy()\n",
    "        self.df_balanced = balanced_df\n",
    "        return balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "eb94d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/angel/Documents/Economics/Research/Banking Project/data/clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5eb1fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = CallReports(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "510dce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define maturity variables:\n",
    "loans_mat_vars = [\n",
    "                'RCONA564', 'RCONA565', 'RCONA566', 'RCONA567', 'RCONA568', 'RCONA569',     # used\n",
    "                #'RCFDA564', 'RCFDA565', 'RCFDA566', 'RCFDA567', 'RCFDA568', 'RCFDA569',     # to be tested\n",
    "                # ------------------------------------------------------------------------------------------------\n",
    "                'RCFDA570', 'RCFDA571', 'RCFDA572', 'RCFDA573', 'RCFDA574', 'RCFDA575',     # used \n",
    "                #'RCONA570', 'RCONA571', 'RCONA572', 'RCONA573', 'RCONA574', 'RCONA575',     # to be tested  \n",
    "                ]\n",
    "\n",
    "securities_mat_vars = [\n",
    "             # --------------------------------------  Treasuries  --------------------------------------\n",
    "                'RCFDA549', 'RCFDA550', 'RCFDA551', 'RCFDA552', 'RCFDA553', 'RCFDA554',     # used\n",
    "                'RCONA549', 'RCONA550', 'RCONA551', 'RCONA552', 'RCONA553', 'RCONA554',     # to be tested\n",
    "            # --------------------------------------  MBS  --------------------------------------\n",
    "                'RCFDA555', 'RCFDA556', 'RCFDA557', 'RCFDA558', 'RCFDA559', 'RCFDA560',     # used\n",
    "                'RCONA555', 'RCONA556', 'RCONA557', 'RCONA558', 'RCONA559', 'RCONA560',     # to be tested\n",
    "                ]\n",
    "\n",
    "\n",
    "# define the list of variables that will be used\n",
    "vars = [\n",
    "             # ------------------------------------------------------------------------------------------------ \n",
    "             'Date', 'IDRSSD', 'Financial Institution Name',           # Identifier Variables\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "            'RCON2170', 'RCFD2170',                                    # Total Assets\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCON2122', 'RCFD2122',                                   # Total Loans\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCON2200',                                               # Total Deposits\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCON3210', 'RCFD3210',                                    # Total Equity Capital\n",
    "             'RCONB530', 'RCFDB530',                                    # AOCI\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCON1754', 'RCFD1754',                                    # HTM Securities Ammortized Cost\n",
    "             'RCFD1754_x', 'RCFD1754_y', 'RCON1754_x', 'RCON1754_y',\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCON1771', 'RCFD1771',                                                # HTM Securities Fair Value\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCON1772', 'RCFD1772',                                                # AFS Securities Ammortized Cost\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCFD1773_x', 'RCFD1773_y', 'RCON1773',                    # AFS Securities Fair Value\n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RCON0010', 'RCFD0010',                                    # Cash and balances due from depository institutions                                                \n",
    "             'RCON0071', 'RCON0081',                                    \n",
    "             'RCFD0071', 'RCFD0081',                                    \n",
    "             # ------------------------------------------------------------------------------------------------\n",
    "             'RIAD4073', 'RIAD4200', 'RIAD4185', 'RIAD4180', 'RIAD4172',# Income Variables\n",
    "             ] \n",
    "\n",
    "# create a list putting together 'vars', 'loans_mat_vars', and 'securities_mat_vars':\n",
    "all_vars = vars + loans_mat_vars + securities_mat_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "eedee49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate variable RCFD1754: max gap between RCFD1754_x and RCFD1754_y is 0.0\n",
      "Dropping duplicate column RCFD1754_y as it is identical to RCFD1754_x.\n",
      "Duplicate variable RCFD1773: max gap between RCFD1773_x and RCFD1773_y is 0.0\n",
      "Dropping duplicate column RCFD1773_y as it is identical to RCFD1773_x.\n",
      "Duplicate variable RCON1754: max gap between RCON1754_x and RCON1754_y is 0.0\n",
      "Dropping duplicate column RCON1754_y as it is identical to RCON1754_x.\n"
     ]
    }
   ],
   "source": [
    "main = cr.select_variables(all_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e06e9f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cr.df_selected.head(10)\n",
    "# Matches the other file! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a292f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#last_digits = sorted(list(set([var[-3:] for var in securities_mat_vars])))\n",
    "\n",
    "#for x in last_digits:\n",
    "#    print('---------------------------------------------------------------------------------')\n",
    "#    print('For x = ', x)\n",
    "#    vars = [\n",
    "#    'RCFDA' + str(int(x)), 'RCONA' + str(int(x))\n",
    "#    ]\n",
    "#    print(cr.compare_variables(vars[0], vars[1]))\n",
    "# Matches the other file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "51ee4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#last_digits = sorted(list(set([var[-3:] for var in loans_mat_vars])))\n",
    "#last_digits = [int(x) for x in last_digits]\n",
    "#last_digits = [x for x in last_digits if x < 570]\n",
    "\n",
    "#for x in last_digits:\n",
    "#    print('---------------------------------------------------------------------------------')\n",
    "#    vars = [\n",
    "#    'RCFDA' + str(x+6), 'RCONA' + str(x)\n",
    "#    ]\n",
    "#    print(vars[0], vars[1])\n",
    "#    print(cr.compare_variables(vars[0], vars[1]))\n",
    "\n",
    "# Matches the other file!   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "726329e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mappings for all of the easy-to-create variables:\n",
    "mappings = [\n",
    "    # Maturity variables – Treasuries:\n",
    "    {\n",
    "        \"first_col\": \"RCFDA549\",\n",
    "        \"second_col\": \"RCONA549\",\n",
    "        \"new_var\": \"Treasuries (3M-)\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"RCFDA550\",\n",
    "        \"second_col\": \"RCONA550\",\n",
    "        \"new_var\": \"Treasuries (3M-1Y)\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"RCFDA551\",\n",
    "        \"second_col\": \"RCONA551\",\n",
    "        \"new_var\": \"Treasuries (1Y-3Y)\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"RCFDA552\",\n",
    "        \"second_col\": \"RCONA552\",\n",
    "        \"new_var\": \"Treasuries (3Y-5Y)\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"RCFDA553\",\n",
    "        \"second_col\": \"RCONA553\",\n",
    "        \"new_var\": \"Treasuries (5Y-15Y)\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"RCFDA554\",\n",
    "        \"second_col\": \"RCONA554\",\n",
    "        \"new_var\": \"Treasuries (15Y+)\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    # 3) Maturity variables – MBS:\n",
    "    {\n",
    "        \"first_col\": \"RCFDA555\",\n",
    "        \"second_col\": \"RCONA555\",\n",
    "        \"new_var\": \"MBS (3M-)\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"RCFDA556\",\n",
    "        \"second_col\": \"RCONA556\",\n",
    "        \"new_var\": \"MBS (3M-1Y)\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"RCFDA557\",\n",
    "        \"second_col\": \"RCONA557\",\n",
    "        \"new_var\": \"MBS (1Y-3Y)\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"RCFDA558\",\n",
    "        \"second_col\": \"RCONA558\",\n",
    "        \"new_var\": \"MBS (3Y-5Y)\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"RCFDA559\",\n",
    "        \"second_col\": \"RCONA559\",\n",
    "        \"new_var\": \"MBS (5Y-15Y)\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"RCFDA560\",\n",
    "        \"second_col\": \"RCONA560\",\n",
    "        \"new_var\": \"MBS (15Y+)\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    # 3) Maturity variables – Overall Securities (as the sum of Treasuries and MBS for each bucket):\n",
    "    {\n",
    "        \"first_col\": \"Treasuries (3M-)\",\n",
    "        \"second_col\": \"MBS (3M-)\",\n",
    "        \"new_var\": \"Securities (3M-)\",\n",
    "        \"method\": \"sum\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"Treasuries (3M-1Y)\",\n",
    "        \"second_col\": \"MBS (3M-1Y)\",\n",
    "        \"new_var\": \"Securities (3M-1Y)\",\n",
    "        \"method\": \"sum\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"Treasuries (1Y-3Y)\",\n",
    "        \"second_col\": \"MBS (1Y-3Y)\",\n",
    "        \"new_var\": \"Securities (1Y-3Y)\",\n",
    "        \"method\": \"sum\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"Treasuries (3Y-5Y)\",\n",
    "        \"second_col\": \"MBS (3Y-5Y)\",\n",
    "        \"new_var\": \"Securities (3Y-5Y)\",\n",
    "        \"method\": \"sum\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"Treasuries (5Y-15Y)\",\n",
    "        \"second_col\": \"MBS (5Y-15Y)\",\n",
    "        \"new_var\": \"Securities (5Y-15Y)\",\n",
    "        \"method\": \"sum\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"Treasuries (15Y+)\",\n",
    "        \"second_col\": \"MBS (15Y+)\",\n",
    "        \"new_var\": \"Securities (15Y+)\",\n",
    "        \"method\": \"sum\"\n",
    "    },\n",
    "    # 3) Maturity variables – Overall Loans:\n",
    "    {\n",
    "        \"first_col\": \"RCFDA570\",\n",
    "        \"second_col\": \"RCONA564\",\n",
    "        \"new_var\": \"Loans (3M-)\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"RCFDA571\",\n",
    "        \"second_col\": \"RCONA565\",\n",
    "        \"new_var\": \"Loans (3M-1Y)\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"RCFDA572\",\n",
    "        \"second_col\": \"RCONA566\",\n",
    "        \"new_var\": \"Loans (1Y-3Y)\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"RCFDA573\",\n",
    "        \"second_col\": \"RCONA567\",\n",
    "        \"new_var\": \"Loans (3Y-5Y)\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"RCFDA574\",\n",
    "        \"second_col\": \"RCONA568\",\n",
    "        \"new_var\": \"Loans (5Y-15Y)\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"RCFDA575\",\n",
    "        \"second_col\": \"RCONA569\",\n",
    "        \"new_var\": \"Loans (15Y+)\",\n",
    "        \"method\": \"secondary\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Create all the new variables:\n",
    "df = cr.construct_definitions(mappings=mappings)\n",
    "\n",
    "\n",
    "#print(df['Loans (3M-)'].describe())\n",
    "#print(df['Treasuries (3M-)'].describe())\n",
    "#print(df['MBS (3M-)'].describe())\n",
    "#print(df['Securities (3M-)'].describe())\n",
    "\n",
    "# Matches the other file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "19a01e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    9.589000e+03\n",
      "mean     5.765784e+06\n",
      "std      3.534790e+07\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      1.258600e+04\n",
      "75%      3.546600e+05\n",
      "max      6.830540e+08\n",
      "Name: RCFD1754_right, dtype: float64\n",
      "count    6.352160e+05\n",
      "mean     9.870183e+04\n",
      "std      4.310712e+06\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      2.419000e+03\n",
      "max      6.830540e+08\n",
      "Name: RCON1754_right, dtype: float64\n",
      "count    6.399020e+05\n",
      "mean     1.072001e+05\n",
      "std      4.359587e+06\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      2.494000e+03\n",
      "max      6.830540e+08\n",
      "Name: 1754_right, dtype: float64\n",
      "count    9.589000e+03\n",
      "mean     1.602612e+07\n",
      "std      4.546470e+07\n",
      "min      0.000000e+00\n",
      "25%      1.189850e+05\n",
      "50%      1.599223e+06\n",
      "75%      8.898807e+06\n",
      "max      4.754790e+08\n",
      "Name: RCFD1772, dtype: float64\n",
      "count    6.303130e+05\n",
      "mean     1.078694e+05\n",
      "std      7.320371e+05\n",
      "min      0.000000e+00\n",
      "25%      7.079000e+03\n",
      "50%      2.283400e+04\n",
      "75%      6.306500e+04\n",
      "max      7.590946e+07\n",
      "Name: RCON1772, dtype: float64\n",
      "count    6.399020e+05\n",
      "mean     3.464061e+05\n",
      "std      5.936300e+06\n",
      "min      0.000000e+00\n",
      "25%      7.197000e+03\n",
      "50%      2.332800e+04\n",
      "75%      6.572075e+04\n",
      "max      4.754790e+08\n",
      "Name: 1772_right, dtype: float64\n",
      "count    5.802590e+05\n",
      "mean     1.993277e+05\n",
      "std      4.544010e+06\n",
      "min      1.000000e+00\n",
      "25%      1.027500e+04\n",
      "50%      2.707300e+04\n",
      "75%      7.089550e+04\n",
      "max      6.830540e+08\n",
      "Name: Securities AC, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mappings = [\n",
    "    # 1) Loans: Total Loans = RCON2122.combine_first(RCFD2122), then mask zeros.\n",
    "    {\n",
    "        \"first_col\": \"RCON2122\",\n",
    "        \"second_col\": \"RCON2122\",\n",
    "        \"new_var\": \"Total Loans\",\n",
    "        \"method\": \"secondary\",   # Gives RCON2122 if available, else RCFD2122.\n",
    "        \"mask_zeros\": True\n",
    "    },\n",
    "    # 2) Deposits: Create Total Deposits from RCON2200 (a simple copy) and mask zeros.\n",
    "    {\n",
    "        \"first_col\": \"RCON2200\",\n",
    "        \"second_col\": \"RCON2200\",\n",
    "        \"new_var\": \"Total Deposits\",\n",
    "        \"method\": \"secondary\",   # Since both are the same, this simply copies RCON2200.\n",
    "        \"mask_zeros\": True\n",
    "    },\n",
    "    # Mapping 1: Create RCON1754_right = RCON1754_x.combine_first(RCON1754)\n",
    "    {\n",
    "        \"first_col\": \"RCON1754\",      # fallback column\n",
    "        \"second_col\": \"RCON1754_x\",   # primary column\n",
    "        \"new_var\": \"RCON1754_right\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    # Mapping 2: Create RCFD1754_right = RCFD1754_x.combine_first(RCFD1754)\n",
    "    {\n",
    "        \"first_col\": \"RCFD1754\",      # fallback column\n",
    "        \"second_col\": \"RCFD1754_x\",   # primary column\n",
    "        \"new_var\": \"RCFD1754_right\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    # Mapping 3: Create 1754_right from RCFD1754_right and RCON1754_right\n",
    "    # This takes the row-wise minimum:\n",
    "    {\n",
    "        \"first_col\": \"RCFD1754_right\",\n",
    "        \"second_col\": \"RCON1754_right\",\n",
    "        \"new_var\": \"1754_right\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    # Mapping 4: create 1772_right from RCFD1772 and RCON1772:\n",
    "    {\n",
    "        \"first_col\": \"RCFD1772\",\n",
    "        \"second_col\": \"RCON1772\",\n",
    "        \"new_var\": \"1772_right\",\n",
    "        \"method\": \"secondary\"\n",
    "    },\n",
    "    {\n",
    "        \"first_col\": \"RCON1772\",\n",
    "        \"second_col\": \"RCON1754_right\",\n",
    "        \"new_var\": \"Securities AC\",\n",
    "        \"method\": \"first\",\n",
    "        \"mask_zeros\": True\n",
    "    },\n",
    "]\n",
    "# Create all the new variables:\n",
    "df = cr.construct_definitions(mappings=mappings)\n",
    "\n",
    "print(df['RCFD1754_right'].describe())\n",
    "print(df['RCON1754_right'].describe())\n",
    "print(df['1754_right'].describe())\n",
    "# Matches the other file!\n",
    "\n",
    "print(df['RCFD1772'].describe())\n",
    "print(df['RCON1772'].describe())\n",
    "print(df['1772_right'].describe())\n",
    "\n",
    "print(df['Securities AC'].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d576f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Date', 'IDRSSD', 'Financial Institution Name', 'Total Loans', 'Total Deposits', 'Securities AC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9e21772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Date']=='2019-03-31') | (df['Date']=='2021-12-31')]\n",
    "df = df.sort_values(by=['IDRSSD', 'Date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7e4c3ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total number of unique dates in the DataFrame\n",
    "total_dates = df['Date'].nunique()\n",
    "\n",
    "# Identify banks that appear in all dates\n",
    "banks_all_dates = df.groupby('IDRSSD')['Date'].nunique() == total_dates\n",
    "banks_to_keep = banks_all_dates[banks_all_dates].index\n",
    "\n",
    "# Filter the DataFrame to keep only these banks\n",
    "df = df[df['IDRSSD'].isin(banks_to_keep)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9a067543",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_banks = [802866, 4114567, 3437483]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cf9af954",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Deposit Growth'] = df.groupby('IDRSSD')['Total Deposits'].pct_change(fill_method=None)\n",
    "df['Securities AC Growth'] = df.groupby('IDRSSD')['Securities AC'].pct_change(fill_method=None)\n",
    "df['Loans Growth'] = df.groupby('IDRSSD')['Total Loans'].pct_change(fill_method=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b6124fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRSSD</th>\n",
       "      <th>Deposit Growth</th>\n",
       "      <th>Securities AC Growth</th>\n",
       "      <th>Loans Growth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6180</th>\n",
       "      <td>802866.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6181</th>\n",
       "      <td>802866.0</td>\n",
       "      <td>2.659752</td>\n",
       "      <td>5.522706</td>\n",
       "      <td>1.251355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9338</th>\n",
       "      <td>3437483.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9339</th>\n",
       "      <td>3437483.0</td>\n",
       "      <td>1.152184</td>\n",
       "      <td>2.461250</td>\n",
       "      <td>0.470411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9662</th>\n",
       "      <td>4114567.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9663</th>\n",
       "      <td>4114567.0</td>\n",
       "      <td>0.915417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         IDRSSD  Deposit Growth  Securities AC Growth  Loans Growth\n",
       "6180   802866.0             NaN                   NaN           NaN\n",
       "6181   802866.0        2.659752              5.522706      1.251355\n",
       "9338  3437483.0             NaN                   NaN           NaN\n",
       "9339  3437483.0        1.152184              2.461250      0.470411\n",
       "9662  4114567.0             NaN                   NaN           NaN\n",
       "9663  4114567.0        0.915417                   NaN      0.746451"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['IDRSSD'].isin(failed_banks)][['IDRSSD', 'Deposit Growth', 'Securities AC Growth', 'Loans Growth']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
